{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b14610-2ac6-43dc-a3ca-2f5533190bd8",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "    <b>Read_conllu_files.ipynb:</b> Read and parse information from diverse .conllu files, and use integrations with libraries to apply data efficently\n",
    " </font>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how diverse .conllu files can be imported, converted and worked with using the open source library [Text Extensions for Pandas](https://github.com/CODAIT/text-extensions-for-pandas). This library uses [Pandas](https://pandas.pydata.org/) DataFrames as a primary data storage format, and to work with several different NLP libraries, such as [SpaCy](https://spacy.io), [Huggingface Transformers](https://huggingface.co/transformers/). \n",
    "\n",
    "Here we show how these features can be used in conjunction to import, select data, display sentence structure information, and then finally retokenize and train a classifier model on the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32709961-2eae-4a62-a7de-84072c1ab7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.pipeline\n",
    "import sklearn.linear_model\n",
    "import transformers\n",
    "\n",
    "# And of course we need the text_extensions_for_pandas library itself.\n",
    "try:\n",
    "    import text_extensions_for_pandas as tp\n",
    "except ModuleNotFoundError as e:\n",
    "    # If we're running from within the project source tree and the parent Python\n",
    "    # environment doesn't have the text_extensions_for_pandas package, use the\n",
    "    # version in the local source tree.\n",
    "    if not os.getcwd().endswith(\"notebooks\"):\n",
    "        raise e\n",
    "    if \"..\" not in sys.path:\n",
    "        sys.path.insert(0, \"..\")\n",
    "    import text_extensions_for_pandas as tp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f78f9f-ec2c-4a85-8b0f-9b114642633e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading files\n",
    "There are several sub-flavors of .conllu files, including those used in the EWT, Ontonotes, Universal Dependencies, and  CoNLL 2009 corpuses. Text Extensions is designed to take advantage of the common features of .conllu files, while allowing for varied types to be accepted. \n",
    "\n",
    "In importing this file type, we\n",
    "1. Translate the raw words into Token Dtypes\n",
    "1. Preserve the dependencies between tokens as represented in the `head` and `deprel` columns\n",
    "1. Capture conllu metadata written into the file, if it exists \n",
    "1. Allow for conll 09 and Ontonotes style predicate - predicate argument representations\n",
    "1. Capture each token's sentence \n",
    "1. Allow the user to choose how sub-tokens are handled\n",
    "\n",
    "\n",
    "First, though we must load the datasets we will be using for this demo notebook \n",
    "\n",
    "In the following cell, we use the facilities of Text Extensions for Pandas to download a copy of the [Universal Dependencies EWT data set](https://github.com/UniversalDependencies/UD_English-EWT) and the [Trial section of the CoNLL 2009 dataset](https://ufal.mff.cuni.cz/conll2009-st/trial-data.html). **Make sure that you adhere to the terms under which they are liscensed when using them** \n",
    "\n",
    "Then we read them in and display them in the document. Notice how different the information stored in each dataset is. One thing to note is in this specific example, we drop a few columns from each dataset for brevity; remove the `.drop()` methods to show more lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd19ec4-8480-4f00-9e34-d18f90f210a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://github.com/UniversalDependencies/UD_English-EWT/raw/master/en_ewt-ud-dev.conllu',\n",
       " 'https://ufal.mff.cuni.cz/conll2009-st/trial/CoNLL2009-ST-English-trial.zip')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init file locations, and download data if necessary. \n",
    "BASE_DIR = 'CoNLL_u_test_inputs/'\n",
    "FEATHER_FILE = \"conllu_database.feather\"\n",
    "\n",
    "ewt_base_url = \"https://github.com/UniversalDependencies/UD_English-EWT/raw/master/en_ewt-ud-\"\n",
    "ewt_dev_url = ewt_base_url + 'dev.conllu'\n",
    "conll_09_test_data_url =  'https://ufal.mff.cuni.cz/conll2009-st/trial/CoNLL2009-ST-English-trial.zip'\n",
    "\n",
    "# allows us to re-start from saved points\n",
    "corpus_df = None \n",
    "\n",
    "ewt_dev_url, conll_09_test_data_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c71e57d-811e-4cd0-84f4-efeefe127697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CoNLL_u_test_inputs//CoNLL2009-ST-English-trial.txt',\n",
       " 'CoNLL_u_test_inputs//en_ewt-ud-dev.conllu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the files if they have not already been downloaded \n",
    "conll_09_path = tp.io.conll.maybe_download_dataset_data(BASE_DIR, conll_09_test_data_url)\n",
    "conllu_ewt_path = tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_dev_url)\n",
    "\n",
    "# if you already have access to the full conll 2009 dataset, name the file accordingly and uncomment this line \n",
    "# conll_09_path = BASE_DIR + 'CoNLL2009-ST-evaluation-English.conllu'\n",
    "conll_09_path, conllu_ewt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a036fb68-3441-4c7f-bc4a-2b23bdf6875d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conll 09 format .conllu document:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>FEAT</th>\n",
       "      <th>head</th>\n",
       "      <th>DEPREL</th>\n",
       "      <th>PRED</th>\n",
       "      <th>predicate</th>\n",
       "      <th>pred0arg</th>\n",
       "      <th>pred1arg</th>\n",
       "      <th>pred2arg</th>\n",
       "      <th>pred3arg</th>\n",
       "      <th>pred4arg</th>\n",
       "      <th>pred5arg</th>\n",
       "      <th>pred6arg</th>\n",
       "      <th>pred7arg</th>\n",
       "      <th>pred8arg</th>\n",
       "      <th>pred9arg</th>\n",
       "      <th>pred10arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 3): 'The'</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NMOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 11): 'economy'</td>\n",
       "      <td>economy</td>\n",
       "      <td>NN</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>NMOD</td>\n",
       "      <td>None</td>\n",
       "      <td>A1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[11, 13): ''s'</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>SUFFIX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14, 25): 'temperature'</td>\n",
       "      <td>temperature</td>\n",
       "      <td>NN</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>SBJ</td>\n",
       "      <td>temperature.01</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[26, 30): 'will'</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AM-MOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      span        LEMMA  POS  FEAT  head  DEPREL  \\\n",
       "0            [0, 3): 'The'          the   DT  None     1    NMOD   \n",
       "1       [4, 11): 'economy'      economy   NN  None     3    NMOD   \n",
       "2           [11, 13): ''s'           's  POS  None     1  SUFFIX   \n",
       "3  [14, 25): 'temperature'  temperature   NN  None     4     SBJ   \n",
       "4         [26, 30): 'will'         will   MD  None  <NA>    ROOT   \n",
       "\n",
       "             PRED predicate pred0arg pred1arg pred2arg pred3arg pred4arg  \\\n",
       "0            None      None     None     None     None     None     None   \n",
       "1            None        A1     None     None     None     None     None   \n",
       "2            None      None     None     None     None     None     None   \n",
       "3  temperature.01        A2       A1     None     None     None     None   \n",
       "4            None      None   AM-MOD     None     None     None     None   \n",
       "\n",
       "  pred5arg pred6arg pred7arg pred8arg pred9arg pred10arg  \n",
       "0     None     None     None     None     None      None  \n",
       "1     None     None     None     None     None      None  \n",
       "2     None     None     None     None     None      None  \n",
       "3     None     None     None     None     None      None  \n",
       "4     None     None     None     None     None      None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWT format .conllu document:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>features</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>deps</th>\n",
       "      <th>misc</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 4): 'From'</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>3:case</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 8): 'the'</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>3:det</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 11): 'AP'</td>\n",
       "      <td>AP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>3</td>\n",
       "      <td>obl</td>\n",
       "      <td>4:obl:from</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 17): 'comes'</td>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18, 22): 'this'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Number=Sing|PronType=Dem</td>\n",
       "      <td>5</td>\n",
       "      <td>det</td>\n",
       "      <td>6:det</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[23, 28): 'story'</td>\n",
       "      <td>story</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>4:nsubj</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[28, 29): ':'</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>punct</td>\n",
       "      <td>4:punct</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[30, 39): 'President'</td>\n",
       "      <td>President</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>11</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5:nsubj</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[40, 44): 'Bush'</td>\n",
       "      <td>Bush</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>7</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[45, 47): 'on'</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    span      lemma upostag xpostag  \\\n",
       "0         [0, 4): 'From'       from     ADP      IN   \n",
       "1          [5, 8): 'the'        the     DET      DT   \n",
       "2          [9, 11): 'AP'         AP   PROPN     NNP   \n",
       "3      [12, 17): 'comes'       come    VERB     VBZ   \n",
       "4       [18, 22): 'this'       this     DET      DT   \n",
       "5      [23, 28): 'story'      story    NOUN      NN   \n",
       "6          [28, 29): ':'          :   PUNCT       :   \n",
       "7  [30, 39): 'President'  President   PROPN     NNP   \n",
       "8       [40, 44): 'Bush'       Bush   PROPN     NNP   \n",
       "9         [45, 47): 'on'         on     ADP      IN   \n",
       "\n",
       "                                            features  head deprel        deps  \\\n",
       "0                                               None     2   case      3:case   \n",
       "1                          Definite=Def|PronType=Art     2    det       3:det   \n",
       "2                                        Number=Sing     3    obl  4:obl:from   \n",
       "3  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...  <NA>   root      0:root   \n",
       "4                           Number=Sing|PronType=Dem     5    det       6:det   \n",
       "5                                        Number=Sing     3  nsubj     4:nsubj   \n",
       "6                                               None     3  punct     4:punct   \n",
       "7                                        Number=Sing    11  nsubj     5:nsubj   \n",
       "8                                        Number=Sing     7   flat      1:flat   \n",
       "9                                               None    10   case      4:case   \n",
       "\n",
       "   misc                                        sentence_id  \\\n",
       "0  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "1  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "2  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "3  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "4  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "5  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "6  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "7  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "8  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "9  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "\n",
       "                                        paragraph_id  \\\n",
       "0  weblog-blogspot.com_nominations_20041117172713...   \n",
       "1  weblog-blogspot.com_nominations_20041117172713...   \n",
       "2  weblog-blogspot.com_nominations_20041117172713...   \n",
       "3  weblog-blogspot.com_nominations_20041117172713...   \n",
       "4  weblog-blogspot.com_nominations_20041117172713...   \n",
       "5  weblog-blogspot.com_nominations_20041117172713...   \n",
       "6  weblog-blogspot.com_nominations_20041117172713...   \n",
       "7  weblog-blogspot.com_nominations_20041117172713...   \n",
       "8  weblog-blogspot.com_nominations_20041117172713...   \n",
       "9  weblog-blogspot.com_nominations_20041117172713...   \n",
       "\n",
       "                                              doc_id  line_num  \n",
       "0  weblog-blogspot.com_nominations_20041117172713...         4  \n",
       "1  weblog-blogspot.com_nominations_20041117172713...         5  \n",
       "2  weblog-blogspot.com_nominations_20041117172713...         6  \n",
       "3  weblog-blogspot.com_nominations_20041117172713...         7  \n",
       "4  weblog-blogspot.com_nominations_20041117172713...         8  \n",
       "5  weblog-blogspot.com_nominations_20041117172713...         9  \n",
       "6  weblog-blogspot.com_nominations_20041117172713...        10  \n",
       "7  weblog-blogspot.com_nominations_20041117172713...        15  \n",
       "8  weblog-blogspot.com_nominations_20041117172713...        16  \n",
       "9  weblog-blogspot.com_nominations_20041117172713...        17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import two very different documents, both in the conllu file format. \n",
    "\n",
    "# by default we look for EWT style column names, \n",
    "# so we have to define a new set for this specific conll09 format\n",
    "conll_09_cols = [\"LEMMA\",\"PLEMMA\",'POS','PPOS','FEAT','PFEAT','head','phead','DEPREL','PDEPREL','FILLPRED','PRED']\n",
    "\n",
    "conll_09_docs = tp.io.conll.conll_u_to_dataframes(conll_09_path,column_names=conll_09_cols)\n",
    "#now just filter,and display the document \n",
    "conll_09_doc = conll_09_docs[0].drop(columns=[\"PLEMMA\",'PPOS','PFEAT','phead','PDEPREL','FILLPRED','sentence','line_num'])\n",
    "print(\"Conll 09 format .conllu document:\")\n",
    "display(conll_09_doc.head())\n",
    "\n",
    "\n",
    "#simultaneously, we can import an ewt style document, and display it with the same function\n",
    "conll_u_docs = tp.io.conll.conll_u_to_dataframes(conllu_ewt_path)\n",
    "#display \n",
    "DOC_NUM = 0\n",
    "doc_df = conll_u_docs[DOC_NUM]\n",
    "# here we drop the sentence argument for brevity.\n",
    "print(\"EWT format .conllu document:\")\n",
    "doc_df.head(10).drop(columns = [\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42bb64-5ac6-4270-b764-6faa991347a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combining documents and saving as a .feather file. \n",
    "\n",
    "Something that is often useful is to store multiple documents from a corpus in one single dataset. Here we do that, then make an adjustment to keep the `'head'` column of our database pointing at the correct elements.\n",
    "\n",
    "\n",
    "Next we quickly write then reread our document as a `.feather` file in its. manipulated state. Because this is serialized, writing and reading is significantly faster than writing to a raw `.conllu` format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153306f1-5b99-459d-8049-fa9a28f7dfee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size is 25153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 4): 'From'</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 8): 'the'</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>2.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 11): 'AP'</td>\n",
       "      <td>AP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 17): 'comes'</td>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18, 22): 'this'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>5.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25148</th>\n",
       "      <td>[251, 254): 'and'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25149</th>\n",
       "      <td>[255, 256): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25150</th>\n",
       "      <td>[257, 261): 'very'</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>25151.0</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25151</th>\n",
       "      <td>[262, 275): 'knowledgeable'</td>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25152</th>\n",
       "      <td>[276, 281): 'staff'</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>25147.0</td>\n",
       "      <td>conj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              span          lemma upostag     head  deprel\n",
       "0                   [0, 4): 'From'           from     ADP      2.0    case\n",
       "1                    [5, 8): 'the'            the     DET      2.0     det\n",
       "2                    [9, 11): 'AP'             AP   PROPN      3.0     obl\n",
       "3                [12, 17): 'comes'           come    VERB      NaN    root\n",
       "4                 [18, 22): 'this'           this     DET      5.0     det\n",
       "...                            ...            ...     ...      ...     ...\n",
       "25148            [251, 254): 'and'            and   CCONJ  25152.0      cc\n",
       "25149              [255, 256): 'a'              a     DET  25152.0     det\n",
       "25150           [257, 261): 'very'           very     ADV  25151.0  advmod\n",
       "25151  [262, 275): 'knowledgeable'  knowledgeable     ADJ  25152.0    amod\n",
       "25152          [276, 281): 'staff'          staff    NOUN  25147.0    conj\n",
       "\n",
       "[25153 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because we are concatenating our dataframes, we need to modify the \"head\" \n",
    "# fields to still point at their desired targets \n",
    "df_starts_at =0\n",
    "temp = conll_u_docs.copy()\n",
    "for df in temp:\n",
    "    df['head'] = df['head'].apply(lambda i: i +df_starts_at if i is not None else -1)\n",
    "    df_starts_at += df.shape[0]\n",
    "\n",
    "# Now concatenate all our documents into one big dataframe\n",
    "complete_df = pd.concat(temp, ignore_index=True)\n",
    "\n",
    "#show the last few rows of the dataframe, select just a few columns for compactness\n",
    "print(f\"size is {complete_df.shape[0]}\")\n",
    "complete_df[[\"span\",\"lemma\",\"upostag\",\"head\",\"deprel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6540975b-14a6-4187-98a4-9993f5f2d1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 μs, sys: 0 ns, total: 1 μs\n",
      "Wall time: 1.67 μs\n",
      "File written to CoNLL_u_test_inputs/conllu_database.feather\n"
     ]
    }
   ],
   "source": [
    "# one advantage of using pandas dataframes is that we can write and read them signifcantly faster than we could the raw conllu files \n",
    "# here we use pyarrow with feather to save and reload our dataframe. \n",
    "\n",
    "# Currently writing multi document files is not supported, so we will have to use a workaround, \n",
    "# by converting sentences from TokenSpanArrays to SpanArrays\n",
    "complete_df[\"sentence\"] = tp.SpanArray(complete_df[\"span\"].array.target_text, complete_df[\"sentence\"].array.begin, complete_df[\"sentence\"].array.end)\n",
    "\n",
    "#finally write to file using feather \n",
    "path = BASE_DIR +FEATHER_FILE\n",
    "# increase the chunksize slightly, to allow writing in a single block\n",
    "# time to show how fast Feather actually is \n",
    "%time\n",
    "complete_df.to_feather(path,chunksize= 65536*8)\n",
    "print(f\"File written to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade30665-3298-46ad-ab24-0da753c23067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1e+03 ns, total: 1e+03 ns\n",
      "Wall time: 3.1 μs\n",
      "size is 25153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25148</th>\n",
       "      <td>[251, 254): 'and'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25149</th>\n",
       "      <td>[255, 256): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25150</th>\n",
       "      <td>[257, 261): 'very'</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>25151.0</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25151</th>\n",
       "      <td>[262, 275): 'knowledgeable'</td>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>25152.0</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25152</th>\n",
       "      <td>[276, 281): 'staff'</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>25147.0</td>\n",
       "      <td>conj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              span          lemma upostag     head  deprel\n",
       "25148            [251, 254): 'and'            and   CCONJ  25152.0      cc\n",
       "25149              [255, 256): 'a'              a     DET  25152.0     det\n",
       "25150           [257, 261): 'very'           very     ADV  25151.0  advmod\n",
       "25151  [262, 275): 'knowledgeable'  knowledgeable     ADJ  25152.0    amod\n",
       "25152          [276, 281): 'staff'          staff    NOUN  25147.0    conj"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can read this df and continue operating on it as before. Time the read operation \n",
    "%time \n",
    "re_read_df = pd.read_feather(path)\n",
    "print(f\"size is {re_read_df.shape[0]}\")\n",
    "# show the same subset of the dataframe as above \n",
    "re_read_df.tail()[[\"span\",\"lemma\",\"upostag\",\"head\",\"deprel\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290f829-688b-4d82-af90-7e168fa5808d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show sentence parse trees using pandas data manipulation, and SpaCy integrations\n",
    "Because of the integrations built into Text extensions, we can use powerful data visualization tools here we're leveraging spaCy's dependency tree visualization tools, to show the parse tree as specified in the raw conllu file. \n",
    "\n",
    "First, we use Pandas groupby to to quickly select the n'th sentence in the dataset, and store it as its own dataframe and display selected columns \n",
    "\n",
    "Then we use Spacy to render the parse tree of that specific sentence, as found in the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f41cb8-a833-4e84-ab9b-d0d5a7408e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>[979, 982): 'And'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>cc</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>[983, 987): 'what'</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>obj</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>[988, 990): 'do'</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>aux</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>[991, 993): 'we'</td>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>[994, 997): 'get'</td>\n",
       "      <td>get</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>[998, 1001): 'for'</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>case</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>[1002, 1006): 'this'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>2518.0</td>\n",
       "      <td>det</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>[1007, 1013): 'effort'</td>\n",
       "      <td>effort</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>obl</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>[1013, 1014): '?'</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>punct</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        span   lemma upostag xpostag    head deprel  \\\n",
       "2511       [979, 982): 'And'     and   CCONJ      CC  2515.0     cc   \n",
       "2512      [983, 987): 'what'    what    PRON      WP  2515.0    obj   \n",
       "2513        [988, 990): 'do'      do     AUX     VBP  2515.0    aux   \n",
       "2514        [991, 993): 'we'      we    PRON     PRP  2515.0  nsubj   \n",
       "2515       [994, 997): 'get'     get    VERB      VB     NaN   root   \n",
       "2516      [998, 1001): 'for'     for     ADP      IN  2518.0   case   \n",
       "2517    [1002, 1006): 'this'    this     DET      DT  2518.0    det   \n",
       "2518  [1007, 1013): 'effort'  effort    NOUN      NN  2515.0    obl   \n",
       "2519       [1013, 1014): '?'       ?   PUNCT       .  2515.0  punct   \n",
       "\n",
       "                                               sentence  \n",
       "2511  [979, 1014): 'And what do we get for this effo...  \n",
       "2512  [979, 1014): 'And what do we get for this effo...  \n",
       "2513  [979, 1014): 'And what do we get for this effo...  \n",
       "2514  [979, 1014): 'And what do we get for this effo...  \n",
       "2515  [979, 1014): 'And what do we get for this effo...  \n",
       "2516  [979, 1014): 'And what do we get for this effo...  \n",
       "2517  [979, 1014): 'And what do we get for this effo...  \n",
       "2518  [979, 1014): 'And what do we get for this effo...  \n",
       "2519  [979, 1014): 'And what do we get for this effo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c0ecdbc58921458792e88cef1a3e9b79-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">And</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">what</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">get</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">effort</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 750.0,2.0 750.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c0ecdbc58921458792e88cef1a3e9b79-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c0ecdbc58921458792e88cef1a3e9b79-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sentence_num = 110\n",
    "\n",
    "# use pandas to quickly select the 'n'th sentence in the dataset \n",
    "nth_sentence = list(re_read_df.groupby(\"sentence_id\",sort=False))[Sentence_num][1]\n",
    "display(nth_sentence[[\"span\",\"lemma\",\"upostag\",\"xpostag\",\"head\",\"deprel\",\"sentence\"]])\n",
    "\n",
    "# now use spacy integration to rendeer the parse tree\n",
    "tp.io.spacy.render_parse_tree(nth_sentence,tag_col=\"upostag\",label_col=\"deprel\",head_col=\"head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc00e06-b2fe-47f0-9f0a-20d0b8370807",
   "metadata": {},
   "source": [
    "# Train a classifier model\n",
    "\n",
    "Now use more text extensions integrations, with *transformers* to quickly and easily train a part of speech classifier model using bert embeddings on our data. We loosely follow the same process as is used in the [Model_Training_with_BERT](./Model_Training_with_BERT.ipynb) demo, notebook so check there for a more indepth explanation of each step.\n",
    "\n",
    "Broadly, what we do is: \n",
    "1. Import all the folds of the dataset we're using (Universal dependencies EWT) \n",
    "1. Create a Pandas Categorical datatype on over which to classify\n",
    "1. Retokenize that dataset using Huggingface Transformers to Bert-compatible tokens\n",
    "1. Correlate the new tokens with their original counterpart's parts of speech\n",
    "1. Create the Bert embeddings for each sub-token\n",
    "1. Convert the parts of speech tags to our categoical datatype\n",
    "1. Initialize and train a sklearn model on the Bert embeddings -> Part of Speech\n",
    "1. Use that model to perform inference on our dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f20214-62d9-4f7b-bd4f-fcd377148aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted fold: 'test' to list of 316 dataframes\n",
      "converted fold: 'dev' to list of 318 dataframes\n",
      "converted fold: 'train' to list of 540 dataframes\n"
     ]
    }
   ],
   "source": [
    "# We're going to need the whole ewt dataset for this: download them, and parse them in \n",
    "fold_paths = {\"test\":  tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"test.conllu\"),\n",
    "              \"dev\":   tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"dev.conllu\"),\n",
    "              \"train\": tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"train.conllu\")}\n",
    "fold_docs = {}\n",
    "for fold,fold_path in fold_paths.items(): \n",
    "    fold_docs[fold] = tp.io.conll.conll_u_to_dataframes(fold_path)\n",
    "    print(f\"converted fold: '{fold}' to list of {len(fold_docs[fold])} dataframes\")\n",
    "    #     uncomment to display segments of the extracted folds \n",
    "    #     display(fold_docs[fold][0].head()[['span','lemma','upostag','features','sentence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade0734-2845-4b30-8472-59f103f44bd9",
   "metadata": {},
   "source": [
    "### Initialize elements for preprocessing steps\n",
    "Instantiate pretrained tokenizer and BERT models from transformers library, and create a pandas categorical datatype for parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf1b9d6-b2cb-45fe-b724-529b7bb75d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(bert_model_name)\n",
    "bert = transformers.BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# also we will want to create a pandas categorical dtype for what we want to predict- part of speech. \n",
    "# use the combined df, because it has all the elements \n",
    "upostags_list = list(re_read_df[\"upostag\"].unique())\n",
    "# upostag_dtype,upostag_list,upostag_dict = tp.io.conll.make_iob_tag_categories(upostags)\n",
    "upostag_dtype = pd.CategoricalDtype(categories = upostags_list)\n",
    "upostag_dict = {upostags_list[i]:i for i in range(len(upostags_list)) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fdc34-613d-47e1-8287-c33384da69ba",
   "metadata": {},
   "source": [
    "## Preprocess the document\n",
    "\n",
    "Because steps 3-6 can only be done on a document-by-document basis, we create a method to do them in a batch, then run them  on the whole corpus. Note this process is computationally intensive so it may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe4b27e-4f8f-4dab-ad42-ca04bcb3234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464d274c90f54d39b8005e732a474a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=316, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2014c1094040f391e07df6842845fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=318, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a03ae876a3c41069b00467d9210f580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=540, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a method to take care of preprocessing steps: 3-6\n",
    "def preprocess_document(document, tokenizer,bert):\n",
    "    # create BERT compatible tokens using our tokenizer\n",
    "    temp = tp.io.bert.make_bert_tokens(document.loc[0,'span'].target_text, tokenizer)\n",
    "    # re-correlate our original spans with their bert-compatible equivalents\n",
    "    spans = tp.TokenSpanArray.align_to_tokens(temp[\"span\"],document[\"span\"])\n",
    "\n",
    "    # now carry over some features from the old spans to the new ones\n",
    "    #spans_df = spans.as_frame().drop(columns = [\"begin\",\"end\"])\n",
    "    spans_df = spans.as_frame().drop(columns=['begin','end','covered_text'])\n",
    "    spans_df['postag'] = document['upostag']\n",
    "    # printed = 20\n",
    "    for i, b_tok, e_tok, pos in spans_df.itertuples():\n",
    "        temp.loc[b_tok:e_tok-1, [\"postag\",\"raw_span\",'raw_span_id']] = pos,spans[i],i\n",
    "\n",
    "    # now translate from text tags to postag\n",
    "    temp['postag'] = temp['postag'].fillna('X') # in our Labels, 'X' is a standin for \"N/A\" so convert N/A's to 'X'\n",
    "    temp[\"postag_id\"] = temp['postag'].apply(lambda t: int(upostag_dict[str(t)]))\n",
    "    temp = temp.astype({'postag_id':'int','postag':upostag_dtype})\n",
    "    return tp.io.bert.add_embeddings(temp, bert)\n",
    "\n",
    "\n",
    "# preprocess the whole corpus: \n",
    "bert_docs_by_fold = {}\n",
    "for fold in fold_docs.keys():\n",
    "    docs = fold_docs[fold]\n",
    "    print(f\"processing fold {fold}\")\n",
    "    bert_docs_by_fold[fold] = tp.jupyter.run_with_progress_bar(len(docs),lambda i: preprocess_document(docs[i],tokenizer,bert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843badb-33c5-4bd3-a05c-ef2159adfa43",
   "metadata": {},
   "source": [
    "## Checkpoint: save preprocessed data \n",
    "\n",
    "Because the last step was time intensive, combine all the documents together, then save them as a feather file, so that we can restart from here if need be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec08895b-98e7-43cc-8138-412893982019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/freiss/pd/tep-python/text_extensions_for_pandas/array/arrow_conversion.py:313: FutureWarning: pyarrow.PyExtensionType is deprecated and will refuse deserialization by default. Instead, please derive from pyarrow.ExtensionType and implement your own serialization mechanism.\n",
      "  pa.PyExtensionType.__init__(self, pa.list_(pyarrow_dtype))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[  -0.37686658,   -0.14841501,     0.7397996, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[  -0.23267001,    -0.4054631,     0.6171939, ...</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>[   -0.8156848,  -0.047826126,    0.08148584, ...</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[   0.78967667,    -0.8511877,    -0.4881261, ...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[  -0.25935128,     0.5710735,  -0.091067344, ...</td>\n",
       "      <td>Mo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  doc_num  token_id               span  input_id  token_type_id  \\\n",
       "0  test        0         0         [0, 0): ''       101              0   \n",
       "1  test        0         1     [0, 4): 'What'      1327              0   \n",
       "2  test        0         2       [5, 7): 'if'      1191              0   \n",
       "3  test        0         3  [8, 14): 'Google'      7986              0   \n",
       "4  test        0         4     [15, 17): 'Mo'     12556              0   \n",
       "\n",
       "   attention_mask  special_tokens_mask postag             raw_span  \\\n",
       "0               1                 True      X                  NaN   \n",
       "1               1                False   PRON       [0, 4): 'What'   \n",
       "2               1                False  SCONJ         [5, 7): 'if'   \n",
       "3               1                False  PROPN    [8, 14): 'Google'   \n",
       "4               1                False   VERB  [15, 22): 'Morphed'   \n",
       "\n",
       "   raw_span_id  postag_id                                          embedding  \\\n",
       "0          NaN         14  [  -0.37686658,   -0.14841501,     0.7397996, ...   \n",
       "1          0.0         11  [  -0.23267001,    -0.4054631,     0.6171939, ...   \n",
       "2          1.0         13  [   -0.8156848,  -0.047826126,    0.08148584, ...   \n",
       "3          2.0          2  [   0.78967667,    -0.8511877,    -0.4881261, ...   \n",
       "4          3.0          3  [  -0.25935128,     0.5710735,  -0.091067344, ...   \n",
       "\n",
       "     text  \n",
       "0          \n",
       "1    What  \n",
       "2      if  \n",
       "3  Google  \n",
       "4      Mo  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine folds and save to a feather file, so we don't necessarily need to redo the preprocessing. \n",
    "corpus_df = tp.io.conll.combine_folds(bert_docs_by_fold)\n",
    "corpus_df[\"text\"] = corpus_df[\"span\"].apply(lambda s: s.covered_text)\n",
    "cols_to_drop = [c for c in corpus_df.columns if \"span\" in c]\n",
    "corpus_df.drop(columns=cols_to_drop).to_feather(\"outputs/conll_u_corpus.feather\")\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63efdd32-5458-4dcb-91f3-dca97a7d1772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.37686658,    -0.14841501,      0.739799...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[   -0.23267001,     -0.4054631,      0.617193...</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>[    -0.8156848,   -0.047826126,     0.0814858...</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[    0.78967667,     -0.8511877,     -0.488126...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[   -0.25935128,      0.5710735,   -0.09106734...</td>\n",
       "      <td>Mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307909</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>756</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>690.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[  -0.069846205,    -0.46460724,     0.8547706...</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307910</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>757</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>691.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[    0.14624085,    -0.46386108,     0.5966832...</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307911</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>758</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>692.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[  -0.090651415,     -0.2959277,     0.5970228...</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307912</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>759</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>693.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[    0.03102396,    -0.27608696,      0.782190...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307913</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>760</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.50887114,     -0.2288592,      0.544943...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307914 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id                 span  input_id  \\\n",
       "0        test        0         0           [0, 0): ''       101   \n",
       "1        test        0         1       [0, 4): 'What'      1327   \n",
       "2        test        0         2         [5, 7): 'if'      1191   \n",
       "3        test        0         3    [8, 14): 'Google'      7986   \n",
       "4        test        0         4       [15, 17): 'Mo'     12556   \n",
       "...       ...      ...       ...                  ...       ...   \n",
       "307909  train      539       756   [3152, 3154): 'my'      1139   \n",
       "307910  train      539       757  [3155, 3158): 'car'      1610   \n",
       "307911  train      539       758    [3158, 3159): ')'       114   \n",
       "307912  train      539       759    [3159, 3160): '.'       119   \n",
       "307913  train      539       760           [0, 0): ''       102   \n",
       "\n",
       "        token_type_id  attention_mask  special_tokens_mask postag  \\\n",
       "0                   0               1                 True      X   \n",
       "1                   0               1                False   PRON   \n",
       "2                   0               1                False  SCONJ   \n",
       "3                   0               1                False  PROPN   \n",
       "4                   0               1                False   VERB   \n",
       "...               ...             ...                  ...    ...   \n",
       "307909              0               1                False   PRON   \n",
       "307910              0               1                False   NOUN   \n",
       "307911              0               1                False  PUNCT   \n",
       "307912              0               1                False  PUNCT   \n",
       "307913              0               1                 True      X   \n",
       "\n",
       "                   raw_span  raw_span_id  postag_id  \\\n",
       "0                       NaN          NaN         14   \n",
       "1            [0, 4): 'What'          0.0         11   \n",
       "2              [5, 7): 'if'          1.0         13   \n",
       "3         [8, 14): 'Google'          2.0          2   \n",
       "4       [15, 22): 'Morphed'          3.0          3   \n",
       "...                     ...          ...        ...   \n",
       "307909   [3152, 3154): 'my'        690.0         11   \n",
       "307910  [3155, 3158): 'car'        691.0          4   \n",
       "307911    [3158, 3159): ')'        692.0          5   \n",
       "307912    [3159, 3160): '.'        693.0          5   \n",
       "307913                  NaN          NaN         14   \n",
       "\n",
       "                                                embedding    text  \n",
       "0       [   -0.37686658,    -0.14841501,      0.739799...          \n",
       "1       [   -0.23267001,     -0.4054631,      0.617193...    What  \n",
       "2       [    -0.8156848,   -0.047826126,     0.0814858...      if  \n",
       "3       [    0.78967667,     -0.8511877,     -0.488126...  Google  \n",
       "4       [   -0.25935128,      0.5710735,   -0.09106734...      Mo  \n",
       "...                                                   ...     ...  \n",
       "307909  [  -0.069846205,    -0.46460724,     0.8547706...      my  \n",
       "307910  [    0.14624085,    -0.46386108,     0.5966832...     car  \n",
       "307911  [  -0.090651415,     -0.2959277,     0.5970228...       )  \n",
       "307912  [    0.03102396,    -0.27608696,      0.782190...       .  \n",
       "307913  [   -0.50887114,     -0.2288592,      0.544943...          \n",
       "\n",
       "[307914 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-read feather document if need be: \n",
    "if corpus_df is None or corpus_df.size == 0:\n",
    "    corpus_df = pd.read_feather(\"outputs/conll_u_corpus.feather\")\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfa7afc-6510-4b5f-9ff4-4b184f00e352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64732</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.41927955,    -0.22575185,      0.664876...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64733</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 2): 'Al'</td>\n",
       "      <td>2586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[0, 2): 'Al'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[   -0.36961353,     -1.0804737,      -0.28336...</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64734</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 3): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[2, 3): '-'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[    -0.9178746,     -0.9462433,     -0.808997...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64735</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 5): 'Z'</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[4, 9): 'Zaman'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[   -0.90530235,     -0.9708696,     -1.440879...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64736</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 9): 'aman'</td>\n",
       "      <td>19853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[4, 9): 'Zaman'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[    -1.1586107,     -1.1497655,      -1.19497...</td>\n",
       "      <td>aman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307909</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>756</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>690.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[  -0.069846205,    -0.46460724,     0.8547706...</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307910</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>757</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>691.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[    0.14624085,    -0.46386108,     0.5966832...</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307911</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>758</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>692.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[  -0.090651415,     -0.2959277,     0.5970228...</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307912</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>759</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>693.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[    0.03102396,    -0.27608696,      0.782190...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307913</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>760</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.50887114,     -0.2288592,      0.544943...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243182 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id                 span  input_id  \\\n",
       "64732   train        0         0           [0, 0): ''       101   \n",
       "64733   train        0         1         [0, 2): 'Al'      2586   \n",
       "64734   train        0         2          [2, 3): '-'       118   \n",
       "64735   train        0         3          [4, 5): 'Z'       163   \n",
       "64736   train        0         4       [5, 9): 'aman'     19853   \n",
       "...       ...      ...       ...                  ...       ...   \n",
       "307909  train      539       756   [3152, 3154): 'my'      1139   \n",
       "307910  train      539       757  [3155, 3158): 'car'      1610   \n",
       "307911  train      539       758    [3158, 3159): ')'       114   \n",
       "307912  train      539       759    [3159, 3160): '.'       119   \n",
       "307913  train      539       760           [0, 0): ''       102   \n",
       "\n",
       "        token_type_id  attention_mask  special_tokens_mask postag  \\\n",
       "64732               0               1                 True      X   \n",
       "64733               0               1                False  PROPN   \n",
       "64734               0               1                False  PUNCT   \n",
       "64735               0               1                False  PROPN   \n",
       "64736               0               1                False  PROPN   \n",
       "...               ...             ...                  ...    ...   \n",
       "307909              0               1                False   PRON   \n",
       "307910              0               1                False   NOUN   \n",
       "307911              0               1                False  PUNCT   \n",
       "307912              0               1                False  PUNCT   \n",
       "307913              0               1                 True      X   \n",
       "\n",
       "                   raw_span  raw_span_id  postag_id  \\\n",
       "64732                   NaN          NaN         14   \n",
       "64733          [0, 2): 'Al'          0.0          2   \n",
       "64734           [2, 3): '-'          1.0          5   \n",
       "64735       [4, 9): 'Zaman'          2.0          2   \n",
       "64736       [4, 9): 'Zaman'          2.0          2   \n",
       "...                     ...          ...        ...   \n",
       "307909   [3152, 3154): 'my'        690.0         11   \n",
       "307910  [3155, 3158): 'car'        691.0          4   \n",
       "307911    [3158, 3159): ')'        692.0          5   \n",
       "307912    [3159, 3160): '.'        693.0          5   \n",
       "307913                  NaN          NaN         14   \n",
       "\n",
       "                                                embedding  text  \n",
       "64732   [   -0.41927955,    -0.22575185,      0.664876...        \n",
       "64733   [   -0.36961353,     -1.0804737,      -0.28336...    Al  \n",
       "64734   [    -0.9178746,     -0.9462433,     -0.808997...     -  \n",
       "64735   [   -0.90530235,     -0.9708696,     -1.440879...     Z  \n",
       "64736   [    -1.1586107,     -1.1497655,      -1.19497...  aman  \n",
       "...                                                   ...   ...  \n",
       "307909  [  -0.069846205,    -0.46460724,     0.8547706...    my  \n",
       "307910  [    0.14624085,    -0.46386108,     0.5966832...   car  \n",
       "307911  [  -0.090651415,     -0.2959277,     0.5970228...     )  \n",
       "307912  [    0.03102396,    -0.27608696,      0.782190...     .  \n",
       "307913  [   -0.50887114,     -0.2288592,      0.544943...        \n",
       "\n",
       "[243182 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now get ready to train our model: \n",
    "train_df = corpus_df[corpus_df[\"fold\"] == \"train\"]\n",
    "train_df = train_df.astype({'postag_id':'int'}, copy=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fbd6f-eecc-40a1-aa60-bfdd41546af0",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Use a sklearn pipeline to train a multinomial regression model ontop of Bert embeddings to predict Part of speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "034a61f3-7fe8-4b02-b649-cea67e14ceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;mlogreg&#x27;,\n",
       "                 LogisticRegression(C=0.1, max_iter=1000, verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;mlogreg&#x27;,\n",
       "                 LogisticRegression(C=0.1, max_iter=1000, verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=1000, verbose=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('mlogreg',\n",
       "                 LogisticRegression(C=0.1, max_iter=1000, verbose=1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now actually train a model, using sklearn\n",
    "#MULTI_CLASS = \"multinomial\"\n",
    "\n",
    "# How many iterations to run the BGFS optimizer when fitting logistic\n",
    "# regression models. 100 ==> Fast; 10000 ==> Full convergence\n",
    "LBGFS_ITERATIONS = 1000\n",
    "REGULARIZATION_COEFF = 1e-1\n",
    "\n",
    "base_pipeline = sklearn.pipeline.Pipeline([\n",
    "    # Standard scaler. This only makes a difference for certain classes\n",
    "    # of embeddings.\n",
    "    #(\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"mlogreg\", sklearn.linear_model.LogisticRegression(\n",
    "        #multi_class=MULTI_CLASS,\n",
    "        verbose=1,\n",
    "        max_iter=LBGFS_ITERATIONS,\n",
    "        C=REGULARIZATION_COEFF\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train = train_df[\"embedding\"].values\n",
    "Y_train = train_df[\"postag_id\"]\n",
    "base_model = base_pipeline.fit(X_train, Y_train)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebcc759-bd0e-497e-8cbe-99708d9da66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "# pickle model so I don't need to re-fit it every time\n",
    "import pickle \n",
    "\n",
    "load_from_file= False\n",
    "pickle_model_file = \"conllu_pos_classifier.pickle\"\n",
    "\n",
    "if not load_from_file:\n",
    "    with open(BASE_DIR+ pickle_model_file, 'wb') as file: \n",
    "        pickle.dump(base_model,file)\n",
    "    print(\"saved\")\n",
    "else: \n",
    "    with open(BASE_DIR+ pickle_model_file, 'rb') as file: \n",
    "        base_model = pickle.load(file)\n",
    "    print(\"loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14187f-ad0b-4fdf-acbe-eadc8acfaffe",
   "metadata": {},
   "source": [
    "### Use the model to run inference on the test set of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf936b74-2f15-4180-8778-2ccac83c9ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_postag</th>\n",
       "      <th>raw_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.37686658,    -0.14841501,      0.739799...</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>X</td>\n",
       "      <td>[3.8628878957358064e-09, 1.5814630122443712e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[   -0.23267001,     -0.4054631,      0.617193...</td>\n",
       "      <td>What</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[  0.000151603222407165,   0.00262331201456116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>[    -0.8156848,   -0.047826126,     0.0814858...</td>\n",
       "      <td>if</td>\n",
       "      <td>13</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[  0.004580406302863653, 1.5823046733312133e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[    0.78967667,     -0.8511877,     -0.488126...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[ 6.787568556052076e-10, 1.8462375223634097e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[   -0.25935128,      0.5710735,   -0.09106734...</td>\n",
       "      <td>Mo</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[   0.02169692151317765,  2.687465260450824e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[17, 19): 'rp'</td>\n",
       "      <td>15615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[    -0.3267123,    -0.10905984,     0.0530879...</td>\n",
       "      <td>rp</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[ 7.801477438016654e-11,  3.233460822608078e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[19, 22): 'hed'</td>\n",
       "      <td>8961</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[    -0.9018075,    -0.16881414,     0.4379887...</td>\n",
       "      <td>hed</td>\n",
       "      <td>3</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[ 0.0001596840954975109,  3.373975531340552e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[23, 27): 'Into'</td>\n",
       "      <td>14000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[23, 27): 'Into'</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[     0.0956599,    -0.10993048,    -0.1493198...</td>\n",
       "      <td>Into</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[    0.9232216075809515,  6.113139647861225e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[28, 34): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[28, 36): 'GoogleOS'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[    -1.2023001,    -0.29254347,     0.2236390...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[1.7792656145443183e-15, 4.8210263680143775e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[34, 36): 'OS'</td>\n",
       "      <td>9025</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[28, 36): 'GoogleOS'</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[   -0.78179884,    -0.20742226,     -1.288185...</td>\n",
       "      <td>OS</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[  2.03803406860384e-08,  4.815731588956786e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[36, 37): '?'</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[36, 37): '?'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[    -0.3406872,     -0.4208276,      0.674407...</td>\n",
       "      <td>?</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[ 2.921961105357443e-05,  1.170210030007627e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[38, 42): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[38, 42): 'What'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[    -0.3910109,     -0.3363231,     0.6353162...</td>\n",
       "      <td>What</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[   2.8592608609573e-05, 0.0001566784599558685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[43, 45): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[43, 45): 'if'</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>[     -0.686653,    -0.16331354,      0.254672...</td>\n",
       "      <td>if</td>\n",
       "      <td>13</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[  0.000371699096614245,   4.53021736444223e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[46, 52): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[46, 52): 'Google'</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[     0.5702742,     -0.9182306,    -0.1871779...</td>\n",
       "      <td>Google</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[1.7352315172108815e-05,   0.02895625424608187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[53, 61): 'expanded'</td>\n",
       "      <td>3631</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[53, 61): 'expanded'</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[   -0.48126486,    -0.15816134,     0.4039634...</td>\n",
       "      <td>expanded</td>\n",
       "      <td>3</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[ 1.563060601733279e-06,  8.354891654900406e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[62, 64): 'on'</td>\n",
       "      <td>1113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[62, 64): 'on'</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.17011842,    -0.37733147,     0.7459479...</td>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[    0.9964091560686736,  1.749123897722656e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[65, 68): 'its'</td>\n",
       "      <td>1157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[65, 68): 'its'</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11</td>\n",
       "      <td>[   -0.34582135,     -0.3814524,      0.539305...</td>\n",
       "      <td>its</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[    0.3579702249396709, 0.0003836140457823451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[69, 75): 'search'</td>\n",
       "      <td>3403</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[69, 75): 'search'</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[   -0.16507237,     -0.5452602,      0.648461...</td>\n",
       "      <td>search</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[ 2.367360749332581e-06,  1.848220714893921e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[75, 76): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[75, 76): '-'</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>[   -0.16116025,    -0.44251344,     0.7121796...</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[  0.004966728689880566,  4.022996160575903e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[77, 83): 'engine'</td>\n",
       "      <td>2395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[77, 83): 'engine'</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[   -0.35368314,    -0.47415978,       0.45511...</td>\n",
       "      <td>engine</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[ 2.191304176077653e-06, 1.5461366536300383e-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  doc_num  token_id                  span  input_id  token_type_id  \\\n",
       "0   test        0         0            [0, 0): ''       101              0   \n",
       "1   test        0         1        [0, 4): 'What'      1327              0   \n",
       "2   test        0         2          [5, 7): 'if'      1191              0   \n",
       "3   test        0         3     [8, 14): 'Google'      7986              0   \n",
       "4   test        0         4        [15, 17): 'Mo'     12556              0   \n",
       "5   test        0         5        [17, 19): 'rp'     15615              0   \n",
       "6   test        0         6       [19, 22): 'hed'      8961              0   \n",
       "7   test        0         7      [23, 27): 'Into'     14000              0   \n",
       "8   test        0         8    [28, 34): 'Google'      7986              0   \n",
       "9   test        0         9        [34, 36): 'OS'      9025              0   \n",
       "10  test        0        10         [36, 37): '?'       136              0   \n",
       "11  test        0        11      [38, 42): 'What'      1327              0   \n",
       "12  test        0        12        [43, 45): 'if'      1191              0   \n",
       "13  test        0        13    [46, 52): 'Google'      7986              0   \n",
       "14  test        0        14  [53, 61): 'expanded'      3631              0   \n",
       "15  test        0        15        [62, 64): 'on'      1113              0   \n",
       "16  test        0        16       [65, 68): 'its'      1157              0   \n",
       "17  test        0        17    [69, 75): 'search'      3403              0   \n",
       "18  test        0        18         [75, 76): '-'       118              0   \n",
       "19  test        0        19    [77, 83): 'engine'      2395              0   \n",
       "\n",
       "    attention_mask  special_tokens_mask postag              raw_span  \\\n",
       "0                1                 True      X                   NaN   \n",
       "1                1                False   PRON        [0, 4): 'What'   \n",
       "2                1                False  SCONJ          [5, 7): 'if'   \n",
       "3                1                False  PROPN     [8, 14): 'Google'   \n",
       "4                1                False   VERB   [15, 22): 'Morphed'   \n",
       "5                1                False   VERB   [15, 22): 'Morphed'   \n",
       "6                1                False   VERB   [15, 22): 'Morphed'   \n",
       "7                1                False    ADP      [23, 27): 'Into'   \n",
       "8                1                False  PROPN  [28, 36): 'GoogleOS'   \n",
       "9                1                False  PROPN  [28, 36): 'GoogleOS'   \n",
       "10               1                False  PUNCT         [36, 37): '?'   \n",
       "11               1                False   PRON      [38, 42): 'What'   \n",
       "12               1                False  SCONJ        [43, 45): 'if'   \n",
       "13               1                False  PROPN    [46, 52): 'Google'   \n",
       "14               1                False   VERB  [53, 61): 'expanded'   \n",
       "15               1                False    ADP        [62, 64): 'on'   \n",
       "16               1                False   PRON       [65, 68): 'its'   \n",
       "17               1                False   NOUN    [69, 75): 'search'   \n",
       "18               1                False  PUNCT         [75, 76): '-'   \n",
       "19               1                False   NOUN    [77, 83): 'engine'   \n",
       "\n",
       "    raw_span_id  postag_id                                          embedding  \\\n",
       "0           NaN         14  [   -0.37686658,    -0.14841501,      0.739799...   \n",
       "1           0.0         11  [   -0.23267001,     -0.4054631,      0.617193...   \n",
       "2           1.0         13  [    -0.8156848,   -0.047826126,     0.0814858...   \n",
       "3           2.0          2  [    0.78967667,     -0.8511877,     -0.488126...   \n",
       "4           3.0          3  [   -0.25935128,      0.5710735,   -0.09106734...   \n",
       "5           3.0          3  [    -0.3267123,    -0.10905984,     0.0530879...   \n",
       "6           3.0          3  [    -0.9018075,    -0.16881414,     0.4379887...   \n",
       "7           4.0          0  [     0.0956599,    -0.10993048,    -0.1493198...   \n",
       "8           5.0          2  [    -1.2023001,    -0.29254347,     0.2236390...   \n",
       "9           5.0          2  [   -0.78179884,    -0.20742226,     -1.288185...   \n",
       "10          6.0          5  [    -0.3406872,     -0.4208276,      0.674407...   \n",
       "11          7.0         11  [    -0.3910109,     -0.3363231,     0.6353162...   \n",
       "12          8.0         13  [     -0.686653,    -0.16331354,      0.254672...   \n",
       "13          9.0          2  [     0.5702742,     -0.9182306,    -0.1871779...   \n",
       "14         10.0          3  [   -0.48126486,    -0.15816134,     0.4039634...   \n",
       "15         11.0          0  [   -0.17011842,    -0.37733147,     0.7459479...   \n",
       "16         12.0         11  [   -0.34582135,     -0.3814524,      0.539305...   \n",
       "17         13.0          4  [   -0.16507237,     -0.5452602,      0.648461...   \n",
       "18         14.0          5  [   -0.16116025,    -0.44251344,     0.7121796...   \n",
       "19         15.0          4  [   -0.35368314,    -0.47415978,       0.45511...   \n",
       "\n",
       "        text  p_id p_postag                                         raw_output  \n",
       "0               14        X  [3.8628878957358064e-09, 1.5814630122443712e-0...  \n",
       "1       What     5    PUNCT  [  0.000151603222407165,   0.00262331201456116...  \n",
       "2         if    13    SCONJ  [  0.004580406302863653, 1.5823046733312133e-0...  \n",
       "3     Google     2    PROPN  [ 6.787568556052076e-10, 1.8462375223634097e-0...  \n",
       "4         Mo     4     NOUN  [   0.02169692151317765,  2.687465260450824e-0...  \n",
       "5         rp     4     NOUN  [ 7.801477438016654e-11,  3.233460822608078e-0...  \n",
       "6        hed     3     VERB  [ 0.0001596840954975109,  3.373975531340552e-0...  \n",
       "7       Into     0      ADP  [    0.9232216075809515,  6.113139647861225e-1...  \n",
       "8     Google     2    PROPN  [1.7792656145443183e-15, 4.8210263680143775e-1...  \n",
       "9         OS     2    PROPN  [  2.03803406860384e-08,  4.815731588956786e-1...  \n",
       "10         ?     5    PUNCT  [ 2.921961105357443e-05,  1.170210030007627e-0...  \n",
       "11      What     5    PUNCT  [   2.8592608609573e-05, 0.0001566784599558685...  \n",
       "12        if    13    SCONJ  [  0.000371699096614245,   4.53021736444223e-0...  \n",
       "13    Google     2    PROPN  [1.7352315172108815e-05,   0.02895625424608187...  \n",
       "14  expanded     3     VERB  [ 1.563060601733279e-06,  8.354891654900406e-1...  \n",
       "15        on     0      ADP  [    0.9964091560686736,  1.749123897722656e-0...  \n",
       "16       its     0      ADP  [    0.3579702249396709, 0.0003836140457823451...  \n",
       "17    search     4     NOUN  [ 2.367360749332581e-06,  1.848220714893921e-0...  \n",
       "18         -     5    PUNCT  [  0.004966728689880566,  4.022996160575903e-0...  \n",
       "19    engine     4     NOUN  [ 2.191304176077653e-06, 1.5461366536300383e-1...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer_on_df(df: pd.DataFrame, id_to_class_dict, predictor):\n",
    "    result_df = df.copy()\n",
    "    inputs = result_df[\"embedding\"].to_numpy()\n",
    "    raw_outputs = tp.TensorArray(predictor.predict_proba(inputs))\n",
    "    result_df[\"p_id\"] = np.argmax(raw_outputs, axis=1)\n",
    "    result_df[\"p_postag\"]= result_df[\"p_id\"].apply(lambda p_id: id_to_class_dict[p_id])\n",
    "    result_df[\"raw_output\"] = raw_outputs\n",
    "    return result_df\n",
    "\n",
    "test_results = infer_on_df(corpus_df[corpus_df[\"fold\"] == \"test\"], upostags_list, base_model)\n",
    "test_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2634300-ea5f-4424-9c65-120143a66444",
   "metadata": {},
   "source": [
    "## Now look at the data we've made and aggregate it to calculate F1 scores \n",
    "\n",
    "First, aggregate by raw surface token, to get the 'real' token predictions from the bert-ified values To do this we multiply the probabilities for each subtoken\n",
    "\n",
    "Then compare with existing labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b57b7d79-2d5f-450e-8cfd-3f6e3e78b799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>p_postag_id</th>\n",
       "      <th>predicted_postag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>VERB</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[307, 309): 'of'</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>ADP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[310, 313): 'the'</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>DET</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[314, 319): 'pic's'</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[319, 320): '.'</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[321, 324): 'One'</th>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>NUM</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num postag  postag_id p_postag_id  \\\n",
       "raw_span                                                           \n",
       "[0, 4): 'What'       test        0   PRON         11           5   \n",
       "[5, 7): 'if'         test        0  SCONJ         13          13   \n",
       "[8, 14): 'Google'    test        0  PROPN          2           2   \n",
       "[15, 22): 'Morphed'  test        0   VERB          3           4   \n",
       "[23, 27): 'Into'     test        0    ADP          0           0   \n",
       "...                   ...      ...    ...        ...         ...   \n",
       "[307, 309): 'of'     test        2    ADP          0           0   \n",
       "[310, 313): 'the'    test        2    DET          1           1   \n",
       "[314, 319): 'pic's'  test        2   NOUN          4           4   \n",
       "[319, 320): '.'      test        2  PUNCT          5           5   \n",
       "[321, 324): 'One'    test        2    NUM          6           6   \n",
       "\n",
       "                    predicted_postag  \n",
       "raw_span                              \n",
       "[0, 4): 'What'                 PUNCT  \n",
       "[5, 7): 'if'                   SCONJ  \n",
       "[8, 14): 'Google'              PROPN  \n",
       "[15, 22): 'Morphed'             NOUN  \n",
       "[23, 27): 'Into'                 ADP  \n",
       "...                              ...  \n",
       "[307, 309): 'of'                 ADP  \n",
       "[310, 313): 'the'                DET  \n",
       "[314, 319): 'pic's'             NOUN  \n",
       "[319, 320): '.'                PUNCT  \n",
       "[321, 324): 'One'                NUM  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def agg_outputs(series: pd.Series):\n",
    "    return series.to_numpy().prod(axis=0).argmax()\n",
    "     \n",
    "test_raw_preds = test_results.groupby(\"raw_span\").agg({\"fold\":'first', \"doc_num\": 'first','postag':'first','postag_id':'first','raw_output': agg_outputs}).rename(columns= {'raw_output':'p_postag_id'}).sort_values([\"fold\",\"doc_num\",'raw_span'])\n",
    "test_raw_preds['predicted_postag'] = test_raw_preds[\"p_postag_id\"].apply(lambda p_id: upostags_list[p_id]) \n",
    "test_raw_preds.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d7dce2-a624-48df-8332-bcec682a4478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ      0.798     0.769     0.783      1794\n",
      "         ADP      0.912     0.919     0.916      2030\n",
      "         ADV      0.784     0.752     0.768      1183\n",
      "         AUX      0.956     0.963     0.959      1543\n",
      "       CCONJ      0.975     0.967     0.971       736\n",
      "         DET      0.957     0.957     0.957      1896\n",
      "        INTJ      0.857     0.694     0.767       121\n",
      "        NOUN      0.866     0.890     0.878      4123\n",
      "         NUM      0.817     0.897     0.855       542\n",
      "        PART      0.949     0.937     0.943       649\n",
      "        PRON      0.962     0.965     0.964      2166\n",
      "       PROPN      0.825     0.856     0.840      2076\n",
      "       PUNCT      0.984     0.965     0.974      3096\n",
      "       SCONJ      0.870     0.786     0.826       384\n",
      "         SYM      0.671     0.523     0.588       109\n",
      "        VERB      0.909     0.906     0.908      2606\n",
      "           X      0.220     0.214     0.217        42\n",
      "\n",
      "    accuracy                          0.900     25096\n",
      "   macro avg      0.842     0.821     0.830     25096\n",
      "weighted avg      0.900     0.900     0.899     25096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# calculate precision, recall, and f1 score for each pos\n",
    "print(metrics.classification_report(test_raw_preds['postag'], test_raw_preds['predicted_postag'], digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce504db1-fba7-4962-8aac-5bc61aad8ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
