{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "    <b>Model_Training_with_TensorArray.ipynb:</b>\n",
    "    <p>Use Text Extensions for Pandas TensorArray to integrate model training and prediction with Pandas.</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook shows how to use the open source library [Text Extensions for Pandas](https://github.com/CODAIT/text-extensions-for-pandas) to seamlessly integrate model training and prediction with [Pandas](https://pandas.pydata.org/) DataFrames for added support of columns with N-dimensional tensors using the Pandas extension array called `TensorArray`.\n",
    "\n",
    "## TensorArray Specification\n",
    "\n",
    "A `TensorArray` represents an array of tensors where each element is an N-dimensional tensor of the same shape. If there are M tensor elements in the array, then the entire `TensorArray` will have a shape of M x N, where the outer dimension is the number of elements. Backing the `TensorArray` is a single `numpy.ndarray` with shape M x N. Standard arithmetic and comparison operations are supported and delegated to the backing ndarray. Taking a slice or multiple item selection will produce another `TensorArray`, while a single element selection will produce a `TensorElement` that also wraps a view of the `numpy.ndarray`, with similar operator support.\n",
    "\n",
    "A `TensorArray` can be constructed with zero copy from a single `numpy.ndarray` or with a sequence of elements of similar shape. Conversion of a `TensorArray` to a `numpy.ndarray` can be done with zero copy by calling `TensorArray.to_numpy()` or using the provided numpy array interface, e.g. `numpy.asarray(TensorArray(...))`. The `TensorArray` is a Pandas extension type of type `TensorType` and can be wrapped in a `pandas.Series` or used as a column in a `pandas.DataFrame` and used in standard Pandas operations. A `NULL` or missing value in the `TensorArray` is represented as a N-dimensional `numpy.ndarray` where all items are `numpy.nan`.\n",
    "\n",
    "## Model Training Example\n",
    "\n",
    "To demonstrate the TensorArray functionality from Text Extensions for Pandas, we will use the CoNLL-2003 dataset used from https://www.aclweb.org/anthology/W03-0419/ to ***\n",
    "\n",
    "1. Retokenize the entire corpus using a \"BERT-compatible\" tokenizer, and map the token/entity labels from the original corpus on to the new tokenization.\n",
    "1. Generate BERT embeddings for every token in the entire corpus in one pass, and store those embeddings in a DataFrame column (of type TensorType) alongside the tokens and labels.\n",
    "1. Persist the DataFrame with computed BERT embeddings to disk as a checkpoint.\n",
    "1. Use the embeddings to quickly train a model that will classify token class.\n",
    "1. Make predictions of the token classes on the test set, adding predicted class probabilities as a TensorArray to the DataFrame.\n",
    "1. Drill down into the DataFrame with some analysis on the predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZATION BOILERPLATE\n",
    "\n",
    "# The Jupyter kernel for this notebook usually starts up inside the notebooks\n",
    "# directory, but the text_extensions_for_pandas package code is in the parent\n",
    "# directory. Add that parent directory to the front of the Python include path.\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from typing import *\n",
    "\n",
    "import sklearn.pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "# And of course we need the text_extensions_for_pandas library itself.\n",
    "import text_extensions_for_pandas as tp\n",
    "\n",
    "# How many iterations to run the BGFS optimizer when fitting logistic\n",
    "# regression models. 100 ==> Fast; 10000 ==> Full convergence\n",
    "LBGFS_ITERATIONS = 10000\n",
    "\n",
    "# BERT Configuration\n",
    "bert_model_name = \"dslim/bert-base-NER\"\n",
    "\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(bert_model_name, \n",
    "                                                           add_special_tokens=True)\n",
    "bert = transformers.BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# Create a Pandas categorical type for consistent encoding of categories\n",
    "# across all documents.\n",
    "_ENTITY_TYPES = [\"LOC\", \"MISC\", \"ORG\", \"PER\"]\n",
    "token_class_dtype, int_to_label, label_to_int = tp.make_iob_tag_categories(_ENTITY_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorArray Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]]),\n",
       " <text_extensions_for_pandas.array.tensor.TensorType at 0x7f97bc035e90>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct from a numpy.ndarray\n",
    "arr = tp.TensorArray(np.arange(10).reshape(5, 2))\n",
    "arr, arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   [0 1]\n",
       "1   [2 3]\n",
       "2   [4 5]\n",
       "3   [6 7]\n",
       "4   [8 9]\n",
       "dtype: TensorType"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap in a Pandas Series\n",
    "s = pd.Series(arr)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]]),\n",
       " dtype('int64'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back to numpy using the provided array interface\n",
    "np_arr = np.asarray(s)\n",
    "np_arr, np_arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [False False]\n",
       "1    [False False]\n",
       "2    [False  True]\n",
       "3    [ True  True]\n",
       "4    [ True  True]\n",
       "dtype: TensorType"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply operations on the Series, result is another Series of type TensorType\n",
    "thresh = s > 4\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3   [12 14]\n",
       "4   [16 18]\n",
       "dtype: TensorType"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select items using a mix of numpy and pandas, use `.array` to get the Series as a `TensorArray`\n",
    "# which can be used on numpy operations\n",
    "s[np.all(thresh.array, axis=1)] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>[2 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>[4 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>[6 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>[8 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time features\n",
       "0 2018-01-01 00:00:00    [0 1]\n",
       "1 2018-01-01 01:00:00    [2 3]\n",
       "2 2018-01-01 02:00:00    [4 5]\n",
       "3 2018-01-01 03:00:00    [6 7]\n",
       "4 2018-01-01 04:00:00    [8 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorArray can also be added to a Pandas DataFrame\n",
    "df = pd.DataFrame({\"time\": pd.date_range('2018-01-01', periods=5, freq='H'), \"features\": arr})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>[8 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>[6 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>[4 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>[2 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time features\n",
       "4 2018-01-01 04:00:00    [8 9]\n",
       "3 2018-01-01 03:00:00    [6 7]\n",
       "2 2018-01-01 02:00:00    [4 5]\n",
       "1 2018-01-01 01:00:00    [2 3]\n",
       "0 2018-01-01 00:00:00    [0 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorArray will be incorporated with standard DataFrame operations \n",
    "df.sort_values(by=\"time\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage using BERT embeddings for Model Training on CoNLL-2003\n",
    "\n",
    "Now let's put the TensorArray to use with an example. Here we use the CoNLL-2003 corpus and retokenize using a BERT tokenizer. Next, the BERT tokens will be used to compute BERT embeddings that will be stored in a TensorArray and added to the DataFrame. Finally, we can use the BERT embeddings to train a model and make predictions on the token class, which will also be added to the DataFrame as a TensorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'outputs/eng.train',\n",
       " 'dev': 'outputs/eng.testa',\n",
       " 'test': 'outputs/eng.testb'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and cache the data set.\n",
    "# NOTE: This data set is licensed for research use only. Be sure to adhere\n",
    "#  to the terms of the license when using this data set!\n",
    "data_set_info = tp.maybe_download_conll_data(\"outputs\")\n",
    "data_set_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show how to retokenize with a BERT tokenizer.\n",
    "\n",
    "Retokenize the corpus using a \"BERT-compatible\" tokenizer, and map the token/entity labels from the original corpus on to the new tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11, 18): 'CRICKET'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[18, 19): '-'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...</td>\n",
       "      <td>1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[20, 28): 'PAKISTAN'</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...</td>\n",
       "      <td>1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[29, 30): 'V'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>[1620, 1621): '8'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[1590, 1634): 'Third one-day match: December 8...</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[1590, 1634): 'Third one-day match: December 8...</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[1590, 1634): 'Third one-day match: December 8...</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[1590, 1634): 'Third one-day match: December 8...</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[1590, 1634): 'Third one-day match: December 8...</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        span ent_iob ent_type  \\\n",
       "0      [0, 10): '-DOCSTART-'       O     None   \n",
       "1        [11, 18): 'CRICKET'       O     None   \n",
       "2              [18, 19): '-'       O     None   \n",
       "3       [20, 28): 'PAKISTAN'       B      LOC   \n",
       "4              [29, 30): 'V'       O     None   \n",
       "..                       ...     ...      ...   \n",
       "350        [1620, 1621): '8'       O     None   \n",
       "351        [1621, 1622): ','       O     None   \n",
       "352       [1623, 1625): 'in'       O     None   \n",
       "353  [1626, 1633): 'Karachi'       B      LOC   \n",
       "354        [1633, 1634): '.'       O     None   \n",
       "\n",
       "                                              sentence  line_num  \n",
       "0                                [0, 10): '-DOCSTART-'      1469  \n",
       "1    [11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...      1471  \n",
       "2    [11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...      1472  \n",
       "3    [11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...      1473  \n",
       "4    [11, 62): 'CRICKET- PAKISTAN V NEW ZEALAND ONE...      1474  \n",
       "..                                                 ...       ...  \n",
       "350  [1590, 1634): 'Third one-day match: December 8...      1865  \n",
       "351  [1590, 1634): 'Third one-day match: December 8...      1866  \n",
       "352  [1590, 1634): 'Third one-day match: December 8...      1867  \n",
       "353  [1590, 1634): 'Third one-day match: December 8...      1868  \n",
       "354  [1590, 1634): 'Third one-day match: December 8...      1869  \n",
       "\n",
       "[355 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the corpus in its original tokenization\n",
    "corpus_raw = {}\n",
    "for fold_name, file_name in data_set_info.items():\n",
    "    df_list = tp.conll_2003_to_dataframes(file_name, \n",
    "                                          [\"pos\", \"phrase\", \"ent\"],\n",
    "                                          [False, True, True])\n",
    "    corpus_raw[fold_name] = [\n",
    "        df.drop(columns=[\"pos\", \"phrase_iob\", \"phrase_type\"])\n",
    "        for df in df_list\n",
    "    ]\n",
    "\n",
    "test_raw = corpus_raw[\"test\"]\n",
    "\n",
    "# Pick out the dataframe for a single example document.\n",
    "example_df = test_raw[5]\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20, 28): 'PAKISTAN'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[20, 28): 'PAKISTAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[31, 42): 'NEW ZEALAND'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[31, 42): 'NEW ZEALAND'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[80, 83): 'GMT'</td>\n",
       "      <td>MISC</td>\n",
       "      <td>[80, 83): 'GMT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[85, 92): 'SIALKOT'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[85, 92): 'SIALKOT'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[94, 102): 'Pakistan'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[94, 102): 'Pakistan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[1488, 1501): 'Shahid Afridi'</td>\n",
       "      <td>PER</td>\n",
       "      <td>[1488, 1501): 'Shahid Afridi'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[1512, 1523): 'Salim Malik'</td>\n",
       "      <td>PER</td>\n",
       "      <td>[1512, 1523): 'Salim Malik'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[1535, 1545): 'Ijaz Ahmad'</td>\n",
       "      <td>PER</td>\n",
       "      <td>[1535, 1545): 'Ijaz Ahmad'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[1565, 1573): 'Pakistan'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[1565, 1573): 'Pakistan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             span ent_type                     token_span\n",
       "0            [20, 28): 'PAKISTAN'      LOC           [20, 28): 'PAKISTAN'\n",
       "1         [31, 42): 'NEW ZEALAND'      LOC        [31, 42): 'NEW ZEALAND'\n",
       "2                 [80, 83): 'GMT'     MISC                [80, 83): 'GMT'\n",
       "3             [85, 92): 'SIALKOT'      LOC            [85, 92): 'SIALKOT'\n",
       "4           [94, 102): 'Pakistan'      LOC          [94, 102): 'Pakistan'\n",
       "..                            ...      ...                            ...\n",
       "69  [1488, 1501): 'Shahid Afridi'      PER  [1488, 1501): 'Shahid Afridi'\n",
       "70    [1512, 1523): 'Salim Malik'      PER    [1512, 1523): 'Salim Malik'\n",
       "71     [1535, 1545): 'Ijaz Ahmad'      PER     [1535, 1545): 'Ijaz Ahmad'\n",
       "72       [1565, 1573): 'Pakistan'      LOC       [1565, 1573): 'Pakistan'\n",
       "73        [1626, 1633): 'Karachi'      LOC        [1626, 1633): 'Karachi'\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_df = tp.iob_to_spans(example_df)\n",
    "\n",
    "# Add a TokenSpan in addition to the Span column, and re-order columns\n",
    "spans_df[\"token_span\"] = tp.TokenSpanArray.from_char_offsets(spans_df[\"span\"].array)\n",
    "spans_df = spans_df.reindex(columns=[\"span\", \"token_span\", \"ent_type\"])\n",
    "spans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>16237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id                     span  input_id  token_type_id  \\\n",
       "0           0               [0, 0): ''       101              0   \n",
       "1           1              [0, 1): '-'       118              0   \n",
       "2           2              [1, 2): 'D'       141              0   \n",
       "3           3             [2, 4): 'OC'      9244              0   \n",
       "4           4             [4, 6): 'ST'      9272              0   \n",
       "..        ...                      ...       ...            ...   \n",
       "684       684        [1621, 1622): ','       117              0   \n",
       "685       685       [1623, 1625): 'in'      1107              0   \n",
       "686       686  [1626, 1633): 'Karachi'     16237              0   \n",
       "687       687        [1633, 1634): '.'       119              0   \n",
       "688       688               [0, 0): ''       102              0   \n",
       "\n",
       "     attention_mask  special_tokens_mask  \n",
       "0                 1                 True  \n",
       "1                 1                False  \n",
       "2                 1                False  \n",
       "3                 1                False  \n",
       "4                 1                False  \n",
       "..              ...                  ...  \n",
       "684               1                False  \n",
       "685               1                False  \n",
       "686               1                False  \n",
       "687               1                False  \n",
       "688               1                 True  \n",
       "\n",
       "[689 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retokenize the document's text with the BERT tokenizer\n",
    "bert_toks_df = tp.make_bert_tokens(example_df[\"span\"].values[0].target_text, tokenizer)\n",
    "\n",
    "# Add a TokenSpan in addition to the Span column, and re-order columns\n",
    "bert_toks_df[\"token_span\"] = tp.TokenSpanArray.from_char_offsets(bert_toks_df[\"span\"].array)\n",
    "bert_toks_df = bert_toks_df.reindex(columns=[\"token_id\", \"span\", \"token_span\", \"input_id\", \"token_type_id\", \"attention_mask\", \"special_tokens_mask\"])\n",
    "bert_toks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id        span  input_id  token_type_id  attention_mask  \\\n",
       "0           0  [0, 0): ''       101              0               1   \n",
       "688       688  [0, 0): ''       102              0               1   \n",
       "\n",
       "     special_tokens_mask  \n",
       "0                   True  \n",
       "688                 True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT tokenization includes special zero-length tokens.\n",
    "bert_toks_df[bert_toks_df[\"special_tokens_mask\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_span</th>\n",
       "      <th>bert_token_span</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[20, 28): 'PAKISTAN'</td>\n",
       "      <td>[20, 28): 'PAKISTAN'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[31, 42): 'NEW ZEALAND'</td>\n",
       "      <td>[31, 42): 'NEW ZEALAND'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[80, 83): 'GMT'</td>\n",
       "      <td>[80, 83): 'GMT'</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[85, 92): 'SIALKOT'</td>\n",
       "      <td>[85, 92): 'SIALKOT'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[94, 102): 'Pakistan'</td>\n",
       "      <td>[94, 102): 'Pakistan'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[1488, 1501): 'Shahid Afridi'</td>\n",
       "      <td>[1488, 1501): 'Shahid Afridi'</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[1512, 1523): 'Salim Malik'</td>\n",
       "      <td>[1512, 1523): 'Salim Malik'</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[1535, 1545): 'Ijaz Ahmad'</td>\n",
       "      <td>[1535, 1545): 'Ijaz Ahmad'</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[1565, 1573): 'Pakistan'</td>\n",
       "      <td>[1565, 1573): 'Pakistan'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_span                bert_token_span ent_type\n",
       "0            [20, 28): 'PAKISTAN'           [20, 28): 'PAKISTAN'      LOC\n",
       "1         [31, 42): 'NEW ZEALAND'        [31, 42): 'NEW ZEALAND'      LOC\n",
       "2                 [80, 83): 'GMT'                [80, 83): 'GMT'     MISC\n",
       "3             [85, 92): 'SIALKOT'            [85, 92): 'SIALKOT'      LOC\n",
       "4           [94, 102): 'Pakistan'          [94, 102): 'Pakistan'      LOC\n",
       "..                            ...                            ...      ...\n",
       "69  [1488, 1501): 'Shahid Afridi'  [1488, 1501): 'Shahid Afridi'      PER\n",
       "70    [1512, 1523): 'Salim Malik'    [1512, 1523): 'Salim Malik'      PER\n",
       "71     [1535, 1545): 'Ijaz Ahmad'     [1535, 1545): 'Ijaz Ahmad'      PER\n",
       "72       [1565, 1573): 'Pakistan'       [1565, 1573): 'Pakistan'      LOC\n",
       "73        [1626, 1633): 'Karachi'        [1626, 1633): 'Karachi'      LOC\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Align the BERT tokens with the original tokenization\n",
    "bert_token_spans = tp.TokenSpanArray.align_to_tokens(bert_toks_df[\"span\"],\n",
    "                                                     spans_df[\"token_span\"])\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"original_span\": spans_df[\"token_span\"],\n",
    "    \"bert_token_span\": bert_token_spans,\n",
    "    \"ent_type\": spans_df[\"ent_type\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>16237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id                     span  input_id  token_type_id  \\\n",
       "0           0               [0, 0): ''       101              0   \n",
       "1           1              [0, 1): '-'       118              0   \n",
       "2           2              [1, 2): 'D'       141              0   \n",
       "3           3             [2, 4): 'OC'      9244              0   \n",
       "4           4             [4, 6): 'ST'      9272              0   \n",
       "..        ...                      ...       ...            ...   \n",
       "684       684        [1621, 1622): ','       117              0   \n",
       "685       685       [1623, 1625): 'in'      1107              0   \n",
       "686       686  [1626, 1633): 'Karachi'     16237              0   \n",
       "687       687        [1633, 1634): '.'       119              0   \n",
       "688       688               [0, 0): ''       102              0   \n",
       "\n",
       "     attention_mask  special_tokens_mask ent_iob ent_type  \n",
       "0                 1                 True       O     <NA>  \n",
       "1                 1                False       O     <NA>  \n",
       "2                 1                False       O     <NA>  \n",
       "3                 1                False       O     <NA>  \n",
       "4                 1                False       O     <NA>  \n",
       "..              ...                  ...     ...      ...  \n",
       "684               1                False       O     <NA>  \n",
       "685               1                False       O     <NA>  \n",
       "686               1                False       B      LOC  \n",
       "687               1                False       O     <NA>  \n",
       "688               1                 True       O     <NA>  \n",
       "\n",
       "[689 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate IOB2 tags and entity labels that align with the BERT tokens.\n",
    "# See https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
    "bert_toks_df[[\"ent_iob\", \"ent_type\"]] = tp.spans_to_iob(bert_token_spans, \n",
    "                                                        spans_df[\"ent_type\"])\n",
    "bert_toks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>16237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id                     span  input_id  token_type_id  \\\n",
       "0           0               [0, 0): ''       101              0   \n",
       "1           1              [0, 1): '-'       118              0   \n",
       "2           2              [1, 2): 'D'       141              0   \n",
       "3           3             [2, 4): 'OC'      9244              0   \n",
       "4           4             [4, 6): 'ST'      9272              0   \n",
       "..        ...                      ...       ...            ...   \n",
       "684       684        [1621, 1622): ','       117              0   \n",
       "685       685       [1623, 1625): 'in'      1107              0   \n",
       "686       686  [1626, 1633): 'Karachi'     16237              0   \n",
       "687       687        [1633, 1634): '.'       119              0   \n",
       "688       688               [0, 0): ''       102              0   \n",
       "\n",
       "     attention_mask  special_tokens_mask ent_iob ent_type token_class  \\\n",
       "0                 1                 True       O     <NA>           O   \n",
       "1                 1                False       O     <NA>           O   \n",
       "2                 1                False       O     <NA>           O   \n",
       "3                 1                False       O     <NA>           O   \n",
       "4                 1                False       O     <NA>           O   \n",
       "..              ...                  ...     ...      ...         ...   \n",
       "684               1                False       O     <NA>           O   \n",
       "685               1                False       O     <NA>           O   \n",
       "686               1                False       B      LOC       B-LOC   \n",
       "687               1                False       O     <NA>           O   \n",
       "688               1                 True       O     <NA>           O   \n",
       "\n",
       "     token_class_id  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "..              ...  \n",
       "684               0  \n",
       "685               0  \n",
       "686               1  \n",
       "687               0  \n",
       "688               0  \n",
       "\n",
       "[689 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The traditional way to transform NER to token classification is to \n",
    "# treat each combination of {I,O,B} X {entity type} as a different\n",
    "# class. Generate class labels in that format.\n",
    "classes_df = tp.add_token_classes(bert_toks_df, token_class_dtype)\n",
    "classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show how to compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.30711797e-02 -3.59590203e-01  1.01506817e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.28625670e-01 -4.93136197e-01  1.28423226e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 2.84805615e-02 -1.78742811e-01  1.54320943e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.46517587 -0.2983605   1.0737675  -0.0316486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.07308812e-01 -3.37210178e-01  1.22697961e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.28065705e-01 -2.32442445e-03  6.78131640e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.30534053 -0.526257    0.8281703  -0.2741491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>16237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.04873929 -0.33797333 -0.05835138  0.7557763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.28932782e-03 -2.97430724e-01  7.16174304e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.03023565e-01  3.62538606e-01  7.31493533e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id                     span  input_id  token_type_id  \\\n",
       "0           0               [0, 0): ''       101              0   \n",
       "1           1              [0, 1): '-'       118              0   \n",
       "2           2              [1, 2): 'D'       141              0   \n",
       "3           3             [2, 4): 'OC'      9244              0   \n",
       "4           4             [4, 6): 'ST'      9272              0   \n",
       "..        ...                      ...       ...            ...   \n",
       "684       684        [1621, 1622): ','       117              0   \n",
       "685       685       [1623, 1625): 'in'      1107              0   \n",
       "686       686  [1626, 1633): 'Karachi'     16237              0   \n",
       "687       687        [1633, 1634): '.'       119              0   \n",
       "688       688               [0, 0): ''       102              0   \n",
       "\n",
       "     attention_mask  special_tokens_mask ent_iob ent_type token_class  \\\n",
       "0                 1                 True       O     <NA>           O   \n",
       "1                 1                False       O     <NA>           O   \n",
       "2                 1                False       O     <NA>           O   \n",
       "3                 1                False       O     <NA>           O   \n",
       "4                 1                False       O     <NA>           O   \n",
       "..              ...                  ...     ...      ...         ...   \n",
       "684               1                False       O     <NA>           O   \n",
       "685               1                False       O     <NA>           O   \n",
       "686               1                False       B      LOC       B-LOC   \n",
       "687               1                False       O     <NA>           O   \n",
       "688               1                 True       O     <NA>           O   \n",
       "\n",
       "     token_class_id                                          embedding  \n",
       "0                 0 [-8.30711797e-02 -3.59590203e-01  1.01506817e+0...  \n",
       "1                 0 [-2.28625670e-01 -4.93136197e-01  1.28423226e+0...  \n",
       "2                 0 [ 2.84805615e-02 -1.78742811e-01  1.54320943e+0...  \n",
       "3                 0 [-0.46517587 -0.2983605   1.0737675  -0.0316486...  \n",
       "4                 0 [-1.07308812e-01 -3.37210178e-01  1.22697961e+0...  \n",
       "..              ...                                                ...  \n",
       "684               0 [-1.28065705e-01 -2.32442445e-03  6.78131640e-0...  \n",
       "685               0 [ 0.30534053 -0.526257    0.8281703  -0.2741491...  \n",
       "686               1 [-0.04873929 -0.33797333 -0.05835138  0.7557763...  \n",
       "687               0 [-5.28932782e-03 -2.97430724e-01  7.16174304e-0...  \n",
       "688               0 [-5.03023565e-01  3.62538606e-01  7.31493533e-0...  \n",
       "\n",
       "[689 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adds embeddings to our example dataframe.\n",
    "embeddings_df = tp.add_embeddings(classes_df, bert)\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate BERT tokens and BERT embeddings for the entire corpus\n",
    "\n",
    "Generate BERT embeddings for every token in the entire corpus in one pass, \n",
    "and store those embeddings in a dataframe column (of type TensorType) \n",
    "alongside the tokens and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.30711797e-02 -3.59590203e-01  1.01506817e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.28625670e-01 -4.93136197e-01  1.28423226e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 2.84805615e-02 -1.78742811e-01  1.54320943e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.46517587 -0.2983605   1.0737675  -0.0316486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.07308812e-01 -3.37210178e-01  1.22697961e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>[1621, 1622): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.28065705e-01 -2.32442445e-03  6.78131640e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>685</td>\n",
       "      <td>[1623, 1625): 'in'</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.30534053 -0.526257    0.8281703  -0.2741491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>686</td>\n",
       "      <td>[1626, 1633): 'Karachi'</td>\n",
       "      <td>16237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.04873929 -0.33797333 -0.05835138  0.7557763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>687</td>\n",
       "      <td>[1633, 1634): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.28932782e-03 -2.97430724e-01  7.16174304e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>688</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.03023565e-01  3.62538606e-01  7.31493533e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id                     span  input_id  token_type_id  \\\n",
       "0           0               [0, 0): ''       101              0   \n",
       "1           1              [0, 1): '-'       118              0   \n",
       "2           2              [1, 2): 'D'       141              0   \n",
       "3           3             [2, 4): 'OC'      9244              0   \n",
       "4           4             [4, 6): 'ST'      9272              0   \n",
       "..        ...                      ...       ...            ...   \n",
       "684       684        [1621, 1622): ','       117              0   \n",
       "685       685       [1623, 1625): 'in'      1107              0   \n",
       "686       686  [1626, 1633): 'Karachi'     16237              0   \n",
       "687       687        [1633, 1634): '.'       119              0   \n",
       "688       688               [0, 0): ''       102              0   \n",
       "\n",
       "     attention_mask  special_tokens_mask ent_iob ent_type token_class  \\\n",
       "0                 1                 True       O     <NA>           O   \n",
       "1                 1                False       O     <NA>           O   \n",
       "2                 1                False       O     <NA>           O   \n",
       "3                 1                False       O     <NA>           O   \n",
       "4                 1                False       O     <NA>           O   \n",
       "..              ...                  ...     ...      ...         ...   \n",
       "684               1                False       O     <NA>           O   \n",
       "685               1                False       O     <NA>           O   \n",
       "686               1                False       B      LOC       B-LOC   \n",
       "687               1                False       O     <NA>           O   \n",
       "688               1                 True       O     <NA>           O   \n",
       "\n",
       "     token_class_id                                          embedding  \n",
       "0                 0 [-8.30711797e-02 -3.59590203e-01  1.01506817e+0...  \n",
       "1                 0 [-2.28625670e-01 -4.93136197e-01  1.28423226e+0...  \n",
       "2                 0 [ 2.84805615e-02 -1.78742811e-01  1.54320943e+0...  \n",
       "3                 0 [-0.46517587 -0.2983605   1.0737675  -0.0316486...  \n",
       "4                 0 [-1.07308812e-01 -3.37210178e-01  1.22697961e+0...  \n",
       "..              ...                                                ...  \n",
       "684               0 [-1.28065705e-01 -2.32442445e-03  6.78131640e-0...  \n",
       "685               0 [ 0.30534053 -0.526257    0.8281703  -0.2741491...  \n",
       "686               1 [-0.04873929 -0.33797333 -0.05835138  0.7557763...  \n",
       "687               0 [-5.28932782e-03 -2.97430724e-01  7.16174304e-0...  \n",
       "688               0 [-5.03023565e-01  3.62538606e-01  7.31493533e-0...  \n",
       "\n",
       "[689 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convienence function to combine the previous few cells' operations in a single call.\n",
    "tp.conll_to_bert(example_df, tokenizer, bert, token_class_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 'train'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4498654257a54bbaa697189c402ba753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=946, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 'dev'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea077f632ade4298aceb3ad26a9f777b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=216, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 'test'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161b1ccf50264e03a380042ad3f1506c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=231, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.17669654 -0.39899608  0.9088872   0.2128861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.85537773e-01 -5.02327383e-01  1.17323220e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.17190674e-01 -1.27011672e-01  1.38969100e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.90257567e-01 -2.50433564e-01  1.07450700e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.77328491e-01 -2.61601597e-01  1.07876039e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>2154</td>\n",
       "      <td>[5704, 5705): ')'</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.01539315 -0.04065072  1.0011852   0.0412664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2155</td>\n",
       "      <td>[5706, 5708): '39'</td>\n",
       "      <td>3614</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 7.50392899e-02  1.44007439e-02  1.04323184e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2156</td>\n",
       "      <td>[5708, 5709): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.08579681  0.05905596  1.1146404   0.1048710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2157</td>\n",
       "      <td>[5709, 5711): '93'</td>\n",
       "      <td>5429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.13780675e-02 -2.63872057e-01  8.81803274e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>2158</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 4.85132843e-01  1.57098746e+00  5.92935205e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2159 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      token_id                span  input_id  token_type_id  attention_mask  \\\n",
       "0            0          [0, 0): ''       101              0               1   \n",
       "1            1         [0, 1): '-'       118              0               1   \n",
       "2            2         [1, 2): 'D'       141              0               1   \n",
       "3            3        [2, 4): 'OC'      9244              0               1   \n",
       "4            4        [4, 6): 'ST'      9272              0               1   \n",
       "...        ...                 ...       ...            ...             ...   \n",
       "2154      2154   [5704, 5705): ')'       114              0               1   \n",
       "2155      2155  [5706, 5708): '39'      3614              0               1   \n",
       "2156      2156   [5708, 5709): '.'       119              0               1   \n",
       "2157      2157  [5709, 5711): '93'      5429              0               1   \n",
       "2158      2158          [0, 0): ''       102              0               1   \n",
       "\n",
       "      special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "0                    True       O     <NA>           O               0   \n",
       "1                   False       O     <NA>           O               0   \n",
       "2                   False       O     <NA>           O               0   \n",
       "3                   False       O     <NA>           O               0   \n",
       "4                   False       O     <NA>           O               0   \n",
       "...                   ...     ...      ...         ...             ...   \n",
       "2154                False       O     <NA>           O               0   \n",
       "2155                False       O     <NA>           O               0   \n",
       "2156                False       O     <NA>           O               0   \n",
       "2157                False       O     <NA>           O               0   \n",
       "2158                 True       O     <NA>           O               0   \n",
       "\n",
       "                                              embedding  \n",
       "0    [-0.17669654 -0.39899608  0.9088872   0.2128861...  \n",
       "1    [-3.85537773e-01 -5.02327383e-01  1.17323220e+0...  \n",
       "2    [-1.17190674e-01 -1.27011672e-01  1.38969100e+0...  \n",
       "3    [-3.90257567e-01 -2.50433564e-01  1.07450700e+0...  \n",
       "4    [-2.77328491e-01 -2.61601597e-01  1.07876039e+0...  \n",
       "...                                                 ...  \n",
       "2154 [ 0.01539315 -0.04065072  1.0011852   0.0412664...  \n",
       "2155 [ 7.50392899e-02  1.44007439e-02  1.04323184e+0...  \n",
       "2156 [-0.08579681  0.05905596  1.1146404   0.1048710...  \n",
       "2157 [ 1.13780675e-02 -2.63872057e-01  8.81803274e-0...  \n",
       "2158 [ 4.85132843e-01  1.57098746e+00  5.92935205e-0...  \n",
       "\n",
       "[2159 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the entire corpus through our processing pipeline.\n",
    "bert_toks_by_fold = {}\n",
    "for fold_name in corpus_raw.keys():\n",
    "    print(f\"Processing fold '{fold_name}'...\")\n",
    "    raw = corpus_raw[fold_name]\n",
    "    bert_toks_by_fold[fold_name] = tp.run_with_progress_bar(\n",
    "        len(raw), lambda i: tp.conll_to_bert(raw[i], tokenizer, \n",
    "                                             bert, token_class_dtype))\n",
    "bert_toks_by_fold[\"dev\"][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate the data structures we've generated so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.85053703e-02 -4.05019075e-01  7.42887914e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.70215769e-02 -4.81121272e-01  9.89868402e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2): 'D'</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.82420959e-02 -2.53300011e-01  1.16719234e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 4): 'OC'</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.66830117e-01 -3.10087562e-01  1.00747287e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 6): 'ST'</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.22296937 -0.2130852   0.93310183 -0.2613601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416536</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>314</td>\n",
       "      <td>[1386, 1393): 'brother'</td>\n",
       "      <td>1711</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.81729121e-02 -8.06238949e-02  9.80488896e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416537</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>315</td>\n",
       "      <td>[1393, 1394): ','</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.18173949e-01 -7.00848699e-02  8.65484953e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416538</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>316</td>\n",
       "      <td>[1395, 1400): 'Bobby'</td>\n",
       "      <td>5545</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.56894344e-01  3.14004630e-01  1.57385385e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416539</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>317</td>\n",
       "      <td>[1400, 1401): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.89571261e-01 -2.45812088e-01  6.62573814e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416540</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>318</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.44689187 -0.31665224  0.7796887   0.3699534...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416541 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id                     span  input_id  \\\n",
       "0       train        0         0               [0, 0): ''       101   \n",
       "1       train        0         1              [0, 1): '-'       118   \n",
       "2       train        0         2              [1, 2): 'D'       141   \n",
       "3       train        0         3             [2, 4): 'OC'      9244   \n",
       "4       train        0         4             [4, 6): 'ST'      9272   \n",
       "...       ...      ...       ...                      ...       ...   \n",
       "416536   test      230       314  [1386, 1393): 'brother'      1711   \n",
       "416537   test      230       315        [1393, 1394): ','       117   \n",
       "416538   test      230       316    [1395, 1400): 'Bobby'      5545   \n",
       "416539   test      230       317        [1400, 1401): '.'       119   \n",
       "416540   test      230       318               [0, 0): ''       102   \n",
       "\n",
       "        token_type_id  attention_mask  special_tokens_mask ent_iob ent_type  \\\n",
       "0                   0               1                 True       O     <NA>   \n",
       "1                   0               1                False       O     <NA>   \n",
       "2                   0               1                False       O     <NA>   \n",
       "3                   0               1                False       O     <NA>   \n",
       "4                   0               1                False       O     <NA>   \n",
       "...               ...             ...                  ...     ...      ...   \n",
       "416536              0               1                False       O     <NA>   \n",
       "416537              0               1                False       O     <NA>   \n",
       "416538              0               1                False       B      PER   \n",
       "416539              0               1                False       O     <NA>   \n",
       "416540              0               1                 True       O     <NA>   \n",
       "\n",
       "       token_class  token_class_id  \\\n",
       "0                O               0   \n",
       "1                O               0   \n",
       "2                O               0   \n",
       "3                O               0   \n",
       "4                O               0   \n",
       "...            ...             ...   \n",
       "416536           O               0   \n",
       "416537           O               0   \n",
       "416538       B-PER               4   \n",
       "416539           O               0   \n",
       "416540           O               0   \n",
       "\n",
       "                                                embedding  \n",
       "0      [-9.85053703e-02 -4.05019075e-01  7.42887914e-0...  \n",
       "1      [-5.70215769e-02 -4.81121272e-01  9.89868402e-0...  \n",
       "2      [-4.82420959e-02 -2.53300011e-01  1.16719234e+0...  \n",
       "3      [-2.66830117e-01 -3.10087562e-01  1.00747287e+0...  \n",
       "4      [-0.22296937 -0.2130852   0.93310183 -0.2613601...  \n",
       "...                                                   ...  \n",
       "416536 [-2.81729121e-02 -8.06238949e-02  9.80488896e-0...  \n",
       "416537 [ 1.18173949e-01 -7.00848699e-02  8.65484953e-0...  \n",
       "416538 [-3.56894344e-01  3.14004630e-01  1.57385385e+0...  \n",
       "416539 [-1.89571261e-01 -2.45812088e-01  6.62573814e-0...  \n",
       "416540 [-0.44689187 -0.31665224  0.7796887   0.3699534...  \n",
       "\n",
       "[416541 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single dataframe with the entire corpus's embeddings.\n",
    "corpus_df = tp.combine_folds(bert_toks_by_fold)\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "With the TensorArray from Text Extension for Pandas, the computed embeddings can be persisted as a tensor along with the rest of the DataFrame using standard Pandas input/output methods. Since this is a costly operation and the embeddings are deterministic, it can save lots of time to checkpoint the data here and save the results to disk. This will allow us to continue working with model training without needing to re-compute the BERT embeddings again.\n",
    " \n",
    " ## Save DataFrame with Embeddings Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the tokenized corpus with embeddings to a Feather file.\n",
    "# We can't currently serialize span columns that cover multiple documents (see issue 73),\n",
    "# so drop span columns from the contents we write to the Feather file.\n",
    "cols_to_drop = [c for c in corpus_df.columns if \"span\" in c]\n",
    "corpus_df.drop(columns=cols_to_drop).to_feather(\"outputs/corpus.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame with Previously Computed Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.85053703e-02 -4.05019075e-01  7.42887914e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.70215769e-02 -4.81121272e-01  9.89868402e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.82420959e-02 -2.53300011e-01  1.16719234e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.66830117e-01 -3.10087562e-01  1.00747287e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.22296937 -0.2130852   0.93310183 -0.2613601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416536</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>314</td>\n",
       "      <td>1711</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.81729121e-02 -8.06238949e-02  9.80488896e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416537</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>315</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.18173949e-01 -7.00848699e-02  8.65484953e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416538</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>316</td>\n",
       "      <td>5545</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PER</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>4</td>\n",
       "      <td>[-3.56894344e-01  3.14004630e-01  1.57385385e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416539</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>317</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.89571261e-01 -2.45812088e-01  6.62573814e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416540</th>\n",
       "      <td>test</td>\n",
       "      <td>230</td>\n",
       "      <td>318</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.44689187 -0.31665224  0.7796887   0.3699534...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416541 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "0       train        0         0       101              0               1   \n",
       "1       train        0         1       118              0               1   \n",
       "2       train        0         2       141              0               1   \n",
       "3       train        0         3      9244              0               1   \n",
       "4       train        0         4      9272              0               1   \n",
       "...       ...      ...       ...       ...            ...             ...   \n",
       "416536   test      230       314      1711              0               1   \n",
       "416537   test      230       315       117              0               1   \n",
       "416538   test      230       316      5545              0               1   \n",
       "416539   test      230       317       119              0               1   \n",
       "416540   test      230       318       102              0               1   \n",
       "\n",
       "        special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "0                      True       O     <NA>           O               0   \n",
       "1                     False       O     <NA>           O               0   \n",
       "2                     False       O     <NA>           O               0   \n",
       "3                     False       O     <NA>           O               0   \n",
       "4                     False       O     <NA>           O               0   \n",
       "...                     ...     ...      ...         ...             ...   \n",
       "416536                False       O     <NA>           O               0   \n",
       "416537                False       O     <NA>           O               0   \n",
       "416538                False       B      PER       B-PER               4   \n",
       "416539                False       O     <NA>           O               0   \n",
       "416540                 True       O     <NA>           O               0   \n",
       "\n",
       "                                                embedding  \n",
       "0      [-9.85053703e-02 -4.05019075e-01  7.42887914e-0...  \n",
       "1      [-5.70215769e-02 -4.81121272e-01  9.89868402e-0...  \n",
       "2      [-4.82420959e-02 -2.53300011e-01  1.16719234e+0...  \n",
       "3      [-2.66830117e-01 -3.10087562e-01  1.00747287e+0...  \n",
       "4      [-0.22296937 -0.2130852   0.93310183 -0.2613601...  \n",
       "...                                                   ...  \n",
       "416536 [-2.81729121e-02 -8.06238949e-02  9.80488896e-0...  \n",
       "416537 [ 1.18173949e-01 -7.00848699e-02  8.65484953e-0...  \n",
       "416538 [-3.56894344e-01  3.14004630e-01  1.57385385e+0...  \n",
       "416539 [-1.89571261e-01 -2.45812088e-01  6.62573814e-0...  \n",
       "416540 [-0.44689187 -0.31665224  0.7796887   0.3699534...  \n",
       "\n",
       "[416541 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the serialized embeddings back in so that you can rerun the model \n",
    "# training parts of this notebook (the cells from here onward) without \n",
    "# regenerating the embeddings.\n",
    "corpus_df = pd.read_feather(\"outputs/corpus.feather\")\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on the BERT embeddings\n",
    "\n",
    "Now we will use the loaded BERT embeddings to train a multinomial model to predict the token class from the embeddings tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional initialization boilerplate\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.85053703e-02 -4.05019075e-01  7.42887914e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.70215769e-02 -4.81121272e-01  9.89868402e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.82420959e-02 -2.53300011e-01  1.16719234e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.66830117e-01 -3.10087562e-01  1.00747287e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.22296937 -0.2130852   0.93310183 -0.2613601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281104</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>53</td>\n",
       "      <td>17057</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 7.55636692e-01 -9.18912172e-01 -1.40303954e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281105</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>54</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.15284957e-01 -4.44919914e-01  4.71556604e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281106</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>55</td>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 4.56021696e-01 -8.97085190e-01  6.78616092e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281107</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>56</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.97137520e-01 -5.42719424e-01  2.94020921e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281108</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>57</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.76507807e-01 -4.21606839e-01  9.94703531e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281109 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "0       train        0         0       101              0               1   \n",
       "1       train        0         1       118              0               1   \n",
       "2       train        0         2       141              0               1   \n",
       "3       train        0         3      9244              0               1   \n",
       "4       train        0         4      9272              0               1   \n",
       "...       ...      ...       ...       ...            ...             ...   \n",
       "281104  train      945        53     17057              0               1   \n",
       "281105  train      945        54       122              0               1   \n",
       "281106  train      945        55      4617              0               1   \n",
       "281107  train      945        56       123              0               1   \n",
       "281108  train      945        57       102              0               1   \n",
       "\n",
       "        special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "0                      True       O     <NA>           O               0   \n",
       "1                     False       O     <NA>           O               0   \n",
       "2                     False       O     <NA>           O               0   \n",
       "3                     False       O     <NA>           O               0   \n",
       "4                     False       O     <NA>           O               0   \n",
       "...                     ...     ...      ...         ...             ...   \n",
       "281104                False       B      ORG       B-ORG               3   \n",
       "281105                False       O     <NA>           O               0   \n",
       "281106                False       B      ORG       B-ORG               3   \n",
       "281107                False       O     <NA>           O               0   \n",
       "281108                 True       O     <NA>           O               0   \n",
       "\n",
       "                                                embedding  \n",
       "0      [-9.85053703e-02 -4.05019075e-01  7.42887914e-0...  \n",
       "1      [-5.70215769e-02 -4.81121272e-01  9.89868402e-0...  \n",
       "2      [-4.82420959e-02 -2.53300011e-01  1.16719234e+0...  \n",
       "3      [-2.66830117e-01 -3.10087562e-01  1.00747287e+0...  \n",
       "4      [-0.22296937 -0.2130852   0.93310183 -0.2613601...  \n",
       "...                                                   ...  \n",
       "281104 [ 7.55636692e-01 -9.18912172e-01 -1.40303954e-0...  \n",
       "281105 [-1.15284957e-01 -4.44919914e-01  4.71556604e-0...  \n",
       "281106 [ 4.56021696e-01 -8.97085190e-01  6.78616092e-0...  \n",
       "281107 [-1.97137520e-01 -5.42719424e-01  2.94020921e-0...  \n",
       "281108 [-5.76507807e-01 -4.21606839e-01  9.94703531e-0...  \n",
       "\n",
       "[281109 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = corpus_df[corpus_df[\"fold\"] == \"train\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 17.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('mlogreg',\n",
       "                 LogisticRegression(max_iter=10000, multi_class='multinomial',\n",
       "                                    verbose=10))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a multinomial logistic regression model on the training set.\n",
    "_MULTI_CLASS = \"multinomial\"\n",
    "base_pipeline = sklearn.pipeline.Pipeline([\n",
    "    # Standard scaler. This only makes a difference for certain classes\n",
    "    # of embeddings.\n",
    "    #(\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"mlogreg\", sklearn.linear_model.LogisticRegression(\n",
    "        multi_class=_MULTI_CLASS,\n",
    "        verbose=10,\n",
    "        max_iter=LBGFS_ITERATIONS\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train = train_df[\"embedding\"].values\n",
    "Y_train = train_df[\"token_class_id\"]\n",
    "base_model = base_pipeline.fit(X_train, Y_train)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - nicer display of tensor float values?\n",
    "#import sys\n",
    "#np.set_printoptions(precision=4, suppress=True, floatmode=\"fixed\", linewidth=100, threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will let us make predictions on a fold of the corpus\n",
    "def predict_on_df(df: pd.DataFrame, id_to_class: Dict[int, str], predictor):\n",
    "    \"\"\"\n",
    "    Run a trained model on a DataFrame of tokens with embeddings.\n",
    "\n",
    "    :param df: DataFrame of tokens for a document, containing a TokenSpan column\n",
    "     called \"embedding\" for each token.\n",
    "    :param id_to_class: Mapping from class ID to class name, as returned by\n",
    "     :func:`text_extensions_for_pandas.make_iob_tag_categories`\n",
    "    :param predictor: Python object with a `predict_proba` method that accepts\n",
    "     a numpy array of embeddings.\n",
    "    :returns: A copy of `df`, with the following additional columns:\n",
    "     `predicted_id`, `predicted_class`, `predicted_iob`, `predicted_type`\n",
    "     and `predicted_class_pr`.\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    class_pr = tp.TensorArray(predictor.predict_proba(result_df[\"embedding\"]))\n",
    "    result_df[\"predicted_id\"] = np.argmax(class_pr, axis=1)\n",
    "    result_df[\"predicted_class\"] = [id_to_class[i]\n",
    "                                    for i in result_df[\"predicted_id\"].values]\n",
    "    iobs, types = tp.decode_class_labels(result_df[\"predicted_class\"].values)\n",
    "    result_df[\"predicted_iob\"] = iobs\n",
    "    result_df[\"predicted_type\"] = types\n",
    "    result_df[\"predicted_class_pr\"] = class_pr\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>predicted_iob</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>predicted_class_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.85053703e-02 -4.05019075e-01  7.42887914e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99162793e-01 7.28614070e-06 3.68106932e-04 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.70215769e-02 -4.81121272e-01  9.89868402e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.98624017e-01 1.17727804e-06 2.30890326e-05 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.82420959e-02 -2.53300011e-01  1.16719234e+0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99822159e-01 2.92875927e-06 4.63864656e-05 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-2.66830117e-01 -3.10087562e-01  1.00747287e+0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99746151e-01 7.32364501e-09 1.02976297e-05 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.22296937 -0.2130852   0.93310183 -0.2613601...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99962561e-01 3.31572805e-10 3.60350074e-07 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281104</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>53</td>\n",
       "      <td>17057</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 7.55636692e-01 -9.18912172e-01 -1.40303954e-0...</td>\n",
       "      <td>3</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[3.28689827e-07 1.31715175e-09 5.09700063e-09 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281105</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>54</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.15284957e-01 -4.44919914e-01  4.71556604e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99998076e-01 6.02579816e-11 1.43360960e-10 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281106</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>55</td>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>[ 4.56021696e-01 -8.97085190e-01  6.78616092e-0...</td>\n",
       "      <td>3</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[1.80262724e-07 4.99876003e-10 2.15961101e-08 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281107</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>56</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.97137520e-01 -5.42719424e-01  2.94020921e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99999401e-01 2.85864619e-11 4.76410155e-11 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281108</th>\n",
       "      <td>train</td>\n",
       "      <td>945</td>\n",
       "      <td>57</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.76507807e-01 -4.21606839e-01  9.94703531e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99996300e-01 1.40033531e-11 2.56121148e-12 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281109 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "0       train        0         0       101              0               1   \n",
       "1       train        0         1       118              0               1   \n",
       "2       train        0         2       141              0               1   \n",
       "3       train        0         3      9244              0               1   \n",
       "4       train        0         4      9272              0               1   \n",
       "...       ...      ...       ...       ...            ...             ...   \n",
       "281104  train      945        53     17057              0               1   \n",
       "281105  train      945        54       122              0               1   \n",
       "281106  train      945        55      4617              0               1   \n",
       "281107  train      945        56       123              0               1   \n",
       "281108  train      945        57       102              0               1   \n",
       "\n",
       "        special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "0                      True       O     <NA>           O               0   \n",
       "1                     False       O     <NA>           O               0   \n",
       "2                     False       O     <NA>           O               0   \n",
       "3                     False       O     <NA>           O               0   \n",
       "4                     False       O     <NA>           O               0   \n",
       "...                     ...     ...      ...         ...             ...   \n",
       "281104                False       B      ORG       B-ORG               3   \n",
       "281105                False       O     <NA>           O               0   \n",
       "281106                False       B      ORG       B-ORG               3   \n",
       "281107                False       O     <NA>           O               0   \n",
       "281108                 True       O     <NA>           O               0   \n",
       "\n",
       "                                                embedding  predicted_id  \\\n",
       "0      [-9.85053703e-02 -4.05019075e-01  7.42887914e-0...             0   \n",
       "1      [-5.70215769e-02 -4.81121272e-01  9.89868402e-0...             0   \n",
       "2      [-4.82420959e-02 -2.53300011e-01  1.16719234e+0...             0   \n",
       "3      [-2.66830117e-01 -3.10087562e-01  1.00747287e+0...             0   \n",
       "4      [-0.22296937 -0.2130852   0.93310183 -0.2613601...             0   \n",
       "...                                                   ...           ...   \n",
       "281104 [ 7.55636692e-01 -9.18912172e-01 -1.40303954e-0...             3   \n",
       "281105 [-1.15284957e-01 -4.44919914e-01  4.71556604e-0...             0   \n",
       "281106 [ 4.56021696e-01 -8.97085190e-01  6.78616092e-0...             3   \n",
       "281107 [-1.97137520e-01 -5.42719424e-01  2.94020921e-0...             0   \n",
       "281108 [-5.76507807e-01 -4.21606839e-01  9.94703531e-0...             0   \n",
       "\n",
       "       predicted_class predicted_iob predicted_type  \\\n",
       "0                    O             O           None   \n",
       "1                    O             O           None   \n",
       "2                    O             O           None   \n",
       "3                    O             O           None   \n",
       "4                    O             O           None   \n",
       "...                ...           ...            ...   \n",
       "281104           B-ORG             B            ORG   \n",
       "281105               O             O           None   \n",
       "281106           B-ORG             B            ORG   \n",
       "281107               O             O           None   \n",
       "281108               O             O           None   \n",
       "\n",
       "                                       predicted_class_pr  \n",
       "0      [9.99162793e-01 7.28614070e-06 3.68106932e-04 1...  \n",
       "1      [9.98624017e-01 1.17727804e-06 2.30890326e-05 6...  \n",
       "2      [9.99822159e-01 2.92875927e-06 4.63864656e-05 9...  \n",
       "3      [9.99746151e-01 7.32364501e-09 1.02976297e-05 1...  \n",
       "4      [9.99962561e-01 3.31572805e-10 3.60350074e-07 4...  \n",
       "...                                                   ...  \n",
       "281104 [3.28689827e-07 1.31715175e-09 5.09700063e-09 9...  \n",
       "281105 [9.99998076e-01 6.02579816e-11 1.43360960e-10 5...  \n",
       "281106 [1.80262724e-07 4.99876003e-10 2.15961101e-08 9...  \n",
       "281107 [9.99999401e-01 2.85864619e-11 4.76410155e-11 3...  \n",
       "281108 [9.99996300e-01 1.40033531e-11 2.56121148e-12 4...  \n",
       "\n",
       "[281109 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results_df = predict_on_df(train_df, int_to_label, base_model)\n",
    "train_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>predicted_iob</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>predicted_class_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351041</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>8</td>\n",
       "      <td>[-2.10291892e-01 -8.53567719e-01  2.75510421e-0...</td>\n",
       "      <td>6</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>I</td>\n",
       "      <td>MISC</td>\n",
       "      <td>[1.98323229e-07 1.53130728e-10 2.78405342e-07 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351042</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>8</td>\n",
       "      <td>[-2.32054338e-01 -9.29077148e-01  3.88911217e-0...</td>\n",
       "      <td>6</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>I</td>\n",
       "      <td>MISC</td>\n",
       "      <td>[3.10633651e-05 5.22947228e-06 6.52603219e-11 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351043</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>8</td>\n",
       "      <td>[ 0.36844087 -0.68091148 -0.10591034 -0.3448123...</td>\n",
       "      <td>8</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>[2.00370294e-03 1.00450102e-01 6.38725156e-06 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351044</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>8</td>\n",
       "      <td>[-3.01310837e-01 -6.54601932e-01 -1.72691718e-0...</td>\n",
       "      <td>8</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>[1.12122699e-04 3.13711716e-06 1.53931420e-07 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351045</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>8</td>\n",
       "      <td>[-1.61161020e-01 -6.98910296e-01  2.34246060e-0...</td>\n",
       "      <td>5</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[7.02232647e-03 3.18677296e-03 7.76558124e-08 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351046</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>18589</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>[-5.85671440e-02 -7.95588315e-01  3.36059839e-0...</td>\n",
       "      <td>1</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[6.36387711e-03 9.02478479e-01 2.26270005e-06 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351047</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[ 2.03760266e-01 -7.37309694e-01 -8.88528451e-0...</td>\n",
       "      <td>5</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[2.00492628e-01 5.12452116e-05 1.72780996e-07 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351048</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>19016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-1.03412405e-01 -3.36818755e-01  1.73846602e-0...</td>\n",
       "      <td>1</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[3.35755616e-02 5.33375311e-01 1.00517707e-07 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351049</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-4.05427039e-01 -6.51651978e-01  2.46960565e-0...</td>\n",
       "      <td>5</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[3.03682213e-04 1.33970366e-04 1.83506170e-08 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351050</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.68292239e-01 -6.47586107e-01  8.14902484e-0...</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[9.99999663e-01 3.75752227e-08 1.14784193e-09 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "351041  test        0        40      3309              0               1   \n",
       "351042  test        0        41      1306              0               1   \n",
       "351043  test        0        42      2001              0               1   \n",
       "351044  test        0        43      1181              0               1   \n",
       "351045  test        0        44      2293              0               1   \n",
       "351046  test        0        45     18589              0               1   \n",
       "351047  test        0        46       118              0               1   \n",
       "351048  test        0        47     19016              0               1   \n",
       "351049  test        0        48      2249              0               1   \n",
       "351050  test        0        49       117              0               1   \n",
       "\n",
       "        special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "351041                False       I      PER       I-PER               8   \n",
       "351042                False       I      PER       I-PER               8   \n",
       "351043                False       I      PER       I-PER               8   \n",
       "351044                False       I      PER       I-PER               8   \n",
       "351045                False       I      PER       I-PER               8   \n",
       "351046                False       B      LOC       B-LOC               1   \n",
       "351047                False       I      LOC       I-LOC               5   \n",
       "351048                False       I      LOC       I-LOC               5   \n",
       "351049                False       I      LOC       I-LOC               5   \n",
       "351050                False       O     <NA>           O               0   \n",
       "\n",
       "                                                embedding  predicted_id  \\\n",
       "351041 [-2.10291892e-01 -8.53567719e-01  2.75510421e-0...             6   \n",
       "351042 [-2.32054338e-01 -9.29077148e-01  3.88911217e-0...             6   \n",
       "351043 [ 0.36844087 -0.68091148 -0.10591034 -0.3448123...             8   \n",
       "351044 [-3.01310837e-01 -6.54601932e-01 -1.72691718e-0...             8   \n",
       "351045 [-1.61161020e-01 -6.98910296e-01  2.34246060e-0...             5   \n",
       "351046 [-5.85671440e-02 -7.95588315e-01  3.36059839e-0...             1   \n",
       "351047 [ 2.03760266e-01 -7.37309694e-01 -8.88528451e-0...             5   \n",
       "351048 [-1.03412405e-01 -3.36818755e-01  1.73846602e-0...             1   \n",
       "351049 [-4.05427039e-01 -6.51651978e-01  2.46960565e-0...             5   \n",
       "351050 [-1.68292239e-01 -6.47586107e-01  8.14902484e-0...             0   \n",
       "\n",
       "       predicted_class predicted_iob predicted_type  \\\n",
       "351041          I-MISC             I           MISC   \n",
       "351042          I-MISC             I           MISC   \n",
       "351043           I-PER             I            PER   \n",
       "351044           I-PER             I            PER   \n",
       "351045           I-LOC             I            LOC   \n",
       "351046           B-LOC             B            LOC   \n",
       "351047           I-LOC             I            LOC   \n",
       "351048           B-LOC             B            LOC   \n",
       "351049           I-LOC             I            LOC   \n",
       "351050               O             O           None   \n",
       "\n",
       "                                       predicted_class_pr  \n",
       "351041 [1.98323229e-07 1.53130728e-10 2.78405342e-07 2...  \n",
       "351042 [3.10633651e-05 5.22947228e-06 6.52603219e-11 5...  \n",
       "351043 [2.00370294e-03 1.00450102e-01 6.38725156e-06 1...  \n",
       "351044 [1.12122699e-04 3.13711716e-06 1.53931420e-07 4...  \n",
       "351045 [7.02232647e-03 3.18677296e-03 7.76558124e-08 6...  \n",
       "351046 [6.36387711e-03 9.02478479e-01 2.26270005e-06 4...  \n",
       "351047 [2.00492628e-01 5.12452116e-05 1.72780996e-07 8...  \n",
       "351048 [3.35755616e-02 5.33375311e-01 1.00517707e-07 9...  \n",
       "351049 [3.03682213e-04 1.33970366e-04 1.83506170e-08 1...  \n",
       "351050 [9.99999663e-01 3.75752227e-08 1.14784193e-09 1...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at results on the test set\n",
    "test_results_df = predict_on_df(corpus_df[corpus_df[\"fold\"] == \"test\"], \n",
    "                                     int_to_label, base_model)\n",
    "# Take a slice to show a region with more entities\n",
    "test_results_df.iloc[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>token_class</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>class_max_pr</th>\n",
       "      <th>predicted_class_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414699</th>\n",
       "      <td>222</td>\n",
       "      <td>371</td>\n",
       "      <td>O</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>0.238123</td>\n",
       "      <td>[0.08202944 0.00349575 0.23812346 0.14204107 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390307</th>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>0.291589</td>\n",
       "      <td>[2.62719988e-01 2.38731092e-01 2.91588782e-01 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367670</th>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.294557</td>\n",
       "      <td>[1.76412153e-01 3.86455931e-07 4.47598135e-07 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363788</th>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.309699</td>\n",
       "      <td>[3.09698791e-01 1.89220263e-05 4.49656243e-05 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411548</th>\n",
       "      <td>213</td>\n",
       "      <td>14</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.317874</td>\n",
       "      <td>[2.89094277e-01 3.86128605e-05 1.78886350e-04 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385606</th>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-MISC</td>\n",
       "      <td>0.327414</td>\n",
       "      <td>[2.28951121e-01 2.04707195e-06 3.27413638e-01 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358565</th>\n",
       "      <td>23</td>\n",
       "      <td>387</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.327566</td>\n",
       "      <td>[2.80056412e-01 1.09979216e-01 9.60765376e-02 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358426</th>\n",
       "      <td>23</td>\n",
       "      <td>248</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.347311</td>\n",
       "      <td>[1.80356203e-02 1.90402981e-03 3.16516185e-02 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364233</th>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.348541</td>\n",
       "      <td>[1.22118924e-03 3.17763625e-05 1.27397341e-05 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386205</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.350508</td>\n",
       "      <td>[3.24629125e-01 2.88704564e-05 1.68123889e-05 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358450</th>\n",
       "      <td>23</td>\n",
       "      <td>272</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.351102</td>\n",
       "      <td>[8.63139036e-02 5.52905711e-04 5.72049257e-03 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412404</th>\n",
       "      <td>216</td>\n",
       "      <td>17</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.359214</td>\n",
       "      <td>[3.10488030e-01 1.26875670e-07 2.63789058e-08 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416251</th>\n",
       "      <td>230</td>\n",
       "      <td>29</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>[2.88083282e-01 1.36639110e-06 4.85029114e-08 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363895</th>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.361754</td>\n",
       "      <td>[2.13445946e-01 4.74910606e-07 2.49798073e-06 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358569</th>\n",
       "      <td>23</td>\n",
       "      <td>391</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.365688</td>\n",
       "      <td>[3.10879823e-01 2.03345842e-05 4.74213364e-05 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414800</th>\n",
       "      <td>222</td>\n",
       "      <td>472</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.368855</td>\n",
       "      <td>[2.84349533e-01 7.96580580e-07 8.77423986e-05 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359866</th>\n",
       "      <td>26</td>\n",
       "      <td>509</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.369956</td>\n",
       "      <td>[2.70727857e-01 1.18119840e-03 9.09545542e-03 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404303</th>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>O</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.371122</td>\n",
       "      <td>[2.72015797e-03 5.62325845e-08 3.46505311e-11 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411834</th>\n",
       "      <td>214</td>\n",
       "      <td>36</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>0.371229</td>\n",
       "      <td>[1.75226722e-01 9.06714172e-02 2.39299287e-04 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414510</th>\n",
       "      <td>222</td>\n",
       "      <td>182</td>\n",
       "      <td>O</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>[1.84664794e-01 1.05512389e-04 4.56295128e-05 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc_num  token_id token_class predicted_class  class_max_pr  \\\n",
       "414699      222       371           O          B-MISC      0.238123   \n",
       "390307      133         8       B-LOC          B-MISC      0.291589   \n",
       "367670       54        49       I-ORG           I-ORG      0.294557   \n",
       "363788       42        28           O               O      0.309699   \n",
       "411548      213        14      I-MISC           I-LOC      0.317874   \n",
       "385606      114        10       I-LOC          B-MISC      0.327414   \n",
       "358565       23       387       B-ORG           B-ORG      0.327566   \n",
       "358426       23       248       I-ORG          I-MISC      0.347311   \n",
       "364233       44        20       I-ORG           I-PER      0.348541   \n",
       "386205      116       116           O           I-PER      0.350508   \n",
       "358450       23       272           O           I-LOC      0.351102   \n",
       "412404      216        17      I-MISC           I-PER      0.359214   \n",
       "416251      230        29           O           I-LOC      0.359878   \n",
       "363895       43        18       I-PER           I-ORG      0.361754   \n",
       "358569       23       391       I-ORG           I-ORG      0.365688   \n",
       "414800      222       472       I-ORG           I-PER      0.368855   \n",
       "359866       26       509       I-ORG           I-LOC      0.369956   \n",
       "404303      188        10           O          I-MISC      0.371122   \n",
       "411834      214        36       I-LOC           B-PER      0.371229   \n",
       "414510      222       182           O           I-PER      0.371584   \n",
       "\n",
       "                                       predicted_class_pr  \n",
       "414699 [0.08202944 0.00349575 0.23812346 0.14204107 0....  \n",
       "390307 [2.62719988e-01 2.38731092e-01 2.91588782e-01 3...  \n",
       "367670 [1.76412153e-01 3.86455931e-07 4.47598135e-07 7...  \n",
       "363788 [3.09698791e-01 1.89220263e-05 4.49656243e-05 5...  \n",
       "411548 [2.89094277e-01 3.86128605e-05 1.78886350e-04 3...  \n",
       "385606 [2.28951121e-01 2.04707195e-06 3.27413638e-01 1...  \n",
       "358565 [2.80056412e-01 1.09979216e-01 9.60765376e-02 3...  \n",
       "358426 [1.80356203e-02 1.90402981e-03 3.16516185e-02 2...  \n",
       "364233 [1.22118924e-03 3.17763625e-05 1.27397341e-05 4...  \n",
       "386205 [3.24629125e-01 2.88704564e-05 1.68123889e-05 8...  \n",
       "358450 [8.63139036e-02 5.52905711e-04 5.72049257e-03 2...  \n",
       "412404 [3.10488030e-01 1.26875670e-07 2.63789058e-08 7...  \n",
       "416251 [2.88083282e-01 1.36639110e-06 4.85029114e-08 1...  \n",
       "363895 [2.13445946e-01 4.74910606e-07 2.49798073e-06 5...  \n",
       "358569 [3.10879823e-01 2.03345842e-05 4.74213364e-05 3...  \n",
       "414800 [2.84349533e-01 7.96580580e-07 8.77423986e-05 3...  \n",
       "359866 [2.70727857e-01 1.18119840e-03 9.09545542e-03 3...  \n",
       "404303 [2.72015797e-03 5.62325845e-08 3.46505311e-11 2...  \n",
       "411834 [1.75226722e-01 9.06714172e-02 2.39299287e-04 8...  \n",
       "414510 [1.84664794e-01 1.05512389e-04 4.56295128e-05 6...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the predictions that had the lowest probability to see what the model did not predict strongly\n",
    "# We can easily mix numpy functions on the TensorArray with standard Pandas on the entire DataFrame\n",
    "# Here we find the max probability for each prediction, then sort the DataFrame by that value ascending\n",
    "test_results_df[\"class_max_pr\"] = np.max(test_results_df[\"predicted_class_pr\"].array, axis=1)\n",
    "pr_asc_df = test_results_df.sort_values(by=\"class_max_pr\")\n",
    "\n",
    "# Select relevant columns and show lowest 20 predictions\n",
    "pr_asc_df[[\"doc_num\", \"token_id\", \"token_class\", \"predicted_class\", \"class_max_pr\", \"predicted_class_pr\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23     11\n",
       "27     10\n",
       "222     6\n",
       "220     5\n",
       "133     3\n",
       "Name: doc_num, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a closer look at the most predictions with the lowest probability and see if there is a document that had the most difficulties\n",
    "lowest_pr_df = pr_asc_df[[\"doc_num\", \"token_id\", \"input_id\", \"predicted_class\", \"class_max_pr\"]].head(100)\n",
    "lowest_pr_df[\"doc_num\"].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[11, 14): 'NHL'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[61, 69): 'NEW YORK'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[94, 109): 'National Hockey'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[110, 116): 'League'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[276, 284): 'HARTFORD'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[301, 308): 'BUFFALO'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[326, 332): 'BOSTON'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[350, 358): 'MONTREAL'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[377, 387): 'PITTSBURGH'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[404, 410): 'OTTAWA'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[427, 435): 'ATLANTIC'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[461, 468): 'FLORIDA'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[485, 497): 'PHILADELPHIA'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[515, 525): 'NEW JERSEY'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[543, 553): 'WASHINGTON'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[571, 581): 'NY RANGERS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[599, 611): 'NY ISLANDERS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[628, 637): 'TAMPA BAY'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[673, 689): 'CENTRAL DIVISION'</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[706, 713): 'DETROIT'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[730, 736): 'DALLAS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[753, 760): 'CHICAGO'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[778, 786): 'ST LOUIS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[804, 811): 'TORONTO'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[829, 836): 'PHOENIX'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[853, 860): 'PACIFIC'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[886, 894): 'COLORADO'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[911, 920): 'VANCOUVER'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[938, 946): 'EDMONTON'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[964, 975): 'LOS ANGELES'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[993, 1001): 'SAN JOSE'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[1019, 1026): 'CALGARY'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[1044, 1051): 'ANAHEIM'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[1087, 1094): 'ANAHEIM'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[1098, 1105): 'BUFFALO'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1106, 1113): 'TORONTO'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[1117, 1127): 'NY RANGERS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[1128, 1138): 'PITTSBURGH'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1142, 1152): 'WASHINGTON'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[1153, 1161): 'MONTREAL'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[1165, 1172): 'CHICAGO'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[1173, 1185): 'PHILADELPHIA'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[1189, 1195): 'DALLAS'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[1196, 1204): 'ST LOUIS'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[1208, 1216): 'COLORADO'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[1217, 1223): 'OTTAWA'</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[1227, 1235): 'EDMONTON'</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              span ent_type\n",
       "0                  [11, 14): 'NHL'      ORG\n",
       "1             [61, 69): 'NEW YORK'      LOC\n",
       "2     [94, 109): 'National Hockey'      ORG\n",
       "3             [110, 116): 'League'      ORG\n",
       "4           [276, 284): 'HARTFORD'      ORG\n",
       "5            [301, 308): 'BUFFALO'      ORG\n",
       "6             [326, 332): 'BOSTON'      ORG\n",
       "7           [350, 358): 'MONTREAL'      ORG\n",
       "8         [377, 387): 'PITTSBURGH'      ORG\n",
       "9             [404, 410): 'OTTAWA'      ORG\n",
       "10          [427, 435): 'ATLANTIC'      LOC\n",
       "11           [461, 468): 'FLORIDA'      ORG\n",
       "12      [485, 497): 'PHILADELPHIA'      ORG\n",
       "13        [515, 525): 'NEW JERSEY'      ORG\n",
       "14        [543, 553): 'WASHINGTON'      ORG\n",
       "15        [571, 581): 'NY RANGERS'      ORG\n",
       "16      [599, 611): 'NY ISLANDERS'      ORG\n",
       "17         [628, 637): 'TAMPA BAY'      ORG\n",
       "18  [673, 689): 'CENTRAL DIVISION'     MISC\n",
       "19           [706, 713): 'DETROIT'      ORG\n",
       "20            [730, 736): 'DALLAS'      ORG\n",
       "21           [753, 760): 'CHICAGO'      ORG\n",
       "22          [778, 786): 'ST LOUIS'      ORG\n",
       "23           [804, 811): 'TORONTO'      ORG\n",
       "24           [829, 836): 'PHOENIX'      ORG\n",
       "25           [853, 860): 'PACIFIC'      LOC\n",
       "26          [886, 894): 'COLORADO'      ORG\n",
       "27         [911, 920): 'VANCOUVER'      ORG\n",
       "28          [938, 946): 'EDMONTON'      ORG\n",
       "29       [964, 975): 'LOS ANGELES'      ORG\n",
       "30         [993, 1001): 'SAN JOSE'      ORG\n",
       "31         [1019, 1026): 'CALGARY'      ORG\n",
       "32         [1044, 1051): 'ANAHEIM'      ORG\n",
       "33         [1087, 1094): 'ANAHEIM'      ORG\n",
       "34         [1098, 1105): 'BUFFALO'      LOC\n",
       "35         [1106, 1113): 'TORONTO'      ORG\n",
       "36      [1117, 1127): 'NY RANGERS'      ORG\n",
       "37      [1128, 1138): 'PITTSBURGH'      ORG\n",
       "38      [1142, 1152): 'WASHINGTON'      LOC\n",
       "39        [1153, 1161): 'MONTREAL'      ORG\n",
       "40         [1165, 1172): 'CHICAGO'      LOC\n",
       "41    [1173, 1185): 'PHILADELPHIA'      ORG\n",
       "42          [1189, 1195): 'DALLAS'      LOC\n",
       "43        [1196, 1204): 'ST LOUIS'      ORG\n",
       "44        [1208, 1216): 'COLORADO'      LOC\n",
       "45          [1217, 1223): 'OTTAWA'      ORG\n",
       "46        [1227, 1235): 'EDMONTON'      LOC"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like document 23 of the test set had the most weak predictions, let's take a look at this document and see which spans caused this\n",
    "# TODO - want to show the span with predictions with this document\n",
    "all_spans = {\n",
    "    k: [tp.iob_to_spans(df) for df in v] for k, v in corpus_raw.items()\n",
    "}\n",
    "fold = \"test\"\n",
    "doc_offset = 23\n",
    "doc_df = all_spans[fold][doc_offset]\n",
    "doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = corpus_df[corpus_df[\"fold\"] == \"test\"]\n",
    "doc_23 = corpus_test[corpus_test[\"doc_num\"] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358178</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.93204927e-01 -7.20973670e-01  6.35356426e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358179</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.59361285e-01 -7.75034666e-01  1.00733566e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358180</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.3389236  -0.59117919  1.06589043  0.2252248...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358181</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>9244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.98726809e-01 -7.89630830e-01  7.54339695e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358182</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>9272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-4.12817359e-01 -6.46852911e-01  8.24099600e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358718</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>540</td>\n",
       "      <td>20002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-3.68024737e-01 -3.88864905e-01 -1.79580003e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358719</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>541</td>\n",
       "      <td>11414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-1.30571973e+00 -7.02589810e-01 -1.70400810e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358720</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>542</td>\n",
       "      <td>18082</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-3.79988015e-01 -5.99230766e-01 -1.29478753e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358721</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>543</td>\n",
       "      <td>2249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>5</td>\n",
       "      <td>[-2.15392202e-01 -8.67155373e-01 -1.35554612e+0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358722</th>\n",
       "      <td>test</td>\n",
       "      <td>23</td>\n",
       "      <td>544</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[-8.72011006e-01 -3.26336920e-01 -1.34052545e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "358178  test       23         0       101              0               1   \n",
       "358179  test       23         1       118              0               1   \n",
       "358180  test       23         2       141              0               1   \n",
       "358181  test       23         3      9244              0               1   \n",
       "358182  test       23         4      9272              0               1   \n",
       "...      ...      ...       ...       ...            ...             ...   \n",
       "358718  test       23       540     20002              0               1   \n",
       "358719  test       23       541     11414              0               1   \n",
       "358720  test       23       542     18082              0               1   \n",
       "358721  test       23       543      2249              0               1   \n",
       "358722  test       23       544       102              0               1   \n",
       "\n",
       "        special_tokens_mask ent_iob ent_type token_class  token_class_id  \\\n",
       "358178                 True       O     <NA>           O               0   \n",
       "358179                False       O     <NA>           O               0   \n",
       "358180                False       O     <NA>           O               0   \n",
       "358181                False       O     <NA>           O               0   \n",
       "358182                False       O     <NA>           O               0   \n",
       "...                     ...     ...      ...         ...             ...   \n",
       "358718                False       I      LOC       I-LOC               5   \n",
       "358719                False       I      LOC       I-LOC               5   \n",
       "358720                False       I      LOC       I-LOC               5   \n",
       "358721                False       I      LOC       I-LOC               5   \n",
       "358722                 True       O     <NA>           O               0   \n",
       "\n",
       "                                                embedding  \n",
       "358178 [-3.93204927e-01 -7.20973670e-01  6.35356426e-0...  \n",
       "358179 [-4.59361285e-01 -7.75034666e-01  1.00733566e+0...  \n",
       "358180 [-0.3389236  -0.59117919  1.06589043  0.2252248...  \n",
       "358181 [-5.98726809e-01 -7.89630830e-01  7.54339695e-0...  \n",
       "358182 [-4.12817359e-01 -6.46852911e-01  8.24099600e-0...  \n",
       "...                                                   ...  \n",
       "358718 [-3.68024737e-01 -3.88864905e-01 -1.79580003e-0...  \n",
       "358719 [-1.30571973e+00 -7.02589810e-01 -1.70400810e+0...  \n",
       "358720 [-3.79988015e-01 -5.99230766e-01 -1.29478753e+0...  \n",
       "358721 [-2.15392202e-01 -8.67155373e-01 -1.35554612e+0...  \n",
       "358722 [-8.72011006e-01 -3.26336920e-01 -1.34052545e-0...  \n",
       "\n",
       "[545 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>5246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11, 14): 'NHL'</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[15, 18): 'ICE'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19, 25): 'HOCKEY'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25, 26): '-'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[27, 36): 'STANDINGS'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[37, 42): 'AFTER'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[43, 51): 'THURSDAY'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[51, 53): ''S'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[54, 59): 'GAMES'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[59, 60): '.'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...</td>\n",
       "      <td>5257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[61, 64): 'NEW'</td>\n",
       "      <td>B</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[61, 80): 'NEW YORK 1996-12-06'</td>\n",
       "      <td>5259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[65, 69): 'YORK'</td>\n",
       "      <td>I</td>\n",
       "      <td>LOC</td>\n",
       "      <td>[61, 80): 'NEW YORK 1996-12-06'</td>\n",
       "      <td>5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[70, 80): '1996-12-06'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[61, 80): 'NEW YORK 1996-12-06'</td>\n",
       "      <td>5261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[81, 90): 'Standings'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[81, 109): 'Standings of National Hockey'</td>\n",
       "      <td>5263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[91, 93): 'of'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[81, 109): 'Standings of National Hockey'</td>\n",
       "      <td>5264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[94, 102): 'National'</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[81, 109): 'Standings of National Hockey'</td>\n",
       "      <td>5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[103, 109): 'Hockey'</td>\n",
       "      <td>I</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[81, 109): 'Standings of National Hockey'</td>\n",
       "      <td>5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[110, 116): 'League'</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[117, 122): 'teams'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[123, 128): 'after'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[129, 134): 'games'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[135, 141): 'played'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[142, 144): 'on'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[145, 153): 'Thursday'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[154, 155): '('</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[155, 163): 'tabulate'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[164, 169): 'under'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[110, 169): 'League teams after games played o...</td>\n",
       "      <td>5277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[170, 173): 'won'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[173, 174): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[175, 179): 'lost'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[179, 180): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[181, 185): 'tied'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[185, 186): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[187, 192): 'goals'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[193, 196): 'for'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[196, 197): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[198, 203): 'goals'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[204, 211): 'against'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[211, 212): ','</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[213, 219): 'points'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[219, 220): ')'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[220, 221): ':'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[170, 221): 'won, lost, tied, goals for, goals...</td>\n",
       "      <td>5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[222, 229): 'EASTERN'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[222, 240): 'EASTERN CONFERENCE'</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[230, 240): 'CONFERENCE'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[222, 240): 'EASTERN CONFERENCE'</td>\n",
       "      <td>5296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[241, 250): 'NORTHEAST'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[241, 259): 'NORTHEAST DIVISION'</td>\n",
       "      <td>5298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[251, 259): 'DIVISION'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[241, 259): 'NORTHEAST DIVISION'</td>\n",
       "      <td>5299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[260, 261): 'W'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[260, 275): 'W L T GF GA PTS'</td>\n",
       "      <td>5301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[262, 263): 'L'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[260, 275): 'W L T GF GA PTS'</td>\n",
       "      <td>5302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[264, 265): 'T'</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[260, 275): 'W L T GF GA PTS'</td>\n",
       "      <td>5303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        span ent_iob ent_type  \\\n",
       "0      [0, 10): '-DOCSTART-'       O     None   \n",
       "1            [11, 14): 'NHL'       B      ORG   \n",
       "2            [15, 18): 'ICE'       O     None   \n",
       "3         [19, 25): 'HOCKEY'       O     None   \n",
       "4              [25, 26): '-'       O     None   \n",
       "5      [27, 36): 'STANDINGS'       O     None   \n",
       "6          [37, 42): 'AFTER'       O     None   \n",
       "7       [43, 51): 'THURSDAY'       O     None   \n",
       "8             [51, 53): ''S'       O     None   \n",
       "9          [54, 59): 'GAMES'       O     None   \n",
       "10             [59, 60): '.'       O     None   \n",
       "11           [61, 64): 'NEW'       B      LOC   \n",
       "12          [65, 69): 'YORK'       I      LOC   \n",
       "13    [70, 80): '1996-12-06'       O     None   \n",
       "14     [81, 90): 'Standings'       O     None   \n",
       "15            [91, 93): 'of'       O     None   \n",
       "16     [94, 102): 'National'       B      ORG   \n",
       "17      [103, 109): 'Hockey'       I      ORG   \n",
       "18      [110, 116): 'League'       B      ORG   \n",
       "19       [117, 122): 'teams'       O     None   \n",
       "20       [123, 128): 'after'       O     None   \n",
       "21       [129, 134): 'games'       O     None   \n",
       "22      [135, 141): 'played'       O     None   \n",
       "23          [142, 144): 'on'       O     None   \n",
       "24    [145, 153): 'Thursday'       O     None   \n",
       "25           [154, 155): '('       O     None   \n",
       "26    [155, 163): 'tabulate'       O     None   \n",
       "27       [164, 169): 'under'       O     None   \n",
       "28         [170, 173): 'won'       O     None   \n",
       "29           [173, 174): ','       O     None   \n",
       "30        [175, 179): 'lost'       O     None   \n",
       "31           [179, 180): ','       O     None   \n",
       "32        [181, 185): 'tied'       O     None   \n",
       "33           [185, 186): ','       O     None   \n",
       "34       [187, 192): 'goals'       O     None   \n",
       "35         [193, 196): 'for'       O     None   \n",
       "36           [196, 197): ','       O     None   \n",
       "37       [198, 203): 'goals'       O     None   \n",
       "38     [204, 211): 'against'       O     None   \n",
       "39           [211, 212): ','       O     None   \n",
       "40      [213, 219): 'points'       O     None   \n",
       "41           [219, 220): ')'       O     None   \n",
       "42           [220, 221): ':'       O     None   \n",
       "43     [222, 229): 'EASTERN'       O     None   \n",
       "44  [230, 240): 'CONFERENCE'       O     None   \n",
       "45   [241, 250): 'NORTHEAST'       O     None   \n",
       "46    [251, 259): 'DIVISION'       O     None   \n",
       "47           [260, 261): 'W'       O     None   \n",
       "48           [262, 263): 'L'       O     None   \n",
       "49           [264, 265): 'T'       O     None   \n",
       "\n",
       "                                             sentence  line_num  \n",
       "0                               [0, 10): '-DOCSTART-'      5246  \n",
       "1   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5248  \n",
       "2   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5249  \n",
       "3   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5250  \n",
       "4   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5251  \n",
       "5   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5252  \n",
       "6   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5253  \n",
       "7   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5254  \n",
       "8   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5255  \n",
       "9   [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5256  \n",
       "10  [11, 60): 'NHL ICE HOCKEY- STANDINGS AFTER THU...      5257  \n",
       "11                    [61, 80): 'NEW YORK 1996-12-06'      5259  \n",
       "12                    [61, 80): 'NEW YORK 1996-12-06'      5260  \n",
       "13                    [61, 80): 'NEW YORK 1996-12-06'      5261  \n",
       "14          [81, 109): 'Standings of National Hockey'      5263  \n",
       "15          [81, 109): 'Standings of National Hockey'      5264  \n",
       "16          [81, 109): 'Standings of National Hockey'      5265  \n",
       "17          [81, 109): 'Standings of National Hockey'      5266  \n",
       "18  [110, 169): 'League teams after games played o...      5268  \n",
       "19  [110, 169): 'League teams after games played o...      5269  \n",
       "20  [110, 169): 'League teams after games played o...      5270  \n",
       "21  [110, 169): 'League teams after games played o...      5271  \n",
       "22  [110, 169): 'League teams after games played o...      5272  \n",
       "23  [110, 169): 'League teams after games played o...      5273  \n",
       "24  [110, 169): 'League teams after games played o...      5274  \n",
       "25  [110, 169): 'League teams after games played o...      5275  \n",
       "26  [110, 169): 'League teams after games played o...      5276  \n",
       "27  [110, 169): 'League teams after games played o...      5277  \n",
       "28  [170, 221): 'won, lost, tied, goals for, goals...      5279  \n",
       "29  [170, 221): 'won, lost, tied, goals for, goals...      5280  \n",
       "30  [170, 221): 'won, lost, tied, goals for, goals...      5281  \n",
       "31  [170, 221): 'won, lost, tied, goals for, goals...      5282  \n",
       "32  [170, 221): 'won, lost, tied, goals for, goals...      5283  \n",
       "33  [170, 221): 'won, lost, tied, goals for, goals...      5284  \n",
       "34  [170, 221): 'won, lost, tied, goals for, goals...      5285  \n",
       "35  [170, 221): 'won, lost, tied, goals for, goals...      5286  \n",
       "36  [170, 221): 'won, lost, tied, goals for, goals...      5287  \n",
       "37  [170, 221): 'won, lost, tied, goals for, goals...      5288  \n",
       "38  [170, 221): 'won, lost, tied, goals for, goals...      5289  \n",
       "39  [170, 221): 'won, lost, tied, goals for, goals...      5290  \n",
       "40  [170, 221): 'won, lost, tied, goals for, goals...      5291  \n",
       "41  [170, 221): 'won, lost, tied, goals for, goals...      5292  \n",
       "42  [170, 221): 'won, lost, tied, goals for, goals...      5293  \n",
       "43                   [222, 240): 'EASTERN CONFERENCE'      5295  \n",
       "44                   [222, 240): 'EASTERN CONFERENCE'      5296  \n",
       "45                   [241, 259): 'NORTHEAST DIVISION'      5298  \n",
       "46                   [241, 259): 'NORTHEAST DIVISION'      5299  \n",
       "47                      [260, 275): 'W L T GF GA PTS'      5301  \n",
       "48                      [260, 275): 'W L T GF GA PTS'      5302  \n",
       "49                      [260, 275): 'W L T GF GA PTS'      5303  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_23 = corpus_raw[\"test\"][23]\n",
    "doc_23[doc_23[\"ent_type\"] != None].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-71181bf03098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: trying to get the char span for tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlowest_pr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowest_pr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlowest_pr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowest_pr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predicted_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class_max_pr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlowest_pr_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: trying to get the char span for tokens\n",
    "lowest_pr_df = lowest_pr_df.merge(test_df, on=[\"doc_num\", \"token_id\"])\n",
    "lowest_pr_df = lowest_pr_df[[\"doc_num\", \"token_id\", \"token_class\", \"predicted_class\", \"class_max_pr\"]]\n",
    "lowest_pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = corpus_raw[\"test\"][23]\n",
    "spans_df = tp.iob_to_spans(example_df)\n",
    "bert_toks_df = tp.make_bert_tokens(example_df[\"char_span\"].values[0].target_text, tokenizer)\n",
    "bert_token_spans = tp.TokenSpanArray.align_to_tokens(bert_toks_df[\"char_span\"],\n",
    "                                                     spans_df[\"token_span\"])\n",
    "bert_toks_df[[\"ent_iob\", \"ent_type\"]] = tp.spans_to_iob(bert_token_spans, \n",
    "                                                        spans_df[\"ent_type\"])\n",
    "bert_toks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - remove below if not computing metrics on predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split model outputs for an entire fold back into documents and add\n",
    "# token information.\n",
    "test_results_by_doc = util.align_model_outputs_to_tokens(test_results_df,\n",
    "                                                         bert_toks_by_fold)\n",
    "test_results_by_doc[(\"test\", 0)].iloc[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert IOB2-format output (and gold standard tags) to spans.\n",
    "test_actual_spans = {k: tp.iob_to_spans(v) for k, v in test_results_by_doc.items()}\n",
    "test_model_spans = {k:\n",
    "        tp.iob_to_spans(v, iob_col_name = \"predicted_iob\",\n",
    "                        entity_type_col_name = \"predicted_type\")\n",
    "          .rename(columns={\"predicted_type\": \"ent_type\"})\n",
    "        for k, v in test_results_by_doc.items()}\n",
    "\n",
    "test_model_spans[(\"test\", 0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every once in a while, the model will split a token in the original data\n",
    "# set into two entities. For example, look at document 202 of the test\n",
    "# set:\n",
    "doc_key = (\"test\", 202)\n",
    "test_model_spans[doc_key].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice `[150, 151): 'W'` and `[151, 156): 'idnes'`. These outputs are part\n",
    "# of the same original token.\n",
    "# We can use spanner algebra to fix up these outputs.\n",
    "spans_df = test_model_spans[doc_key]\n",
    "toks_df = test_raw[202]\n",
    "\n",
    "# First, find which tokens the spans overlap with:\n",
    "overlaps_df = (\n",
    "    tp\n",
    "    .overlap_join(spans_df[\"token_span\"], toks_df[\"char_span\"],\n",
    "                 \"token_span\", \"corpus_token\")\n",
    "    .merge(spans_df)\n",
    ")\n",
    "overlaps_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, compute the minimum span that covers all the corpus tokens\n",
    "# that overlap with each entity span.\n",
    "agg_df = (\n",
    "    overlaps_df\n",
    "    .groupby(\"token_span\")\n",
    "    .aggregate({\"corpus_token\": \"sum\", \"ent_type\": \"first\"})\n",
    "    .reset_index()\n",
    ")\n",
    "agg_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, take unique values and covert character-based spans to spans\n",
    "# in the corpus tokenization (since the new offsets might not match a\n",
    "# BERT tokenizer token boundary)\n",
    "cons_df = (\n",
    "    tp.consolidate(agg_df, \"corpus_token\")\n",
    "    [[\"corpus_token\", \"ent_type\"]]\n",
    "    .rename(columns={\"corpus_token\": \"token_span\"})\n",
    ")\n",
    "cons_df[\"token_span\"] = tp.TokenSpanArray.align_to_tokens(toks_df[\"char_span\"],\n",
    "                                                          cons_df[\"token_span\"])\n",
    "cons_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.py contains a single function that repeats the actions of the \n",
    "# previous 3 cells.\n",
    "tp.align_bert_tokens_to_corpus_tokens(test_model_spans[doc_key], test_raw[202]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all of our dataframes through `realign_to_toks`\n",
    "keys = list(test_model_spans.keys())\n",
    "new_values = tp.run_with_progress_bar(\n",
    "    len(keys), \n",
    "    lambda i: tp.align_bert_tokens_to_corpus_tokens(test_model_spans[keys[i]], test_raw[keys[i][1]]))\n",
    "test_model_spans = {k: v for k, v in zip(keys, new_values)}\n",
    "test_model_spans[doc_key].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same per-document statistics calculation code as in CoNLL_2.ipynb\n",
    "test_stats_by_doc = tp.compute_accuracy_by_document(test_actual_spans, test_model_spans)\n",
    "test_stats_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection-wide precision and recall can be computed by aggregating\n",
    "# our dataframe.\n",
    "tp.compute_global_accuracy(test_stats_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function analyze_model() in util.py combines the above postprocessing steps \n",
    "# into a single function.\n",
    "base_test_results = util.analyze_model(\n",
    "    corpus_df[corpus_df[\"fold\"] == \"test\"], \n",
    "    int_to_label, base_model, bert_toks_by_fold, corpus_raw, expand_matches=True)\n",
    "base_test_results[\"global_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results on the training set\n",
    "base_train_results = util.analyze_model(\n",
    "    corpus_df[corpus_df[\"fold\"] == \"train\"],\n",
    "    int_to_label, base_model, bert_toks_by_fold, corpus_raw, expand_matches=True)\n",
    "base_train_results[\"global_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results on the development set\n",
    "base_dev_results = util.analyze_model(\n",
    "    corpus_df[corpus_df[\"fold\"] == \"dev\"],\n",
    "    int_to_label, base_model, bert_toks_by_fold, corpus_raw, expand_matches=True)\n",
    "base_dev_results[\"global_scores\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pdext-dev] *",
   "language": "python",
   "name": "conda-env-pdext-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
