{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d77966eb-3dac-432a-aede-2ae7da92423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import feather\n",
    "import sklearn.pipeline\n",
    "import sklearn.linear_model\n",
    "\n",
    "# And of course we need the text_extensions_for_pandas library itself.\n",
    "try:\n",
    "    import text_extensions_for_pandas as tp\n",
    "except ModuleNotFoundError as e:\n",
    "    # If we're running from within the project source tree and the parent Python\n",
    "    # environment doesn't have the text_extensions_for_pandas package, use the\n",
    "    # version in the local source tree.\n",
    "    if not os.getcwd().endswith(\"notebooks\"):\n",
    "        raise e\n",
    "    if \"..\" not in sys.path:\n",
    "        sys.path.insert(0, \"..\")\n",
    "    import text_extensions_for_pandas as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd30eda8-e16a-45fa-a827-2a5865066c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init file locations, and download data if necessary. \n",
    "BASE_DIR = 'CoNLL_u_test_inputs/'\n",
    "FEATHER_FILE = \"conllu_database.feather\"\n",
    "\n",
    "ewt_base_url = \"https://github.com/UniversalDependencies/UD_English-EWT/blob/master/en_ewt-ud-\"\n",
    "ewt_dev_url = ewt_base_url + 'dev.conllu'\n",
    "conll_09_test_data_url =  'https://ufal.mff.cuni.cz/conll2009-st/trial/CoNLL2009-ST-English-trial.zip'\n",
    "\n",
    "# download the files if they have not already been downloaded \n",
    "conll_09_path = tp.io.conll.maybe_download_dataset_data(BASE_DIR, conll_09_test_data_url)\n",
    "conllu_ewt_path = tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_dev_url)\n",
    "\n",
    "# if you already have access to the full conll_2009_dataset, name the file accordingly and uncomment this line \n",
    "# conll_09_path = BASE_DIR + 'CoNLL2009-ST-evaluation-English.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a036fb68-3441-4c7f-bc4a-2b23bdf6875d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>POS</th>\n",
       "      <th>FEAT</th>\n",
       "      <th>head</th>\n",
       "      <th>DEPREL</th>\n",
       "      <th>PRED</th>\n",
       "      <th>predicate</th>\n",
       "      <th>pred0arg</th>\n",
       "      <th>pred1arg</th>\n",
       "      <th>pred2arg</th>\n",
       "      <th>pred3arg</th>\n",
       "      <th>pred4arg</th>\n",
       "      <th>pred5arg</th>\n",
       "      <th>pred6arg</th>\n",
       "      <th>pred7arg</th>\n",
       "      <th>pred8arg</th>\n",
       "      <th>pred9arg</th>\n",
       "      <th>pred10arg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 3): 'The'</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NMOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 11): 'economy'</td>\n",
       "      <td>economy</td>\n",
       "      <td>NN</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NMOD</td>\n",
       "      <td>None</td>\n",
       "      <td>A1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[11, 13): ''s'</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SUFFIX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14, 25): 'temperature'</td>\n",
       "      <td>temperature</td>\n",
       "      <td>NN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SBJ</td>\n",
       "      <td>temperature.01</td>\n",
       "      <td>A2</td>\n",
       "      <td>A1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[26, 30): 'will'</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AM-MOD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      span        LEMMA  POS  FEAT  head  DEPREL  \\\n",
       "0            [0, 3): 'The'          the   DT  None   1.0    NMOD   \n",
       "1       [4, 11): 'economy'      economy   NN  None   3.0    NMOD   \n",
       "2           [11, 13): ''s'           's  POS  None   1.0  SUFFIX   \n",
       "3  [14, 25): 'temperature'  temperature   NN  None   4.0     SBJ   \n",
       "4         [26, 30): 'will'         will   MD  None   NaN    ROOT   \n",
       "\n",
       "             PRED predicate pred0arg pred1arg pred2arg pred3arg pred4arg  \\\n",
       "0            None      None     None     None     None     None     None   \n",
       "1            None        A1     None     None     None     None     None   \n",
       "2            None      None     None     None     None     None     None   \n",
       "3  temperature.01        A2       A1     None     None     None     None   \n",
       "4            None      None   AM-MOD     None     None     None     None   \n",
       "\n",
       "  pred5arg pred6arg pred7arg pred8arg pred9arg pred10arg  \n",
       "0     None     None     None     None     None      None  \n",
       "1     None     None     None     None     None      None  \n",
       "2     None     None     None     None     None      None  \n",
       "3     None     None     None     None     None      None  \n",
       "4     None     None     None     None     None      None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>features</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>deps</th>\n",
       "      <th>misc</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 4): 'From'</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>case</td>\n",
       "      <td>3:case</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5, 8): 'the'</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>2.0</td>\n",
       "      <td>det</td>\n",
       "      <td>3:det</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 11): 'AP'</td>\n",
       "      <td>AP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>obl</td>\n",
       "      <td>4:obl:from</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 17): 'comes'</td>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[18, 22): 'this'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Number=Sing|PronType=Dem</td>\n",
       "      <td>5.0</td>\n",
       "      <td>det</td>\n",
       "      <td>6:det</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[23, 28): 'story'</td>\n",
       "      <td>story</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>4:nsubj</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[28, 29): ':'</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>punct</td>\n",
       "      <td>4:punct</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[30, 39): 'President'</td>\n",
       "      <td>President</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>11.0</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5:nsubj</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[40, 44): 'Bush'</td>\n",
       "      <td>Bush</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>7.0</td>\n",
       "      <td>flat</td>\n",
       "      <td>1:flat</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[45, 47): 'on'</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>10.0</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>None</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>weblog-blogspot.com_nominations_20041117172713...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    span      lemma upostag xpostag  \\\n",
       "0         [0, 4): 'From'       from     ADP      IN   \n",
       "1          [5, 8): 'the'        the     DET      DT   \n",
       "2          [9, 11): 'AP'         AP   PROPN     NNP   \n",
       "3      [12, 17): 'comes'       come    VERB     VBZ   \n",
       "4       [18, 22): 'this'       this     DET      DT   \n",
       "5      [23, 28): 'story'      story    NOUN      NN   \n",
       "6          [28, 29): ':'          :   PUNCT       :   \n",
       "7  [30, 39): 'President'  President   PROPN     NNP   \n",
       "8       [40, 44): 'Bush'       Bush   PROPN     NNP   \n",
       "9         [45, 47): 'on'         on     ADP      IN   \n",
       "\n",
       "                                            features  head deprel        deps  \\\n",
       "0                                               None   2.0   case      3:case   \n",
       "1                          Definite=Def|PronType=Art   2.0    det       3:det   \n",
       "2                                        Number=Sing   3.0    obl  4:obl:from   \n",
       "3  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...   NaN   root      0:root   \n",
       "4                           Number=Sing|PronType=Dem   5.0    det       6:det   \n",
       "5                                        Number=Sing   3.0  nsubj     4:nsubj   \n",
       "6                                               None   3.0  punct     4:punct   \n",
       "7                                        Number=Sing  11.0  nsubj     5:nsubj   \n",
       "8                                        Number=Sing   7.0   flat      1:flat   \n",
       "9                                               None  10.0   case      4:case   \n",
       "\n",
       "   misc                                        sentence_id  \\\n",
       "0  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "1  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "2  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "3  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "4  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "5  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "6  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "7  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "8  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "9  None  weblog-blogspot.com_nominations_20041117172713...   \n",
       "\n",
       "                                        paragraph_id  \\\n",
       "0  weblog-blogspot.com_nominations_20041117172713...   \n",
       "1  weblog-blogspot.com_nominations_20041117172713...   \n",
       "2  weblog-blogspot.com_nominations_20041117172713...   \n",
       "3  weblog-blogspot.com_nominations_20041117172713...   \n",
       "4  weblog-blogspot.com_nominations_20041117172713...   \n",
       "5  weblog-blogspot.com_nominations_20041117172713...   \n",
       "6  weblog-blogspot.com_nominations_20041117172713...   \n",
       "7  weblog-blogspot.com_nominations_20041117172713...   \n",
       "8  weblog-blogspot.com_nominations_20041117172713...   \n",
       "9  weblog-blogspot.com_nominations_20041117172713...   \n",
       "\n",
       "                                              doc_id  line_num  \n",
       "0  weblog-blogspot.com_nominations_20041117172713...         4  \n",
       "1  weblog-blogspot.com_nominations_20041117172713...         5  \n",
       "2  weblog-blogspot.com_nominations_20041117172713...         6  \n",
       "3  weblog-blogspot.com_nominations_20041117172713...         7  \n",
       "4  weblog-blogspot.com_nominations_20041117172713...         8  \n",
       "5  weblog-blogspot.com_nominations_20041117172713...         9  \n",
       "6  weblog-blogspot.com_nominations_20041117172713...        10  \n",
       "7  weblog-blogspot.com_nominations_20041117172713...        15  \n",
       "8  weblog-blogspot.com_nominations_20041117172713...        16  \n",
       "9  weblog-blogspot.com_nominations_20041117172713...        17  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import two very different documents, both in the conllu file format. \n",
    "\n",
    "# by default we look for EWT style column names, \n",
    "# so we have to define a new set for this specific conll09 format\n",
    "conll_09_cols = [\"LEMMA\",\"PLEMMA\",'POS','PPOS','FEAT','PFEAT','head','phead','DEPREL','PDEPREL','FILLPRED','PRED']\n",
    "\n",
    "conllu_09_docs = tp.io.conll.conll_u_to_dataframes(conll_09_path,column_names=conll_09_cols)\n",
    "#now just filter,and display the document \n",
    "conllu_09_doc = conllu_09_docs[0].drop(columns=[\"PLEMMA\",'PPOS','PFEAT','phead','PDEPREL','FILLPRED','sentence','line_num'])\n",
    "display(conllu_09_doc.head())\n",
    "\n",
    "\n",
    "#simultaneously, we can import an ewt style document, and display it with the same function\n",
    "conll_u_docs = tp.io.conll.conll_u_to_dataframes(conllu_ewt_path)\n",
    "#display \n",
    "DOC_NUM = 0\n",
    "doc_df = conll_u_docs[DOC_NUM]\n",
    "# here we drop the sentence argument for brevity. Note how we look for \n",
    "doc_df.head(10).drop(columns = [\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64a60cd7-3001-4529-9874-d8be8d1a7c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25146</th>\n",
       "      <td>[251, 254): 'and'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25147</th>\n",
       "      <td>[255, 256): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25148</th>\n",
       "      <td>[257, 261): 'very'</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>25149.0</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25149</th>\n",
       "      <td>[262, 275): 'knowledgeable'</td>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25150</th>\n",
       "      <td>[276, 281): 'staff'</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>25145.0</td>\n",
       "      <td>conj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              span          lemma upostag     head  deprel\n",
       "25146            [251, 254): 'and'            and   CCONJ  25150.0      cc\n",
       "25147              [255, 256): 'a'              a     DET  25150.0     det\n",
       "25148           [257, 261): 'very'           very     ADV  25149.0  advmod\n",
       "25149  [262, 275): 'knowledgeable'  knowledgeable     ADJ  25150.0    amod\n",
       "25150          [276, 281): 'staff'          staff    NOUN  25145.0    conj"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we combine all of our documents into one large combined dataframe,for simplicity\n",
    "\n",
    "# because we are concatenating our dataframes, we need to modify the \"head\" feilds to still point at their desired targets \n",
    "df_starts_at =0\n",
    "temp = conll_u_docs.copy()\n",
    "for df in temp: \n",
    "    df[\"head\"] += df_starts_at\n",
    "    df_starts_at +=df.shape[0]\n",
    "\n",
    "# Now concatenate all our documents into one big dataframe\n",
    "complete_df = temp[0]\n",
    "complete_df = complete_df.append(temp[1:], ignore_index=True)\n",
    "\n",
    "#show the last few rows of the dataframe, select just a few columns for compactness\n",
    "display(complete_df.shape[0])\n",
    "complete_df.tail()[[\"span\",\"lemma\",\"upostag\",\"head\",\"deprel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6540975b-14a6-4187-98a4-9993f5f2d1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to CoNLL_u_test_inputs/conllu_database.feather\n"
     ]
    }
   ],
   "source": [
    "# one advantage of using pandas dataframes is that we can write and read them signifcantly faster than we could the raw conllu files \n",
    "# here we use pyarrow with feather to save and reload our dataframe. \n",
    "\n",
    "# Currently writing multi document files is not supported, so we will have to use a workaround, \n",
    "# by converting sentences from TokenSpanArrays to SpanArrays\n",
    "complete_df[\"sentence\"] = tp.SpanArray(complete_df[\"span\"].array.target_text, complete_df[\"sentence\"].array.begin, complete_df[\"sentence\"].array.end)\n",
    "\n",
    "#finally write to file using feather \n",
    "path = BASE_DIR +FEATHER_FILE\n",
    "# increase the chunksize slightly, to allow writing in a single block\n",
    "feather.write_dataframe(complete_df, path,chunksize= 65536*8)\n",
    "print(f\"File written to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ade30665-3298-46ad-ab24-0da753c23067",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size is 352114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25146</th>\n",
       "      <td>[251, 254): 'and'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25147</th>\n",
       "      <td>[255, 256): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25148</th>\n",
       "      <td>[257, 261): 'very'</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>25149.0</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25149</th>\n",
       "      <td>[262, 275): 'knowledgeable'</td>\n",
       "      <td>knowledgeable</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25150</th>\n",
       "      <td>[276, 281): 'staff'</td>\n",
       "      <td>staff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>25145.0</td>\n",
       "      <td>conj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              span          lemma upostag     head  deprel\n",
       "25146            [251, 254): 'and'            and   CCONJ  25150.0      cc\n",
       "25147              [255, 256): 'a'              a     DET  25150.0     det\n",
       "25148           [257, 261): 'very'           very     ADV  25149.0  advmod\n",
       "25149  [262, 275): 'knowledgeable'  knowledgeable     ADJ  25150.0    amod\n",
       "25150          [276, 281): 'staff'          staff    NOUN  25145.0    conj"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can read this df and continue operating on it as before\n",
    "re_read_df = feather.read_dataframe(path)\n",
    "print(f\"size is {re_read_df.size}\")\n",
    "# show the same subset of the dataframe as above \n",
    "re_read_df.tail()[[\"span\",\"lemma\",\"upostag\",\"head\",\"deprel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3425060-3542-438a-ae5a-099084b66ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upostag</th>\n",
       "      <th>xpostag</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>[979, 982): 'And'</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>cc</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>[983, 987): 'what'</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>obj</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>[988, 990): 'do'</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>aux</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>[991, 993): 'we'</td>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>[994, 997): 'get'</td>\n",
       "      <td>get</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>root</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>[998, 1001): 'for'</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>case</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>[1002, 1006): 'this'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>det</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>[1007, 1013): 'effort'</td>\n",
       "      <td>effort</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>obl</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>[1013, 1014): '?'</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>punct</td>\n",
       "      <td>[979, 1014): 'And what do we get for this effo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        span   lemma upostag xpostag    head deprel  \\\n",
       "2510       [979, 982): 'And'     and   CCONJ      CC  2514.0     cc   \n",
       "2511      [983, 987): 'what'    what    PRON      WP  2514.0    obj   \n",
       "2512        [988, 990): 'do'      do     AUX     VBP  2514.0    aux   \n",
       "2513        [991, 993): 'we'      we    PRON     PRP  2514.0  nsubj   \n",
       "2514       [994, 997): 'get'     get    VERB      VB     NaN   root   \n",
       "2515      [998, 1001): 'for'     for     ADP      IN  2517.0   case   \n",
       "2516    [1002, 1006): 'this'    this     DET      DT  2517.0    det   \n",
       "2517  [1007, 1013): 'effort'  effort    NOUN      NN  2514.0    obl   \n",
       "2518       [1013, 1014): '?'       ?   PUNCT       .  2514.0  punct   \n",
       "\n",
       "                                               sentence  \n",
       "2510  [979, 1014): 'And what do we get for this effo...  \n",
       "2511  [979, 1014): 'And what do we get for this effo...  \n",
       "2512  [979, 1014): 'And what do we get for this effo...  \n",
       "2513  [979, 1014): 'And what do we get for this effo...  \n",
       "2514  [979, 1014): 'And what do we get for this effo...  \n",
       "2515  [979, 1014): 'And what do we get for this effo...  \n",
       "2516  [979, 1014): 'And what do we get for this effo...  \n",
       "2517  [979, 1014): 'And what do we get for this effo...  \n",
       "2518  [979, 1014): 'And what do we get for this effo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5f50ec90bb6f40b2866543125c3f8bd4-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">And</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">what</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">get</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">effort</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 750.0,2.0 750.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-6\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5f50ec90bb6f40b2866543125c3f8bd4-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# because of the support we've built into Text extensions, we can use powerful data visualization tools \n",
    "# here we're leveraging spaCy's dependency tree visualization tools, to show the parse tree \n",
    "# as specified in the raw conllu file. \n",
    "# other integrations with spacy, as well as other packages are possible \n",
    "\n",
    "Sentence_num = 110\n",
    "# use pandas to quickly select the 'n'th sentence in the dataset \n",
    "first_sentence = list(re_read_df.groupby(\"sentence_id\",sort=False))[Sentence_num][1]\n",
    "# then display it, as well as its parse tree. \n",
    "display(first_sentence[[\"span\",\"lemma\",\"upostag\",\"xpostag\",\"head\",\"deprel\",\"sentence\"]])\n",
    "tp.io.spacy.render_parse_tree(first_sentence,tag_col=\"upostag\",label_col=\"deprel\",head_col=\"head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc00e06-b2fe-47f0-9f0a-20d0b8370807",
   "metadata": {},
   "source": [
    "# Train a classifier model\n",
    "Now use more text extensions integrations, with spaCy to quickly and easily train a classifier model on our data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "20f20214-62d9-4f7b-bd4f-fcd377148aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted fold: 'test' to list of 316 dataframes\n",
      "converted fold: 'dev' to list of 318 dataframes\n",
      "converted fold: 'train' to list of 540 dataframes\n"
     ]
    }
   ],
   "source": [
    "# We're going to need the whole ewt dataset for this: download them, and parse them in \n",
    "fold_paths = {\"test\":  tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"test.conllu\"),\n",
    "              \"dev\":   tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"dev.conllu\"),\n",
    "              \"train\": tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"train.conllu\")}\n",
    "fold_docs = {}\n",
    "for fold,fold_path in fold_paths.items(): \n",
    "    fold_docs[fold] = tp.io.conll.conll_u_to_dataframes(fold_path)\n",
    "    print(f\"converted fold: '{fold}' to list of {len(fold_docs[fold])} dataframes\")\n",
    "    #     uncomment to display segments of the extracted folds \n",
    "    #     display(fold_docs[fold][0].head()[['span','lemma','upostag','features','sentence']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c1eca7b6-7138-428e-901e-d07839b778f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['O', 'B-ADP', 'B-DET', 'B-PROPN', 'B-VERB', 'B-NOUN',\n",
       "                  'B-PUNCT', 'B-NUM', 'B-PART', 'B-ADJ', 'B-ADV', 'B-AUX',\n",
       "                  'B-PRON', 'B-CCONJ', 'B-SCONJ', 'B-X', 'B-SYM', 'B-INTJ',\n",
       "                  'I-ADP', 'I-DET', 'I-PROPN', 'I-VERB', 'I-NOUN', 'I-PUNCT',\n",
       "                  'I-NUM', 'I-PART', 'I-ADJ', 'I-ADV', 'I-AUX', 'I-PRON',\n",
       "                  'I-CCONJ', 'I-SCONJ', 'I-X', 'I-SYM', 'I-INTJ'],\n",
       ", ordered=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to convert each fold to bert-compatible tokenization. \n",
    "# we will first initialize a pretrained BERT-compatible tokenizer from transformers,\n",
    "# and use it to tokenize the document, then use another pretrained model to \n",
    "# generate BERT embeddings \n",
    "# See the 'Model_Training_with_BERT' notebook for more information on this process. \n",
    "\n",
    "bert_model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(bert_model_name)\n",
    "bert = transformers.BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# also we will want to create a pandas categorical dtype for what we want to predict- part of speech. \n",
    "# use the combined df, because it has all the elements \n",
    "upostags = list(re_read_df[\"upostag\"].unique())\n",
    "upostag_dtype,upostag_list,upostag_dict = tp.io.conll.make_iob_tag_categories(upostags)\n",
    "upostag_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5bf91aa-573f-4dbe-9bca-98c1cd233dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag_iob</th>\n",
       "      <th>postag</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[    -0.3136824,    -0.12475453,      0.657083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'From'</td>\n",
       "      <td>1622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>ADP</td>\n",
       "      <td>B-ADP</td>\n",
       "      <td>1</td>\n",
       "      <td>[   -0.16610569,   0.0027155988,      0.836163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[5, 8): 'the'</td>\n",
       "      <td>1103</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>DET</td>\n",
       "      <td>B-DET</td>\n",
       "      <td>2</td>\n",
       "      <td>[    -0.5103949,    -0.43374223,      0.522710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[9, 11): 'AP'</td>\n",
       "      <td>10997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[    -0.6617647,     -0.4930782,   -0.01439116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[12, 17): 'comes'</td>\n",
       "      <td>2502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>VERB</td>\n",
       "      <td>B-VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>[   -0.12817244,     -0.1552504,     0.5966705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>[463, 465): 'St'</td>\n",
       "      <td>1457</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[     1.2990547,      1.8487868,    -0.3757655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>[465, 468): 'ead'</td>\n",
       "      <td>12393</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>I-PROPN</td>\n",
       "      <td>20</td>\n",
       "      <td>[    0.38742343,      1.0229412,     0.3259903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>[468, 471): 'man'</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>I-PROPN</td>\n",
       "      <td>20</td>\n",
       "      <td>[     1.0614744,      1.2706978,    -0.5080642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>[471, 472): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[   -0.22779426,    -0.14614452,      0.612667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.05079651,      1.0258889,      0.422901...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     token_id               span  input_id  token_type_id  attention_mask  \\\n",
       "0           0         [0, 0): ''       101              0               1   \n",
       "1           1     [0, 4): 'From'      1622              0               1   \n",
       "2           2      [5, 8): 'the'      1103              0               1   \n",
       "3           3      [9, 11): 'AP'     10997              0               1   \n",
       "4           4  [12, 17): 'comes'      2502              0               1   \n",
       "..        ...                ...       ...            ...             ...   \n",
       "98         98   [463, 465): 'St'      1457              0               1   \n",
       "99         99  [465, 468): 'ead'     12393              0               1   \n",
       "100       100  [468, 471): 'man'      1399              0               1   \n",
       "101       101    [471, 472): '.'       119              0               1   \n",
       "102       102         [0, 0): ''       102              0               1   \n",
       "\n",
       "     special_tokens_mask postag_iob postag token_class  token_class_id  \\\n",
       "0                   True          O   <NA>           O               0   \n",
       "1                  False          B    ADP       B-ADP               1   \n",
       "2                  False          B    DET       B-DET               2   \n",
       "3                  False          B  PROPN     B-PROPN               3   \n",
       "4                  False          B   VERB      B-VERB               4   \n",
       "..                   ...        ...    ...         ...             ...   \n",
       "98                 False          B  PROPN     B-PROPN               3   \n",
       "99                 False          I  PROPN     I-PROPN              20   \n",
       "100                False          I  PROPN     I-PROPN              20   \n",
       "101                False          B  PUNCT     B-PUNCT               6   \n",
       "102                 True          O   <NA>           O               0   \n",
       "\n",
       "                                             embedding  \n",
       "0    [    -0.3136824,    -0.12475453,      0.657083...  \n",
       "1    [   -0.16610569,   0.0027155988,      0.836163...  \n",
       "2    [    -0.5103949,    -0.43374223,      0.522710...  \n",
       "3    [    -0.6617647,     -0.4930782,   -0.01439116...  \n",
       "4    [   -0.12817244,     -0.1552504,     0.5966705...  \n",
       "..                                                 ...  \n",
       "98   [     1.2990547,      1.8487868,    -0.3757655...  \n",
       "99   [    0.38742343,      1.0229412,     0.3259903...  \n",
       "100  [     1.0614744,      1.2706978,    -0.5080642...  \n",
       "101  [   -0.22779426,    -0.14614452,      0.612667...  \n",
       "102  [   -0.05079651,      1.0258889,      0.422901...  \n",
       "\n",
       "[103 rows x 11 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep an example df for use with  a bert model as follows: \n",
    "# start by making bert tokens for the target text. \n",
    "# then align the texts, convert to iob, and mark the categorical data accordingly\n",
    "\n",
    "tokenized = tp.io.bert.make_bert_tokens(doc_df.loc[0,'span'].target_text, tokenizer)\n",
    "# align to text  -- convert \"raw\" spans to spans over bert tokens\n",
    "aligned_spans = tp.TokenSpanArray.align_to_tokens(tokenized[\"span\"],doc_df[\"span\"])\n",
    "# convert to IOB format for token -> UPOSTAG \n",
    "tokenized[[\"postag_iob\",\"postag\"]] = tp.io.conll.spans_to_iob(aligned_spans,doc_df[\"upostag\"])\n",
    "# add tokenization in our specific dtype\n",
    "tokenized = tp.io.conll.add_token_classes(tokenized,upostag_dtype,iob_col_name = \"postag_iob\",entity_type_col_name=\"postag\")\n",
    "# finally, create an embedding for each bert token \n",
    "embeddings_df = tp.io.bert.add_embeddings(tokenized, bert)\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3742c07b-ec21-4b2c-8ec6-d41045e757cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the above process into a method for use on the whole dataset: \n",
    "def preprocess_document(document, tokenizer,bert):\n",
    "    temp = tp.io.bert.make_bert_tokens(document.loc[0,'span'].target_text, tokenizer)\n",
    "    spans = tp.TokenSpanArray.align_to_tokens(temp[\"span\"],document[\"span\"])\n",
    "    temp[[\"postag_iob\",\"postag\"]] = tp.io.conll.spans_to_iob(spans,document[\"upostag\"])\n",
    "    temp = tp.io.conll.add_token_classes(temp,upostag_dtype,iob_col_name = \"postag_iob\",entity_type_col_name=\"postag\")\n",
    "    return tp.io.bert.add_embeddings(temp, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c8793c3-a030-4135-b94b-b77fb7f9b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f349e2c036b4971bf179b378bc754a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=316, style=ProgressStyle(desc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b377a2438d4185851798c10ee3f782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=318, style=ProgressStyle(desc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8754649b31224a389fe09c1ef3037cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=540, style=ProgressStyle(desc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now preprocess the whole corpus: \n",
    "bert_docs_by_fold = {}\n",
    "for fold in fold_docs.keys():\n",
    "    docs = fold_docs[fold]\n",
    "    print(f\"processing fold {fold}\")\n",
    "    bert_docs_by_fold[fold] = tp.jupyter.run_with_progress_bar(len(docs),lambda i: preprocess_document(docs[i],tokenizer,bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9b60b289-56d0-4dc0-8b8a-34aca63568ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag_iob</th>\n",
       "      <th>postag</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.37686592,    -0.14841378,     0.7398001...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PRON</td>\n",
       "      <td>B-PRON</td>\n",
       "      <td>12</td>\n",
       "      <td>[   -0.23266968,    -0.40546328,      0.617192...</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>B-SCONJ</td>\n",
       "      <td>14</td>\n",
       "      <td>[    -0.8156859,    -0.04782569,    0.08148429...</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[    0.78967804,     -0.8511879,    -0.4881262...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>VERB</td>\n",
       "      <td>B-VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>[   -0.25935018,      0.5710723,    -0.0910664...</td>\n",
       "      <td>Mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307892</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>756</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PRON</td>\n",
       "      <td>B-PRON</td>\n",
       "      <td>12</td>\n",
       "      <td>[   -0.06984596,     -0.4646067,     0.8547705...</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307893</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>757</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>B-NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>[    0.14624132,    -0.46386197,      0.596684...</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307894</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>758</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[  -0.090651065,    -0.29592788,      0.597023...</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307895</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>759</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[   0.031023545,    -0.27608734,      0.782190...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307896</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>760</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[    -0.5088702,    -0.22885968,      0.544944...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307897 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id                 span  input_id  \\\n",
       "0        test        0         0           [0, 0): ''       101   \n",
       "1        test        0         1       [0, 4): 'What'      1327   \n",
       "2        test        0         2         [5, 7): 'if'      1191   \n",
       "3        test        0         3    [8, 14): 'Google'      7986   \n",
       "4        test        0         4       [15, 17): 'Mo'     12556   \n",
       "...       ...      ...       ...                  ...       ...   \n",
       "307892  train      539       756   [3152, 3154): 'my'      1139   \n",
       "307893  train      539       757  [3155, 3158): 'car'      1610   \n",
       "307894  train      539       758    [3158, 3159): ')'       114   \n",
       "307895  train      539       759    [3159, 3160): '.'       119   \n",
       "307896  train      539       760           [0, 0): ''       102   \n",
       "\n",
       "        token_type_id  attention_mask  special_tokens_mask postag_iob postag  \\\n",
       "0                   0               1                 True          O   <NA>   \n",
       "1                   0               1                False          B   PRON   \n",
       "2                   0               1                False          B  SCONJ   \n",
       "3                   0               1                False          B  PROPN   \n",
       "4                   0               1                False          B   VERB   \n",
       "...               ...             ...                  ...        ...    ...   \n",
       "307892              0               1                False          B   PRON   \n",
       "307893              0               1                False          B   NOUN   \n",
       "307894              0               1                False          B  PUNCT   \n",
       "307895              0               1                False          B  PUNCT   \n",
       "307896              0               1                 True          O   <NA>   \n",
       "\n",
       "       token_class  token_class_id  \\\n",
       "0                O               0   \n",
       "1           B-PRON              12   \n",
       "2          B-SCONJ              14   \n",
       "3          B-PROPN               3   \n",
       "4           B-VERB               4   \n",
       "...            ...             ...   \n",
       "307892      B-PRON              12   \n",
       "307893      B-NOUN               5   \n",
       "307894     B-PUNCT               6   \n",
       "307895     B-PUNCT               6   \n",
       "307896           O               0   \n",
       "\n",
       "                                                embedding    text  \n",
       "0       [   -0.37686592,    -0.14841378,     0.7398001...          \n",
       "1       [   -0.23266968,    -0.40546328,      0.617192...    What  \n",
       "2       [    -0.8156859,    -0.04782569,    0.08148429...      if  \n",
       "3       [    0.78967804,     -0.8511879,    -0.4881262...  Google  \n",
       "4       [   -0.25935018,      0.5710723,    -0.0910664...      Mo  \n",
       "...                                                   ...     ...  \n",
       "307892  [   -0.06984596,     -0.4646067,     0.8547705...      my  \n",
       "307893  [    0.14624132,    -0.46386197,      0.596684...     car  \n",
       "307894  [  -0.090651065,    -0.29592788,      0.597023...       )  \n",
       "307895  [   0.031023545,    -0.27608734,      0.782190...       .  \n",
       "307896  [    -0.5088702,    -0.22885968,      0.544944...          \n",
       "\n",
       "[307897 rows x 14 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine folds and save to a feather file, so we don't necessarily need to redo the preprocessing. \n",
    "corpus_df = tp.io.conll.combine_folds(bert_docs_by_fold)\n",
    "corpus_df[\"text\"] = corpus_df[\"span\"].apply(lambda s: s.covered_text)\n",
    "corpus_df.drop(columns=[\"span\"]).to_feather(\"outputs/conll_u_corpus.feather\")\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "63efdd32-5458-4dcb-91f3-dca97a7d1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read feather document if need be: \n",
    "if corpus_df is None or corpus_df.size == 0:\n",
    "    corpus_df = pd.read_feather(\"outputs/conll_u_corpus.feather\")\n",
    "    corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0bfa7afc-6510-4b5f-9ff4-4b184f00e352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag_iob</th>\n",
       "      <th>postag</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64729</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.41927838,    -0.22575253,     0.6648760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64730</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[   -0.36961424,     -1.0804733,     -0.283367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64731</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[    -0.9178737,    -0.94624436,     -0.808995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64732</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[   -0.90530086,    -0.97086835,     -1.440879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64733</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>I-PROPN</td>\n",
       "      <td>20</td>\n",
       "      <td>[    -1.1586123,      -1.149766,     -1.194975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307892</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>756</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PRON</td>\n",
       "      <td>B-PRON</td>\n",
       "      <td>12</td>\n",
       "      <td>[   -0.06984596,     -0.4646067,     0.8547705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307893</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>757</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>B-NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>[    0.14624132,    -0.46386197,      0.596684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307894</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>758</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[  -0.090651065,    -0.29592788,      0.597023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307895</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>759</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[   0.031023545,    -0.27608734,      0.782190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307896</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>760</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[    -0.5088702,    -0.22885968,      0.544944...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243168 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id  input_id  token_type_id  attention_mask  \\\n",
       "64729   train        0         0       101              0               1   \n",
       "64730   train        0         1      2586              0               1   \n",
       "64731   train        0         2       118              0               1   \n",
       "64732   train        0         3       163              0               1   \n",
       "64733   train        0         4     19853              0               1   \n",
       "...       ...      ...       ...       ...            ...             ...   \n",
       "307892  train      539       756      1139              0               1   \n",
       "307893  train      539       757      1610              0               1   \n",
       "307894  train      539       758       114              0               1   \n",
       "307895  train      539       759       119              0               1   \n",
       "307896  train      539       760       102              0               1   \n",
       "\n",
       "        special_tokens_mask postag_iob postag token_class  token_class_id  \\\n",
       "64729                  True          O   <NA>           O               0   \n",
       "64730                 False          B  PROPN     B-PROPN               3   \n",
       "64731                 False          B  PUNCT     B-PUNCT               6   \n",
       "64732                 False          B  PROPN     B-PROPN               3   \n",
       "64733                 False          I  PROPN     I-PROPN              20   \n",
       "...                     ...        ...    ...         ...             ...   \n",
       "307892                False          B   PRON      B-PRON              12   \n",
       "307893                False          B   NOUN      B-NOUN               5   \n",
       "307894                False          B  PUNCT     B-PUNCT               6   \n",
       "307895                False          B  PUNCT     B-PUNCT               6   \n",
       "307896                 True          O   <NA>           O               0   \n",
       "\n",
       "                                                embedding  \n",
       "64729   [   -0.41927838,    -0.22575253,     0.6648760...  \n",
       "64730   [   -0.36961424,     -1.0804733,     -0.283367...  \n",
       "64731   [    -0.9178737,    -0.94624436,     -0.808995...  \n",
       "64732   [   -0.90530086,    -0.97086835,     -1.440879...  \n",
       "64733   [    -1.1586123,      -1.149766,     -1.194975...  \n",
       "...                                                   ...  \n",
       "307892  [   -0.06984596,     -0.4646067,     0.8547705...  \n",
       "307893  [    0.14624132,    -0.46386197,      0.596684...  \n",
       "307894  [  -0.090651065,    -0.29592788,      0.597023...  \n",
       "307895  [   0.031023545,    -0.27608734,      0.782190...  \n",
       "307896  [    -0.5088702,    -0.22885968,      0.544944...  \n",
       "\n",
       "[243168 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now get ready to train our model: \n",
    "train_df = corpus_df[corpus_df[\"fold\"] == \"train\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "954fe75f-c190-4c99-afb9-fb378ec66275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/zacharyeichenberger/anaconda3/envs/pd/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 25.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 25.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('mlogreg',\n",
       "                 LogisticRegression(max_iter=1000, multi_class='multinomial',\n",
       "                                    verbose=10))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now actually train a model, using sklearn \n",
    "MULTI_CLASS= \"multinomial\"\n",
    "\n",
    "# How many iterations to run the BGFS optimizer when fitting logistic\n",
    "# regression models. 100 ==> Fast; 10000 ==> Full convergence\n",
    "LBGFS_ITERATIONS = 1000\n",
    "\n",
    "base_pipeline = sklearn.pipeline.Pipeline([\n",
    "    # Standard scaler. This only makes a difference for certain classes\n",
    "    # of embeddings.\n",
    "    #(\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "    (\"mlogreg\", sklearn.linear_model.LogisticRegression(\n",
    "        multi_class=MULTI_CLASS,\n",
    "        verbose=10,\n",
    "        max_iter=LBGFS_ITERATIONS\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train = train_df[\"embedding\"].values\n",
    "Y_train = train_df[\"token_class_id\"]\n",
    "base_model = base_pipeline.fit(X_train, Y_train)\n",
    "base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6937f2cd-60bb-4296-b900-87cf19048895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag_iob</th>\n",
       "      <th>postag</th>\n",
       "      <th>token_class</th>\n",
       "      <th>token_class_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_postag</th>\n",
       "      <th>p_iob</th>\n",
       "      <th>p_type</th>\n",
       "      <th>raw_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.37686592,    -0.14841378,     0.7398001...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[    0.9999999977550698, 1.2013331410996974e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PRON</td>\n",
       "      <td>B-PRON</td>\n",
       "      <td>12</td>\n",
       "      <td>[   -0.23266968,    -0.40546328,      0.617192...</td>\n",
       "      <td>What</td>\n",
       "      <td>6</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[1.1636381343139794e-10,  6.632241756523535e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>B-SCONJ</td>\n",
       "      <td>14</td>\n",
       "      <td>[    -0.8156859,    -0.04782569,    0.08148429...</td>\n",
       "      <td>if</td>\n",
       "      <td>14</td>\n",
       "      <td>B-SCONJ</td>\n",
       "      <td>B</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[1.9222457126669029e-10,  0.003846132485503873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>3</td>\n",
       "      <td>[    0.78967804,     -0.8511879,    -0.4881262...</td>\n",
       "      <td>Google</td>\n",
       "      <td>3</td>\n",
       "      <td>B-PROPN</td>\n",
       "      <td>B</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[ 7.078586986533554e-14,  5.643222225393274e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>VERB</td>\n",
       "      <td>B-VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>[   -0.25935018,      0.5710723,    -0.0910664...</td>\n",
       "      <td>Mo</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NOUN</td>\n",
       "      <td>B</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[ 6.094384616059652e-15,  4.748000666238187e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32675</th>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>57</td>\n",
       "      <td>[315, 324): 'exercises'</td>\n",
       "      <td>11536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>B-NOUN</td>\n",
       "      <td>5</td>\n",
       "      <td>[    0.04967872,    -0.29388765,     0.8163368...</td>\n",
       "      <td>exercises</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NOUN</td>\n",
       "      <td>B</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[1.0632510146485344e-09, 2.1276845533963685e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32676</th>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>58</td>\n",
       "      <td>[325, 327): 'to'</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PART</td>\n",
       "      <td>B-PART</td>\n",
       "      <td>8</td>\n",
       "      <td>[    0.10523166,     -0.3070524,      0.730677...</td>\n",
       "      <td>to</td>\n",
       "      <td>8</td>\n",
       "      <td>B-PART</td>\n",
       "      <td>B</td>\n",
       "      <td>PART</td>\n",
       "      <td>[2.6366796918071336e-08,    0.2350564146996362...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32677</th>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>59</td>\n",
       "      <td>[328, 331): 'use'</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>VERB</td>\n",
       "      <td>B-VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>[    0.13797167,    -0.47705936,     0.8551439...</td>\n",
       "      <td>use</td>\n",
       "      <td>4</td>\n",
       "      <td>B-VERB</td>\n",
       "      <td>B</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[2.5537423737537782e-09, 2.6663335749291686e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32678</th>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>60</td>\n",
       "      <td>[331, 332): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>6</td>\n",
       "      <td>[   0.014988249,    -0.32625836,      0.820147...</td>\n",
       "      <td>.</td>\n",
       "      <td>6</td>\n",
       "      <td>B-PUNCT</td>\n",
       "      <td>B</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[ 6.589471900572395e-08,  8.925740601368359e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32679</th>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>61</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.43900165,   -0.021463677,      1.101970...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[    0.9996253839209109, 1.9005539269680534e-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32680 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold  doc_num  token_id                     span  input_id  \\\n",
       "0      test        0         0               [0, 0): ''       101   \n",
       "1      test        0         1           [0, 4): 'What'      1327   \n",
       "2      test        0         2             [5, 7): 'if'      1191   \n",
       "3      test        0         3        [8, 14): 'Google'      7986   \n",
       "4      test        0         4           [15, 17): 'Mo'     12556   \n",
       "...     ...      ...       ...                      ...       ...   \n",
       "32675  test      315        57  [315, 324): 'exercises'     11536   \n",
       "32676  test      315        58         [325, 327): 'to'      1106   \n",
       "32677  test      315        59        [328, 331): 'use'      1329   \n",
       "32678  test      315        60          [331, 332): '.'       119   \n",
       "32679  test      315        61               [0, 0): ''       102   \n",
       "\n",
       "       token_type_id  attention_mask  special_tokens_mask postag_iob postag  \\\n",
       "0                  0               1                 True          O   <NA>   \n",
       "1                  0               1                False          B   PRON   \n",
       "2                  0               1                False          B  SCONJ   \n",
       "3                  0               1                False          B  PROPN   \n",
       "4                  0               1                False          B   VERB   \n",
       "...              ...             ...                  ...        ...    ...   \n",
       "32675              0               1                False          B   NOUN   \n",
       "32676              0               1                False          B   PART   \n",
       "32677              0               1                False          B   VERB   \n",
       "32678              0               1                False          B  PUNCT   \n",
       "32679              0               1                 True          O   <NA>   \n",
       "\n",
       "      token_class  token_class_id  \\\n",
       "0               O               0   \n",
       "1          B-PRON              12   \n",
       "2         B-SCONJ              14   \n",
       "3         B-PROPN               3   \n",
       "4          B-VERB               4   \n",
       "...           ...             ...   \n",
       "32675      B-NOUN               5   \n",
       "32676      B-PART               8   \n",
       "32677      B-VERB               4   \n",
       "32678     B-PUNCT               6   \n",
       "32679           O               0   \n",
       "\n",
       "                                               embedding       text  p_id  \\\n",
       "0      [   -0.37686592,    -0.14841378,     0.7398001...                0   \n",
       "1      [   -0.23266968,    -0.40546328,      0.617192...       What     6   \n",
       "2      [    -0.8156859,    -0.04782569,    0.08148429...         if    14   \n",
       "3      [    0.78967804,     -0.8511879,    -0.4881262...     Google     3   \n",
       "4      [   -0.25935018,      0.5710723,    -0.0910664...         Mo     5   \n",
       "...                                                  ...        ...   ...   \n",
       "32675  [    0.04967872,    -0.29388765,     0.8163368...  exercises     5   \n",
       "32676  [    0.10523166,     -0.3070524,      0.730677...         to     8   \n",
       "32677  [    0.13797167,    -0.47705936,     0.8551439...        use     4   \n",
       "32678  [   0.014988249,    -0.32625836,      0.820147...          .     6   \n",
       "32679  [   -0.43900165,   -0.021463677,      1.101970...                0   \n",
       "\n",
       "      p_postag p_iob p_type                                         raw_output  \n",
       "0            O     O   None  [    0.9999999977550698, 1.2013331410996974e-1...  \n",
       "1      B-PUNCT     B  PUNCT  [1.1636381343139794e-10,  6.632241756523535e-0...  \n",
       "2      B-SCONJ     B  SCONJ  [1.9222457126669029e-10,  0.003846132485503873...  \n",
       "3      B-PROPN     B  PROPN  [ 7.078586986533554e-14,  5.643222225393274e-1...  \n",
       "4       B-NOUN     B   NOUN  [ 6.094384616059652e-15,  4.748000666238187e-0...  \n",
       "...        ...   ...    ...                                                ...  \n",
       "32675   B-NOUN     B   NOUN  [1.0632510146485344e-09, 2.1276845533963685e-0...  \n",
       "32676   B-PART     B   PART  [2.6366796918071336e-08,    0.2350564146996362...  \n",
       "32677   B-VERB     B   VERB  [2.5537423737537782e-09, 2.6663335749291686e-0...  \n",
       "32678  B-PUNCT     B  PUNCT  [ 6.589471900572395e-08,  8.925740601368359e-0...  \n",
       "32679        O     O   None  [    0.9996253839209109, 1.9005539269680534e-0...  \n",
       "\n",
       "[32680 rows x 19 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer_on_df(df: pd.DataFrame, id_to_class_dict, predictor):\n",
    "    result_df = df.copy()\n",
    "    raw_outputs = tp.TensorArray(predictor.predict_proba(result_df[\"embedding\"]))\n",
    "    result_df[\"p_id\"] = np.argmax(raw_outputs, axis=1)\n",
    "    result_df[\"p_postag\"]= result_df[\"p_id\"].apply(lambda p_id: id_to_class_dict[p_id])\n",
    "    iobs, types = tp.io.conll.decode_class_labels(result_df [\"p_postag\"].values)\n",
    "    result_df[\"p_iob\"] = iobs\n",
    "    result_df[\"p_type\"] = types\n",
    "    result_df[\"raw_output\"] = raw_outputs\n",
    "    return result_df\n",
    "\n",
    "dev_results = infer_on_df(corpus_df[corpus_df[\"fold\"] == \"test\"],upostag_list,base_model)\n",
    "dev_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef9617-6310-4561-9203-8e2a5b2cffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
