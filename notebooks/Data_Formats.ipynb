{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informed-passage",
   "metadata": {},
   "source": [
    "# Data_Formats.ipynb\n",
    "\n",
    "Demonstration of the differences in file size and read time between different file formats for NLP corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regulated-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pathlib\n",
    "\n",
    "# And of course we need the text_extensions_for_pandas library itself.\n",
    "try:\n",
    "    import text_extensions_for_pandas as tp\n",
    "except ModuleNotFoundError as e:\n",
    "    # If we're running from within the project source tree and the parent Python\n",
    "    # environment doesn't have the text_extensions_for_pandas package, use the\n",
    "    # version in the local source tree.\n",
    "    if not os.getcwd().endswith(\"notebooks\"):\n",
    "        raise e\n",
    "    if \"..\" not in sys.path:\n",
    "        sys.path.insert(0, \"..\")\n",
    "    import text_extensions_for_pandas as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-essence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'outputs/eng.train',\n",
       " 'dev': 'outputs/eng.testa',\n",
       " 'test': 'outputs/eng.testb'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the CoNLL-2003 data set if necessary\n",
    "data_set_info = tp.io.conll.maybe_download_conll_data(\"outputs\")\n",
    "data_set_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sticky-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size of training fold in CoNLL format: 3206 kib'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with the size of the training fold in the original CoNLL format.\n",
    "train_fold_conll = data_set_info[\"train\"]\n",
    "conll_bytes = pathlib.Path(train_fold_conll).stat().st_size\n",
    "\n",
    "f\"Size of training fold in CoNLL format: {conll_bytes // 1024} kib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 23.2 ms, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read into one DataFrame per document.\n",
    "train_fold_dfs = tp.io.conll.conll_2003_to_dataframes(\n",
    "    train_fold_conll, column_names=[\"pos\", \"phrase\", \"ent\"],\n",
    "    iob_columns=[False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accurate-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialization of multi-doc token span arrays not yet implemented, so\n",
    "# convert sentences to SpanArrays as a workaround.\n",
    "for df in train_fold_dfs:\n",
    "    df[\"sentence\"] = tp.SpanArray(df[\"span\"].array.target_text, df[\"sentence\"].array.begin, df[\"sentence\"].array.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chubby-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>pos</th>\n",
       "      <th>phrase_iob</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>-X-</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11, 13): 'EU'</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[14, 21): 'rejects'</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B</td>\n",
       "      <td>VP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22, 28): 'German'</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>MISC</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[29, 33): 'call'</td>\n",
       "      <td>NN</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204562</th>\n",
       "      <td>[149, 154): 'three'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[140, 154): 'Division three'</td>\n",
       "      <td>219547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204563</th>\n",
       "      <td>[155, 162): 'Swansea'</td>\n",
       "      <td>NN</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204564</th>\n",
       "      <td>[163, 164): '1'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204565</th>\n",
       "      <td>[165, 172): 'Lincoln'</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204566</th>\n",
       "      <td>[173, 174): '2'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204567 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         span  pos phrase_iob phrase_type ent_iob ent_type  \\\n",
       "0       [0, 10): '-DOCSTART-'  -X-          O        None       O     None   \n",
       "1              [11, 13): 'EU'  NNP          B          NP       B      ORG   \n",
       "2         [14, 21): 'rejects'  VBZ          B          VP       O     None   \n",
       "3          [22, 28): 'German'   JJ          B          NP       B     MISC   \n",
       "4            [29, 33): 'call'   NN          I          NP       O     None   \n",
       "...                       ...  ...        ...         ...     ...      ...   \n",
       "204562    [149, 154): 'three'   CD          I          NP       O     None   \n",
       "204563  [155, 162): 'Swansea'   NN          B          NP       B      ORG   \n",
       "204564        [163, 164): '1'   CD          I          NP       O     None   \n",
       "204565  [165, 172): 'Lincoln'  NNP          I          NP       B      ORG   \n",
       "204566        [173, 174): '2'   CD          I          NP       O     None   \n",
       "\n",
       "                                                 sentence  line_num  \n",
       "0                                   [0, 10): '-DOCSTART-'         0  \n",
       "1       [11, 58): 'EU rejects German call to boycott B...         2  \n",
       "2       [11, 58): 'EU rejects German call to boycott B...         3  \n",
       "3       [11, 58): 'EU rejects German call to boycott B...         4  \n",
       "4       [11, 58): 'EU rejects German call to boycott B...         5  \n",
       "...                                                   ...       ...  \n",
       "204562                       [140, 154): 'Division three'    219547  \n",
       "204563                  [155, 174): 'Swansea 1 Lincoln 2'    219549  \n",
       "204564                  [155, 174): 'Swansea 1 Lincoln 2'    219550  \n",
       "204565                  [155, 174): 'Swansea 1 Lincoln 2'    219551  \n",
       "204566                  [155, 174): 'Swansea 1 Lincoln 2'    219552  \n",
       "\n",
       "[204567 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fold = pd.concat(train_fold_dfs).reset_index(drop=True)\n",
    "train_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loaded-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the training fold as a Feather file\n",
    "train_fold_feather = \"outputs/eng.train.feather\"\n",
    "train_fold.to_feather(train_fold_feather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "orange-franklin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size of training fold in Feather format: 7449 kib'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How big is the Feather file?\n",
    "feather_bytes = pathlib.Path(train_fold_feather).stat().st_size\n",
    "\n",
    "f\"Size of training fold in Feather format: {feather_bytes // 1024} kib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dangerous-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_parquet = \"outputs/eng.train.parquet\"\n",
    "train_fold.to_parquet(train_fold_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unavailable-replication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size of training fold in Parquet format: 3575 kib'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How big is the Parquet file?\n",
    "parquet_bytes = pathlib.Path(train_fold_parquet).stat().st_size\n",
    "\n",
    "f\"Size of training fold in Parquet format: {parquet_bytes // 1024} kib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "departmental-discussion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.5 ms, sys: 8.72 ms, total: 44.2 ms\n",
      "Wall time: 28.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>span</th>\n",
       "      <th>pos</th>\n",
       "      <th>phrase_iob</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>line_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>-X-</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 10): '-DOCSTART-'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[11, 13): 'EU'</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[14, 21): 'rejects'</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B</td>\n",
       "      <td>VP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22, 28): 'German'</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>MISC</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[29, 33): 'call'</td>\n",
       "      <td>NN</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[11, 58): 'EU rejects German call to boycott B...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204562</th>\n",
       "      <td>[149, 154): 'three'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[140, 154): 'Division three'</td>\n",
       "      <td>219547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204563</th>\n",
       "      <td>[155, 162): 'Swansea'</td>\n",
       "      <td>NN</td>\n",
       "      <td>B</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204564</th>\n",
       "      <td>[163, 164): '1'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204565</th>\n",
       "      <td>[165, 172): 'Lincoln'</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204566</th>\n",
       "      <td>[173, 174): '2'</td>\n",
       "      <td>CD</td>\n",
       "      <td>I</td>\n",
       "      <td>NP</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>[155, 174): 'Swansea 1 Lincoln 2'</td>\n",
       "      <td>219552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204567 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         span  pos phrase_iob phrase_type ent_iob ent_type  \\\n",
       "0       [0, 10): '-DOCSTART-'  -X-          O        None       O     None   \n",
       "1              [11, 13): 'EU'  NNP          B          NP       B      ORG   \n",
       "2         [14, 21): 'rejects'  VBZ          B          VP       O     None   \n",
       "3          [22, 28): 'German'   JJ          B          NP       B     MISC   \n",
       "4            [29, 33): 'call'   NN          I          NP       O     None   \n",
       "...                       ...  ...        ...         ...     ...      ...   \n",
       "204562    [149, 154): 'three'   CD          I          NP       O     None   \n",
       "204563  [155, 162): 'Swansea'   NN          B          NP       B      ORG   \n",
       "204564        [163, 164): '1'   CD          I          NP       O     None   \n",
       "204565  [165, 172): 'Lincoln'  NNP          I          NP       B      ORG   \n",
       "204566        [173, 174): '2'   CD          I          NP       O     None   \n",
       "\n",
       "                                                 sentence  line_num  \n",
       "0                                   [0, 10): '-DOCSTART-'         0  \n",
       "1       [11, 58): 'EU rejects German call to boycott B...         2  \n",
       "2       [11, 58): 'EU rejects German call to boycott B...         3  \n",
       "3       [11, 58): 'EU rejects German call to boycott B...         4  \n",
       "4       [11, 58): 'EU rejects German call to boycott B...         5  \n",
       "...                                                   ...       ...  \n",
       "204562                       [140, 154): 'Division three'    219547  \n",
       "204563                  [155, 174): 'Swansea 1 Lincoln 2'    219549  \n",
       "204564                  [155, 174): 'Swansea 1 Lincoln 2'    219550  \n",
       "204565                  [155, 174): 'Swansea 1 Lincoln 2'    219551  \n",
       "204566                  [155, 174): 'Swansea 1 Lincoln 2'    219552  \n",
       "\n",
       "[204567 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read the Feather file back in\n",
    "pd.read_parquet(train_fold_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "honey-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpaCy's converter is picky about how to format document boundaries.\n",
    "# Adjust the contents of the training fold to suit.\n",
    "with open(train_fold_conll, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "SPACY_DOC_DELIMITER = \"-DOCSTART- -X- O O\"\n",
    "    \n",
    "train_fold_conll_spacy = \"outputs/eng.train2.conll\"\n",
    "with open(train_fold_conll_spacy, \"w\") as f:\n",
    "    for l in lines:\n",
    "        if l.startswith(\"-DOCSTART-\"):\n",
    "            f.write(SPACY_DOC_DELIMITER + \"\\n\")\n",
    "        else:\n",
    "            f.write(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "popular-intensity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.07 s, sys: 73.1 ms, total: 1.15 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(train_fold_conll_spacy) as f:\n",
    "    file_contents = f.read()\n",
    "\n",
    "# Read the training fold using SpaCy's corpus utilities\n",
    "training_docs_generator = spacy.training.converters.conll_ner_to_docs(\n",
    "    file_contents,\n",
    "    n_sents=0,\n",
    "    seg_sents=False,\n",
    ")\n",
    "training_docs = list(training_docs_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ruled-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
      "disabled.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (946 documents): outputs/eng.train2.spacy\u001b[0m\n",
      "CPU times: user 13.2 ms, sys: 21.6 ms, total: 34.8 ms\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert to SpaCy binary\n",
    "! python -m spacy convert outputs/eng.train2.conll outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "southern-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n",
      "disabled.\u001b[0m\n",
      "\u001b[38;5;2m✔ Generated output file (1 documents): outputs/eng.train2.json\u001b[0m\n",
      "CPU times: user 11 ms, sys: 19.2 ms, total: 30.1 ms\n",
      "Wall time: 2.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert to SpaCy JSON\n",
    "! python -m spacy convert outputs/eng.train2.conll outputs --file-type json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fatal-exception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 782 ms, sys: 24.8 ms, total: 807 ms\n",
      "Wall time: 806 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_fold_spacy = \"outputs/eng.train2.spacy\"\n",
    "\n",
    "corpus = spacy.training.Corpus(train_fold_spacy)\n",
    "nlp = spacy.blank(\"en\")\n",
    "train_data_generator = corpus(nlp)\n",
    "train_data = list(train_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "statewide-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training fold with nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fallen-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK reader needs the corpus to be an entire directory.\n",
    "!mkdir -p outputs/eng.train.nltk\n",
    "!cp outputs/eng.train outputs/eng.train.nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "graduate-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 881 ms, sys: 115 ms, total: 996 ms\n",
      "Wall time: 993 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reader = nltk.corpus.reader.conll.ConllCorpusReader(root=\"outputs/eng.train.nltk\", \n",
    "                                           fileids=[train_fold_conll],\n",
    "                                           columntypes=[\"words\", \"pos\", \"ignore\", \"ne\"])\n",
    "tagged_words = list(reader.tagged_words(\"eng.train\"))\n",
    "sentences = list(reader.sents(\"eng.train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acquired-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP'), ('rejects', 'VBZ'), ('German', 'JJ'), ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tagged_words(\"eng.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-water",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
