{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bcbc8e-302c-4693-be39-1e5ae57047b1",
   "metadata": {},
   "source": [
    "<font size=6>\n",
    "    <b>Cross_check_datapoints.ipynb:</b> Train an ensemble of lower accuracy models, then use them to find inaccurate labels in the ewt conll dataset. \n",
    " </font>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This document is currently a Work in Progress. The goal is to do something similar to conll_3.ipynb, where an ensemble of models are used together to find possible incorrect labels in the orignal corpus. \n",
    "There are three main phases: \n",
    "\n",
    "### 1. Preprocessing\n",
    "\n",
    "The preprocessing phase uses many of the integrations for Text-extensions for Pandas to prep the dataset for training and inferencing on ahead of susspicious enry flagging \n",
    "Broadly, what we do is: \n",
    "1. Import all the folds of the dataset we're using (Universal dependencies EWT) \n",
    "1. Create a Pandas Categorical datatype on over which to classify\n",
    "1. Retokenize that dataset using Huggingface Transformers to Bert-compatible tokens\n",
    "1. Correlate the new tokens with their original counterpart's parts of speech\n",
    "1. Create the Bert embeddings for each sub-token\n",
    "1. Convert the parts of speech tags to our categoical datatype\n",
    "\n",
    "### 2. Model Training \n",
    "   \n",
    "During the model training phase, we train a number of models ontop of the bert embeddings ontop of the Bert embeddings we calculated in phase one \n",
    "These fall into two categories: \n",
    "- a large model accross the whole Bert embedding space with relatively high accuracy\n",
    "- a large number of lower accuracy models trained on gaussian random projections of the Bert embedding space\n",
    "\n",
    "### 3. Cross-correlation\n",
    "\n",
    "In this phase, we run inference on the corpus and, using the models in conjunction look for places where there is high agreement between models that disagrees with the corpus ground truth label, flag suspicious entries and go through some descriptive stats. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afdac88d-365d-4759-9c05-2215d4240dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import sklearn\n",
    "\n",
    "import sklearn.pipeline\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import util\n",
    "\n",
    "# And of course we need the text_extensions_for_pandas library itself.\n",
    "try:\n",
    "    import text_extensions_for_pandas as tp\n",
    "except ModuleNotFoundError as e:\n",
    "    # If we're running from within the project source tree and the parent Python\n",
    "    # environment doesn't have the text_extensions_for_pandas package, use the\n",
    "    # version in the local source tree.\n",
    "    if \"../..\" not in sys.path:\n",
    "        sys.path.insert(0, \"../..\")\n",
    "    import text_extensions_for_pandas as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f5d917-21ef-4daa-8f61-d2b7d31608c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init some globals we need later on \n",
    "BASE_DIR = '../../notebooks/CoNLL_u_test_inputs/'\n",
    "FEATHER_FILE = \"conllu_database.feather\"\n",
    "ewt_base_url = \"https://github.com/UniversalDependencies/UD_English-EWT/blob/master/en_ewt-ud-\"\n",
    "corpus_df = None\n",
    "load_cached_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45319df7-2fa8-4587-8406-d058905c37a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted fold: 'test' to list of 316 dataframes\n",
      "converted fold: 'dev' to list of 318 dataframes\n",
      "converted fold: 'train' to list of 540 dataframes\n"
     ]
    }
   ],
   "source": [
    "# We're going to need the whole ewt dataset for this: download them, and parse them in \n",
    "fold_paths = {\"test\":  tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"test.conllu\"),\n",
    "              \"dev\":   tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"dev.conllu\"),\n",
    "              \"train\": tp.io.conll.maybe_download_dataset_data(BASE_DIR, ewt_base_url + \"train.conllu\")}\n",
    "fold_docs = {}\n",
    "for fold,fold_path in fold_paths.items(): \n",
    "    fold_docs[fold] = tp.io.conll.conll_u_to_dataframes(fold_path)\n",
    "    print(f\"converted fold: '{fold}' to list of {len(fold_docs[fold])} dataframes\")\n",
    "    #     uncomment to display segments of the extracted folds \n",
    "    #     display(fold_docs[fold][0].head()[['span','lemma','upostag','features','sentence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ccb89-1d01-4833-9c8a-d6c660f58e98",
   "metadata": {},
   "source": [
    "## Initialize elements for preprocessing steps\n",
    "Instantiate pretrained tokenizer and BERT models from transformers library, and create a pandas categorical datatype for parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6bfd97-30f4-4031-8562-05bda164b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(bert_model_name)\n",
    "bert = transformers.BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# also we will want to create a pandas categorical dtype for what we want to predict- part of speech. \n",
    "# use the combined df, because it has all the elements \n",
    "upostags_list = list(fold_docs['train'][0].append(fold_docs['train'][1:])['upostag'].unique())\n",
    "# upostag_dtype,upostag_list,upostag_dict = tp.io.conll.make_iob_tag_categories(upostags)\n",
    "upostag_dtype = pd.CategoricalDtype(categories = upostags_list)\n",
    "upostag_dict = {upostags_list[i]:i for i in range(len(upostags_list)) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c30f1-a203-44e9-9811-c1fe3b5ee30f",
   "metadata": {},
   "source": [
    "## Preprocess the document\n",
    "\n",
    "Because steps 3-6 can only be done on a document-by-document basis, we create a method to do them in a batch, then run them  on the whole corpus. Note this process is computationally intensive so it may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db01bfcd-363c-4183-8554-c24d6a11e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9258d30b75eb4181848450c73c8849e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=316, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0586a795f549109a46e8a7da13330e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=318, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91747a7f5f93449093db012c96be9403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Starting...', layout=Layout(width='100%'), max=540, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a method to take care of preprocessing steps: 3-6\n",
    "def preprocess_document(document, tokenizer,bert):\n",
    "    # create BERT compatible tokens using our tokenizer\n",
    "    temp = tp.io.bert.make_bert_tokens(document.loc[0,'span'].target_text, tokenizer)\n",
    "    # re-correlate our original spans with their bert-compatible equivalents\n",
    "    spans = tp.TokenSpanArray.align_to_tokens(temp[\"span\"],document[\"span\"])\n",
    "    \n",
    "    # now carry over some features from the old spans to the new onesspans_df = spans.as_frame().drop(columns = [\"begin\",\"end\"])\n",
    "    spans_df = spans.as_frame().drop(columns = ['begin','end','covered_text'])\n",
    "    spans_df['postag'] = document['upostag']\n",
    "    printed = 20\n",
    "    for i,b_tok,e_tok,pos in spans_df.itertuples():\n",
    "        temp.loc[b_tok:e_tok-1 , [\"postag\",\"raw_span\",'raw_span_id']] = pos,spans[i],i\n",
    "    \n",
    "    # now translate from text tags to postag \n",
    "    temp['postag'].fillna('X',inplace=True) # in our Labels, 'X' is a standin for \"N/A\" so convert N/A's to 'X'\n",
    "    temp[\"postag_id\"] = temp['postag'].apply(lambda t: int(upostag_dict[str(t)]))\n",
    "    temp = temp.astype({'postag_id':'int','postag':upostag_dtype})\n",
    "    return tp.io.bert.add_embeddings(temp, bert)\n",
    "\n",
    "\n",
    "# preprocess the whole corpus: \n",
    "bert_docs_by_fold = {}\n",
    "for fold in fold_docs.keys():\n",
    "    docs = fold_docs[fold]\n",
    "    print(f\"processing fold {fold}\")\n",
    "    bert_docs_by_fold[fold] = tp.jupyter.run_with_progress_bar(len(docs),lambda i: preprocess_document(docs[i],tokenizer,bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740fe0a8-7f12-49f1-88a0-13d3cb9e17c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[  -0.37686592,   -0.14841378,    0.73980016, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>[  -0.23266968,   -0.40546328,     0.6171929, ...</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>[5, 7): 'if'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>[   -0.8156859,   -0.04782569,   0.081484295, ...</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>7986</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[8, 14): 'Google'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[   0.78967804,    -0.8511879,   -0.48812625, ...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[15, 17): 'Mo'</td>\n",
       "      <td>12556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[15, 22): 'Morphed'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[  -0.25935018,     0.5710723,   -0.09106647, ...</td>\n",
       "      <td>Mo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  doc_num  token_id               span  input_id  token_type_id  \\\n",
       "0  test        0         0         [0, 0): ''       101              0   \n",
       "1  test        0         1     [0, 4): 'What'      1327              0   \n",
       "2  test        0         2       [5, 7): 'if'      1191              0   \n",
       "3  test        0         3  [8, 14): 'Google'      7986              0   \n",
       "4  test        0         4     [15, 17): 'Mo'     12556              0   \n",
       "\n",
       "   attention_mask  special_tokens_mask postag             raw_span  \\\n",
       "0               1                 True      X                  NaN   \n",
       "1               1                False   PRON       [0, 4): 'What'   \n",
       "2               1                False  SCONJ         [5, 7): 'if'   \n",
       "3               1                False  PROPN    [8, 14): 'Google'   \n",
       "4               1                False   VERB  [15, 22): 'Morphed'   \n",
       "\n",
       "   raw_span_id  postag_id                                          embedding  \\\n",
       "0          NaN         14  [  -0.37686592,   -0.14841378,    0.73980016, ...   \n",
       "1          0.0          8  [  -0.23266968,   -0.40546328,     0.6171929, ...   \n",
       "2          1.0         10  [   -0.8156859,   -0.04782569,   0.081484295, ...   \n",
       "3          2.0          0  [   0.78967804,    -0.8511879,   -0.48812625, ...   \n",
       "4          3.0          4  [  -0.25935018,     0.5710723,   -0.09106647, ...   \n",
       "\n",
       "     text  \n",
       "0          \n",
       "1    What  \n",
       "2      if  \n",
       "3  Google  \n",
       "4      Mo  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine folds and save to a feather file, so we don't necessarily need to redo the preprocessing. \n",
    "corpus_df = tp.io.conll.combine_folds(bert_docs_by_fold)\n",
    "corpus_df[\"text\"] = corpus_df[\"span\"].apply(lambda s: s.covered_text)\n",
    "cols_to_drop = [c for c in corpus_df.columns if \"span\" in c]\n",
    "corpus_df.drop(columns=cols_to_drop).to_feather(\"outputs/conll_u_corpus.feather\")\n",
    "corpus_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803b52bd-f09e-45e7-9be8-5797fc816e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read feather document if need be: \n",
    "if corpus_df is None or corpus_df.size == 0:\n",
    "    corpus_df = pd.read_feather(\"outputs/conll_u_corpus.feather\")\n",
    "    corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3929cfe5-c3ad-4666-9c6f-dae150d3463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>span</th>\n",
       "      <th>input_id</th>\n",
       "      <th>token_type_id</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>special_tokens_mask</th>\n",
       "      <th>postag</th>\n",
       "      <th>raw_span</th>\n",
       "      <th>raw_span_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64729</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[   -0.41927838,    -0.22575253,     0.6648760...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64730</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 2): 'Al'</td>\n",
       "      <td>2586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[0, 2): 'Al'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.36961424,     -1.0804733,     -0.283367...</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64731</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 3): '-'</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[2, 3): '-'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[    -0.9178737,    -0.94624436,     -0.808995...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64732</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[4, 5): 'Z'</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[4, 9): 'Zaman'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[   -0.90530086,    -0.97086835,     -1.440879...</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64733</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[5, 9): 'aman'</td>\n",
       "      <td>19853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>[4, 9): 'Zaman'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[    -1.1586123,      -1.149766,     -1.194975...</td>\n",
       "      <td>aman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307892</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>756</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>1139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "      <td>[3152, 3154): 'my'</td>\n",
       "      <td>690.0</td>\n",
       "      <td>8</td>\n",
       "      <td>[   -0.06984596,     -0.4646067,     0.8547705...</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307893</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>757</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>1610</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[3155, 3158): 'car'</td>\n",
       "      <td>691.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[    0.14624132,    -0.46386197,      0.596684...</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307894</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>758</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3158, 3159): ')'</td>\n",
       "      <td>692.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[  -0.090651065,    -0.29592788,      0.597023...</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307895</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>759</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>[3159, 3160): '.'</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[   0.031023545,    -0.27608734,      0.782190...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307896</th>\n",
       "      <td>train</td>\n",
       "      <td>539</td>\n",
       "      <td>760</td>\n",
       "      <td>[0, 0): ''</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>[    -0.5088702,    -0.22885968,      0.544944...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243168 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fold  doc_num  token_id                 span  input_id  \\\n",
       "64729   train        0         0           [0, 0): ''       101   \n",
       "64730   train        0         1         [0, 2): 'Al'      2586   \n",
       "64731   train        0         2          [2, 3): '-'       118   \n",
       "64732   train        0         3          [4, 5): 'Z'       163   \n",
       "64733   train        0         4       [5, 9): 'aman'     19853   \n",
       "...       ...      ...       ...                  ...       ...   \n",
       "307892  train      539       756   [3152, 3154): 'my'      1139   \n",
       "307893  train      539       757  [3155, 3158): 'car'      1610   \n",
       "307894  train      539       758    [3158, 3159): ')'       114   \n",
       "307895  train      539       759    [3159, 3160): '.'       119   \n",
       "307896  train      539       760           [0, 0): ''       102   \n",
       "\n",
       "        token_type_id  attention_mask  special_tokens_mask postag  \\\n",
       "64729               0               1                 True      X   \n",
       "64730               0               1                False  PROPN   \n",
       "64731               0               1                False  PUNCT   \n",
       "64732               0               1                False  PROPN   \n",
       "64733               0               1                False  PROPN   \n",
       "...               ...             ...                  ...    ...   \n",
       "307892              0               1                False   PRON   \n",
       "307893              0               1                False   NOUN   \n",
       "307894              0               1                False  PUNCT   \n",
       "307895              0               1                False  PUNCT   \n",
       "307896              0               1                 True      X   \n",
       "\n",
       "                   raw_span  raw_span_id  postag_id  \\\n",
       "64729                   NaN          NaN         14   \n",
       "64730          [0, 2): 'Al'          0.0          0   \n",
       "64731           [2, 3): '-'          1.0          1   \n",
       "64732       [4, 9): 'Zaman'          2.0          0   \n",
       "64733       [4, 9): 'Zaman'          2.0          0   \n",
       "...                     ...          ...        ...   \n",
       "307892   [3152, 3154): 'my'        690.0          8   \n",
       "307893  [3155, 3158): 'car'        691.0          3   \n",
       "307894    [3158, 3159): ')'        692.0          1   \n",
       "307895    [3159, 3160): '.'        693.0          1   \n",
       "307896                  NaN          NaN         14   \n",
       "\n",
       "                                                embedding  text  \n",
       "64729   [   -0.41927838,    -0.22575253,     0.6648760...        \n",
       "64730   [   -0.36961424,     -1.0804733,     -0.283367...    Al  \n",
       "64731   [    -0.9178737,    -0.94624436,     -0.808995...     -  \n",
       "64732   [   -0.90530086,    -0.97086835,     -1.440879...     Z  \n",
       "64733   [    -1.1586123,      -1.149766,     -1.194975...  aman  \n",
       "...                                                   ...   ...  \n",
       "307892  [   -0.06984596,     -0.4646067,     0.8547705...    my  \n",
       "307893  [    0.14624132,    -0.46386197,      0.596684...   car  \n",
       "307894  [  -0.090651065,    -0.29592788,      0.597023...     )  \n",
       "307895  [   0.031023545,    -0.27608734,      0.782190...     .  \n",
       "307896  [    -0.5088702,    -0.22885968,      0.544944...        \n",
       "\n",
       "[243168 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now get ready to train our model: \n",
    "train_df = corpus_df[corpus_df[\"fold\"] == \"train\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac817b-0da2-450f-89cc-665397dd1d38",
   "metadata": {},
   "source": [
    "# Train an ensemble of models\n",
    "use embeddings to quickly train multiple models at different sophistication levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6063ff-9d18-4fca-acd1-8e52515c6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.pipeline\n",
    "# import ray\n",
    "# if ray.is_initialized():\n",
    "#     ray.shutdown()\n",
    "# ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9955cd-260b-4496-9a08-87e3cd88de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('mlogreg',\n",
       "                 LogisticRegression(max_iter=10000, multi_class='multinomial',\n",
       "                                    verbose=10))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBFGS_ITERATIONS = 10000\n",
    "\n",
    "load_from_file = True # we've trained a model already so just load it from there \n",
    "pickle_model_file = \"conllu_pos_classifier.pickle\"\n",
    "\n",
    "\n",
    "if load_from_file: \n",
    "    with open(BASE_DIR+ pickle_model_file, 'rb') as file: \n",
    "        base_model = pickle.load(file)\n",
    "    print(\"loaded\")\n",
    "else: \n",
    "    # train a simple multinomial logisticmodel on the training set: \n",
    "    _MULTI_CLASS = \"multinomial\"\n",
    "    base_pipeline = sklearn.pipeline.Pipeline([\n",
    "        # Standard scaler. This only makes a difference for certain classes\n",
    "        # of embeddings.\n",
    "        #(\"scaler\", sklearn.preprocessing.StandardScaler()),\n",
    "        (\"mlogreg\", sklearn.linear_model.LogisticRegression(\n",
    "            multi_class=_MULTI_CLASS,\n",
    "            verbose=10,\n",
    "            max_iter=10000\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    base_model = base_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "X_train = train_df[\"embedding\"].values\n",
    "Y_train = train_df[\"postag_id\"]    \n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6c8a7c-8d16-4a16-a468-98c4b1d212f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_postag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ADP</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag  postag_id predicted_id  \\\n",
       "raw_span                                                                      \n",
       "[0, 4): 'What'       test        0         1   PRON          8            1   \n",
       "[5, 7): 'if'         test        0         2  SCONJ         10           10   \n",
       "[8, 14): 'Google'    test        0         3  PROPN          0            0   \n",
       "[15, 22): 'Morphed'  test        0         4   VERB          4            3   \n",
       "[23, 27): 'Into'     test        0         7    ADP          6            6   \n",
       "\n",
       "                    predicted_postag  \n",
       "raw_span                              \n",
       "[0, 4): 'What'                 PUNCT  \n",
       "[5, 7): 'if'                   SCONJ  \n",
       "[8, 14): 'Google'              PROPN  \n",
       "[15, 22): 'Morphed'             NOUN  \n",
       "[23, 27): 'Into'                 ADP  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a few functions to predict on a dataframe \n",
    "def infer_on_df(df: pd.DataFrame, id_to_class_dict, predictor):\n",
    "    result_df = df.copy()\n",
    "    raw_outputs = tp.TensorArray(predictor.predict_proba(result_df[\"embedding\"]))\n",
    "    result_df[\"p_id\"] = np.argmax(raw_outputs, axis=1)\n",
    "    result_df[\"p_postag\"]= result_df[\"p_id\"].apply(lambda p_id: id_to_class_dict[p_id])\n",
    "    result_df[\"raw_output\"] = raw_outputs\n",
    "    return result_df\n",
    "\n",
    "def infer_and_deBert(df_in: pd.DataFrame, id_to_class_dict, predictor,groupby_tag='raw_span',output_tag='raw_outputs',name_output='predicted_id',name_val = 'predicted_postag'):\n",
    "    #util function \n",
    "    def agg_outputs(series: pd.Series):\n",
    "        return series.to_numpy().prod(axis=0).argmax()\n",
    "    #build aggregation fields\n",
    "    keep_cols = [c for c in ['fold','doc_num','token_id','postag','postag_id'] if c in df_in.columns]\n",
    "    aggby = {k: 'first' for k in keep_cols}\n",
    "    aggby[output_tag] = agg_outputs\n",
    "    sort_cols = [col for col in [\"fold\", \"doc_num\", \"raw_span\"] if col in df_in.columns]\n",
    "    df = df_in[['embedding','raw_span'] + keep_cols].copy()\n",
    "    \n",
    "    #first, run inference \n",
    "    df.loc[:,'raw_outputs'] = tp.TensorArray(predictor.predict_proba(df[\"embedding\"]))\n",
    "    #group by original tag \n",
    "    results_df = (\n",
    "        df.groupby(\"raw_span\")\n",
    "        .agg(aggby)\n",
    "        .rename(columns={'raw_outputs': name_output})\n",
    "        .sort_values(sort_cols)\n",
    "    )\n",
    "    #repeat translation \n",
    "    results_df[\"predicted_postag\"] = results_df[name_output].apply(\n",
    "        lambda p_id: id_to_class_dict[p_id]\n",
    "    )\n",
    "    return results_df\n",
    " \n",
    "inferred = infer_and_deBert(corpus_df[corpus_df[\"fold\"] == \"test\"],upostags_list,base_model)\n",
    "inferred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2480c114-be05-44b0-bcb0-d726efea0264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.79      0.78      0.79      1782\n",
      "         ADP       0.92      0.92      0.92      2030\n",
      "         ADV       0.79      0.75      0.77      1147\n",
      "         AUX       0.94      0.95      0.95      1509\n",
      "       CCONJ       0.97      0.96      0.97       738\n",
      "         DET       0.96      0.96      0.96      1898\n",
      "        INTJ       0.88      0.71      0.78       120\n",
      "        NOUN       0.86      0.89      0.88      4136\n",
      "         NUM       0.86      0.90      0.88       541\n",
      "        PART       0.95      0.94      0.95       630\n",
      "        PRON       0.97      0.96      0.97      2158\n",
      "       PROPN       0.84      0.83      0.84      1985\n",
      "       PUNCT       0.99      0.96      0.97      3098\n",
      "       SCONJ       0.86      0.83      0.85       443\n",
      "         SYM       0.65      0.64      0.64       106\n",
      "        VERB       0.90      0.90      0.90      2640\n",
      "           X       0.47      0.70      0.56       137\n",
      "\n",
      "    accuracy                           0.90     25098\n",
      "   macro avg       0.86      0.86      0.86     25098\n",
      "weighted avg       0.90      0.90      0.90     25098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(inferred['postag'],inferred['predicted_postag']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4171e26-fc57-4826-b59f-b92d41a0c46d",
   "metadata": {},
   "source": [
    "## Make a large number of less accurate models, to cross-correlate\n",
    "\n",
    "[`util.py`](./util.py) contains a function `train_reduced_model()` that produces \n",
    "detuned versions of our multilogreg model. This function works by setting up\n",
    "a two-stage pipeline. The first stage is a `sklearn.random_projection.GaussianRandomProjection`\n",
    "model that reduces the number of dimensions of the input embeddings, and the second\n",
    "stage is a multinomial logistic regression model trained with `sklearn.linear_model.LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ff6967-edc0-4ca9-abd7-7271ce6bcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.random_projection\n",
    "def train_reduced_model(x_values: np.ndarray, y_values: np.ndarray, n_components: int,\n",
    "                        seed: int, max_iter: int = 10000) -> sklearn.base.BaseEstimator:\n",
    "    reduce_pipeline = sklearn.pipeline.Pipeline([\n",
    "        (\"dimred\", sklearn.random_projection.GaussianRandomProjection(\n",
    "            n_components=n_components,\n",
    "            random_state=seed\n",
    "        )),\n",
    "        (\"mlogreg\", sklearn.linear_model.LogisticRegression(\n",
    "            multi_class=\"multinomial\",\n",
    "            max_iter=max_iter\n",
    "        ))\n",
    "    ])\n",
    "    print(f\"Training model with n_components={n_components} and seed={seed}.\")\n",
    "    return reduce_pipeline.fit(x_values, y_values)\n",
    "\n",
    "# reduced_model = train_reduced_model(X_train, Y_train, 16, None, max_iter=LBFGS_ITERATIONS)\n",
    "# reduced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe00586-a9b2-4616-93f5-f0c95e0098f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9008298858574293,\n",
       " 'recall': 0.8996334369272452,\n",
       " 'f1-score': 0.8999523406011769}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_descriptive_stats(df:pd.DataFrame,Y_actual_col,Y_pred_col):\n",
    "    ret = {\n",
    "        'precision': sklearn.metrics.precision_score(df[Y_actual_col],df[Y_pred_col],average='weighted'),\n",
    "        'recall'   : sklearn.metrics.recall_score(df[Y_actual_col],df[Y_pred_col],average='weighted'),\n",
    "        'f1-score' : sklearn.metrics.f1_score(df[Y_actual_col],df[Y_pred_col],average='weighted')\n",
    "    }\n",
    "    return ret\n",
    "# reduced_out = infer_and_deBert(corpus_df[corpus_df[\"fold\"] == \"test\"],upostags_list,reduced_model)\n",
    "print('original: ')\n",
    "display(calc_descriptive_stats(inferred,'postag','predicted_postag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f44c6c0b-4852-4be6-8232-3981084dc03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_components': 512, 'seed': 3},\n",
       " {'n_components': 512, 'seed': 2},\n",
       " {'n_components': 512, 'seed': 1},\n",
       " {'n_components': 384, 'seed': 3},\n",
       " {'n_components': 384, 'seed': 2},\n",
       " {'n_components': 384, 'seed': 1},\n",
       " {'n_components': 256, 'seed': 3},\n",
       " {'n_components': 256, 'seed': 2},\n",
       " {'n_components': 256, 'seed': 1},\n",
       " {'n_components': 192, 'seed': 3},\n",
       " {'n_components': 192, 'seed': 2},\n",
       " {'n_components': 192, 'seed': 1},\n",
       " {'n_components': 128, 'seed': 3},\n",
       " {'n_components': 128, 'seed': 2},\n",
       " {'n_components': 128, 'seed': 1},\n",
       " {'n_components': 64, 'seed': 3},\n",
       " {'n_components': 64, 'seed': 2},\n",
       " {'n_components': 64, 'seed': 1},\n",
       " {'n_components': 32, 'seed': 3},\n",
       " {'n_components': 32, 'seed': 2},\n",
       " {'n_components': 32, 'seed': 1}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train a bunch of models using this\n",
    "_N_COMPONENTS = [32,64,128,192,256,384,512]  # Values for the n_components parameter TODO: this might need to be higher? \n",
    "_SEEDS = [1,2,3]              # values for the random seed (these are arbitrary)\n",
    "\n",
    "params = [{\"n_components\": c, \"seed\": s} \n",
    "          for c in _N_COMPONENTS\n",
    "          for s in _SEEDS]\n",
    "params.reverse() # start largest elts first \n",
    "\n",
    "def params_to_name(p):\n",
    "    return f\"{p['n_components']}_{p['seed']}\"\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c7689c-e996-4caa-bab0-860bf2fe0292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-14 21:36:05,912\tINFO services.py:1267 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=90710)\u001b[0m Training model with n_components=192 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90715)\u001b[0m Training model with n_components=256 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90712)\u001b[0m Training model with n_components=192 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90709)\u001b[0m Training model with n_components=128 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90707)\u001b[0m Training model with n_components=128 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90714)\u001b[0m Training model with n_components=256 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90721)\u001b[0m Training model with n_components=512 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90717)\u001b[0m Training model with n_components=384 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90718)\u001b[0m Training model with n_components=512 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90716)\u001b[0m Training model with n_components=384 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90706)\u001b[0m Training model with n_components=192 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90720)\u001b[0m Training model with n_components=512 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90713)\u001b[0m Training model with n_components=256 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90708)\u001b[0m Training model with n_components=64 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90711)\u001b[0m Training model with n_components=128 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90719)\u001b[0m Training model with n_components=384 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90708)\u001b[0m Training model with n_components=64 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90709)\u001b[0m Training model with n_components=64 and seed=1.\n",
      "\u001b[2m\u001b[36m(pid=90711)\u001b[0m Training model with n_components=32 and seed=3.\n",
      "\u001b[2m\u001b[36m(pid=90707)\u001b[0m Training model with n_components=32 and seed=2.\n",
      "\u001b[2m\u001b[36m(pid=90708)\u001b[0m Training model with n_components=32 and seed=1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup Ray \n",
    "import ray\n",
    "actual_num_cores = multiprocessing.cpu_count() // 2\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "# Wrap util.train_reduced_model in a Ray task\n",
    "@ray.remote\n",
    "def train_reduced_model_task(\n",
    "        x_values: np.ndarray, y_values: np.ndarray, n_components: int,\n",
    "        seed: int, max_iter: int = 10000) -> sklearn.base.BaseEstimator:\n",
    "    return train_reduced_model(x_values, y_values, n_components, seed, max_iter)\n",
    "\n",
    "# Push the X and Y values to Plasma so that our tasks can share them.\n",
    "X_id = ray.put(X_train.to_numpy())\n",
    "Y_id = ray.put(Y_train.to_numpy())\n",
    "\n",
    "names = [params_to_name(p) for p in params]\n",
    "futures = [\n",
    "    train_reduced_model_task.remote(X_id, Y_id, p[\"n_components\"], p[\"seed\"],\n",
    "                                          max_iter=LBFGS_ITERATIONS)\n",
    "    for p in params]\n",
    "results = ray.get(futures)\n",
    "\n",
    "# Clean up items we've added to Plasma\n",
    "del(X_id)\n",
    "del(Y_id)\n",
    "models = { name: model for name, model in zip(names, results) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a069902-4b86-4bfa-b249-610aa36d719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also include the model with no Gaussian random projections.\n",
    "models[\"768_1\"] = base_model\n",
    "params.append({\"n_components\": 768, \"seed\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062cff7f-2938-449d-8f41-140cc5e6d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models for future reference. (training takes a long time.)\n",
    "cached_models_dir = 'cached_models/'\n",
    "fname = cached_models_dir + 'cross_check_models_reduced.pickle'\n",
    "# if needed load from file \n",
    "if load_cached_models and False: #todo: change this \n",
    "    with open(fname, 'rb') as file:\n",
    "        models = pickle.load(file)\n",
    "    load_cached_models = False\n",
    "else: \n",
    "    with open(fname,'wb') as file:\n",
    "        pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46afe306-ccf2-48cb-888c-176bdcebd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate run inference with all of our models\n",
    "test_df = corpus_df[corpus_df[\"fold\"] == \"test\"]\n",
    "test_res_by_model = {name: infer_and_deBert(corpus_df[corpus_df[\"fold\"] == \"test\"]\n",
    "                                            ,upostags_list,models[name])\n",
    "                        for name in models.keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e78c819-307b-4efa-8dd0-5b5d4b42e927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_postag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ADP</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag  postag_id predicted_id  \\\n",
       "raw_span                                                                      \n",
       "[0, 4): 'What'       test        0         1   PRON          8            1   \n",
       "[5, 7): 'if'         test        0         2  SCONJ         10           10   \n",
       "[8, 14): 'Google'    test        0         3  PROPN          0            0   \n",
       "[15, 22): 'Morphed'  test        0         4   VERB          4            3   \n",
       "[23, 27): 'Into'     test        0         7    ADP          6           12   \n",
       "\n",
       "                    predicted_postag  \n",
       "raw_span                              \n",
       "[0, 4): 'What'                 PUNCT  \n",
       "[5, 7): 'if'                   SCONJ  \n",
       "[8, 14): 'Google'              PROPN  \n",
       "[15, 22): 'Morphed'             NOUN  \n",
       "[23, 27): 'Into'                 ADV  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict = {name: test_res_by_model[name] for name in test_res_by_model.keys()}\n",
    "# show that we have our outputs setup nicely \n",
    "res_dict[names[1]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd24ad57-2666-4714-96e5-d8358c97fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_components</th>\n",
       "      <th>seed</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32_2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.418101</td>\n",
       "      <td>0.421269</td>\n",
       "      <td>0.403034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32_3</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.427130</td>\n",
       "      <td>0.432863</td>\n",
       "      <td>0.415683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32_1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430198</td>\n",
       "      <td>0.435772</td>\n",
       "      <td>0.423233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64_1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567714</td>\n",
       "      <td>0.567296</td>\n",
       "      <td>0.561680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64_3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.561059</td>\n",
       "      <td>0.562435</td>\n",
       "      <td>0.553285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64_2</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537297</td>\n",
       "      <td>0.542832</td>\n",
       "      <td>0.532613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128_1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700500</td>\n",
       "      <td>0.700295</td>\n",
       "      <td>0.697950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128_2</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.703114</td>\n",
       "      <td>0.704439</td>\n",
       "      <td>0.701450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128_3</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>0.681582</td>\n",
       "      <td>0.677584</td>\n",
       "      <td>0.676334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>192_1</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766548</td>\n",
       "      <td>0.765041</td>\n",
       "      <td>0.763976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>192_2</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769108</td>\n",
       "      <td>0.767392</td>\n",
       "      <td>0.766732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>192_3</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764537</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>0.762140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256_2</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>0.805758</td>\n",
       "      <td>0.803690</td>\n",
       "      <td>0.803682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256_3</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804872</td>\n",
       "      <td>0.803052</td>\n",
       "      <td>0.802915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256_1</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808530</td>\n",
       "      <td>0.806399</td>\n",
       "      <td>0.806252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>384_1</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855704</td>\n",
       "      <td>0.854371</td>\n",
       "      <td>0.854482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384_2</td>\n",
       "      <td>384</td>\n",
       "      <td>2</td>\n",
       "      <td>0.854429</td>\n",
       "      <td>0.852498</td>\n",
       "      <td>0.853003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384_3</td>\n",
       "      <td>384</td>\n",
       "      <td>3</td>\n",
       "      <td>0.851486</td>\n",
       "      <td>0.849590</td>\n",
       "      <td>0.849914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>512_3</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>0.874191</td>\n",
       "      <td>0.872619</td>\n",
       "      <td>0.872882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>512_2</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.877847</td>\n",
       "      <td>0.876763</td>\n",
       "      <td>0.876898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512_1</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876485</td>\n",
       "      <td>0.874930</td>\n",
       "      <td>0.875233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>768_1</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900830</td>\n",
       "      <td>0.899633</td>\n",
       "      <td>0.899952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  n_components  seed  precision    recall  f1-score\n",
       "19   32_2            32     2   0.418101  0.421269  0.403034\n",
       "18   32_3            32     3   0.427130  0.432863  0.415683\n",
       "20   32_1            32     1   0.430198  0.435772  0.423233\n",
       "17   64_1            64     1   0.567714  0.567296  0.561680\n",
       "15   64_3            64     3   0.561059  0.562435  0.553285\n",
       "16   64_2            64     2   0.537297  0.542832  0.532613\n",
       "14  128_1           128     1   0.700500  0.700295  0.697950\n",
       "13  128_2           128     2   0.703114  0.704439  0.701450\n",
       "12  128_3           128     3   0.681582  0.677584  0.676334\n",
       "11  192_1           192     1   0.766548  0.765041  0.763976\n",
       "10  192_2           192     2   0.769108  0.767392  0.766732\n",
       "9   192_3           192     3   0.764537  0.762571  0.762140\n",
       "7   256_2           256     2   0.805758  0.803690  0.803682\n",
       "6   256_3           256     3   0.804872  0.803052  0.802915\n",
       "8   256_1           256     1   0.808530  0.806399  0.806252\n",
       "5   384_1           384     1   0.855704  0.854371  0.854482\n",
       "4   384_2           384     2   0.854429  0.852498  0.853003\n",
       "3   384_3           384     3   0.851486  0.849590  0.849914\n",
       "0   512_3           512     3   0.874191  0.872619  0.872882\n",
       "1   512_2           512     2   0.877847  0.876763  0.876898\n",
       "2   512_1           512     1   0.876485  0.874930  0.875233\n",
       "21  768_1           768     1   0.900830  0.899633  0.899952"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now get precision and recall for each\n",
    "precisions = []\n",
    "for p in params:\n",
    "    name = params_to_name(p)\n",
    "    row = {'name': name}\n",
    "    row.update(p)\n",
    "    row.update(calc_descriptive_stats(test_res_by_model[name],\n",
    "                                      'postag','predicted_postag'))\n",
    "    precisions.append(row)\n",
    "f1_scores = pd.DataFrame(precisions).sort_values('n_components')\n",
    "f1_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "217d014a-b2d4-4ba8-9a1b-d0456ab073fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the tradeoff between dimensionality and F1 score -(x scale is log base 2)\n",
    "x = f1_scores['n_components']\n",
    "y = f1_scores['f1-score']\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.scatter(x,y)\n",
    "plt.xscale('log',base=2)\n",
    "# plt.yscale('log')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('kernel size')\n",
    "plt.show()\n",
    "# this seems like it needs a high number of features to accurately predict.\n",
    "# it might be interesting to see how the accuracy of models we use can impact \n",
    "# the quality of the 'flags' that we raise on the corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5695ea-2e18-4c2e-922e-599f4b8ac8e6",
   "metadata": {},
   "source": [
    "# Now group and find agreements and disagreements between groups and 'gold' \n",
    "This process is largely analagous to what is done in conll_3.ipynb. Even though this problem is a token classification problem and the other one is an entity recognition one, by treating each token / part_of_speech pair as a seperate entity we are able to do much of the same grouping and comparisons\n",
    "\n",
    "This process works as follows: \n",
    "\n",
    "1. Start with our set of predictions made by each model as a seperate dataframe\n",
    "1. Grab a copy of the 'gold standard' tags from the corpus, and format it similarly to the predictions\n",
    "1. Label each of the 'labels' dataframes with its original source\n",
    "1. Combine the dataframes and use a single Pandas Groupby operation to find common token/Part-of-speech pairings, count the number of models in agreement, and determine if the pair is in the gold standard dataset \n",
    "1. Split into our 'in_gold' and 'not_in_gold' flagged subsets for human inspection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85373ab6-7a8a-4f78-af03-ce2188da2a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>predicted_id</th>\n",
       "      <th>predicted_postag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ADP</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag  postag_id predicted_id  \\\n",
       "raw_span                                                                      \n",
       "[0, 4): 'What'       test        0         1   PRON          8           12   \n",
       "[5, 7): 'if'         test        0         2  SCONJ         10            3   \n",
       "[8, 14): 'Google'    test        0         3  PROPN          0            0   \n",
       "[15, 22): 'Morphed'  test        0         4   VERB          4            3   \n",
       "[23, 27): 'Into'     test        0         7    ADP          6            6   \n",
       "\n",
       "                    predicted_postag  \n",
       "raw_span                              \n",
       "[0, 4): 'What'                   ADV  \n",
       "[5, 7): 'if'                    NOUN  \n",
       "[8, 14): 'Google'              PROPN  \n",
       "[15, 22): 'Morphed'             NOUN  \n",
       "[23, 27): 'Into'                 ADP  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with results dictionary dataframes... \n",
    "a_model = '256_1' # just took one at random\n",
    "# copy res_dict because we will be modifying it\n",
    "res_feats = {name: test_res_by_model[name].copy() for name in test_res_by_model.keys()}\n",
    "res_feats[a_model].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "165e7d89-4001-4f06-8871-fd83d5119feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>model</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>8</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>True</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>10</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>True</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>0</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>VERB</td>\n",
       "      <td>4</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>True</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>ADP</td>\n",
       "      <td>6</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>True</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag  postag_id model  in_gold  \\\n",
       "raw_span                                                                        \n",
       "[0, 4): 'What'       test        0         1   PRON          8  GOLD     True   \n",
       "[5, 7): 'if'         test        0         2  SCONJ         10  GOLD     True   \n",
       "[8, 14): 'Google'    test        0         3  PROPN          0  GOLD     True   \n",
       "[15, 22): 'Morphed'  test        0         4   VERB          4  GOLD     True   \n",
       "[23, 27): 'Into'     test        0         7    ADP          6  GOLD     True   \n",
       "\n",
       "                    gold_pos  \n",
       "raw_span                      \n",
       "[0, 4): 'What'          PRON  \n",
       "[5, 7): 'if'           SCONJ  \n",
       "[8, 14): 'Google'      PROPN  \n",
       "[15, 22): 'Morphed'     VERB  \n",
       "[23, 27): 'Into'         ADP  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now extract the 'in_gold' features and make them into a similar format as the results\n",
    "gold_feats = res_feats[list(res_feats.keys())[0]][['fold','doc_num','token_id','postag','postag_id']].copy()\n",
    "gold_feats['model'] = 'GOLD'\n",
    "gold_feats['in_gold'] =True\n",
    "gold_feats['gold_pos'] = gold_feats['postag']\n",
    "gold_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e6e7469-5394-4fa0-ae4b-684c2524858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>model</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>ADV</td>\n",
       "      <td>256_1</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>256_1</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>256_1</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>256_1</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>ADP</td>\n",
       "      <td>256_1</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag_id postag  model  in_gold  \\\n",
       "raw_span                                                                        \n",
       "[0, 4): 'What'       test        0         1        12    ADV  256_1    False   \n",
       "[5, 7): 'if'         test        0         2         3   NOUN  256_1    False   \n",
       "[8, 14): 'Google'    test        0         3         0  PROPN  256_1    False   \n",
       "[15, 22): 'Morphed'  test        0         4         3   NOUN  256_1    False   \n",
       "[23, 27): 'Into'     test        0         7         6    ADP  256_1    False   \n",
       "\n",
       "                    gold_pos  \n",
       "raw_span                      \n",
       "[0, 4): 'What'          PRON  \n",
       "[5, 7): 'if'           SCONJ  \n",
       "[8, 14): 'Google'      PROPN  \n",
       "[15, 22): 'Morphed'     VERB  \n",
       "[23, 27): 'Into'         ADP  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will quickly want to modify them to label who created them, and remove the predicted cols\n",
    "for model_name in res_feats.keys():\n",
    "    res_feats[model_name]['model'] = model_name\n",
    "    res_feats[model_name]['in_gold'] = False\n",
    "    res_feats[model_name]['gold_pos'] = res_feats[model_name]['postag']\n",
    "    res_feats[model_name].drop(columns = ['postag_id','postag'],inplace=True)\n",
    "    res_feats[model_name].rename(columns= {'predicted_id':'postag_id','predicted_postag':'postag'},inplace=True)\n",
    "res_feats[a_model].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e6c1b5-58db-4bd0-968d-662c749f99f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>postag_id</th>\n",
       "      <th>postag</th>\n",
       "      <th>model</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_span</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0, 4): 'What'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>ADV</td>\n",
       "      <td>512_3</td>\n",
       "      <td>False</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5, 7): 'if'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>512_3</td>\n",
       "      <td>False</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8, 14): 'Google'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>512_3</td>\n",
       "      <td>False</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[15, 22): 'Morphed'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>512_3</td>\n",
       "      <td>False</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[23, 27): 'Into'</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>ADV</td>\n",
       "      <td>512_3</td>\n",
       "      <td>False</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold  doc_num  token_id postag_id postag  model  in_gold  \\\n",
       "raw_span                                                                        \n",
       "[0, 4): 'What'       test        0         1        12    ADV  512_3    False   \n",
       "[5, 7): 'if'         test        0         2        10  SCONJ  512_3    False   \n",
       "[8, 14): 'Google'    test        0         3         0  PROPN  512_3    False   \n",
       "[15, 22): 'Morphed'  test        0         4         3   NOUN  512_3    False   \n",
       "[23, 27): 'Into'     test        0         7        12    ADV  512_3    False   \n",
       "\n",
       "                    gold_pos  \n",
       "raw_span                      \n",
       "[0, 4): 'What'          PRON  \n",
       "[5, 7): 'if'           SCONJ  \n",
       "[8, 14): 'Google'      PROPN  \n",
       "[15, 22): 'Morphed'     VERB  \n",
       "[23, 27): 'Into'         ADP  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now combine and collate \n",
    "res_feats['gold'] = gold_feats\n",
    "result_feats_df= pd.concat(list(res_feats.values()))\n",
    "result_feats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc9911c-0748-4cb2-a56f-290cd925b436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_span</th>\n",
       "      <th>postag</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>counts</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[226, 228): 'is'</td>\n",
       "      <td>AUX</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>41</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[201, 204): 'the'</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>34</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[133, 135): 'in'</td>\n",
       "      <td>ADP</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>22</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[124, 127): 'the'</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>20</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[77, 83): 'tissue'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>315</td>\n",
       "      <td>14</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[278, 282): 'Seth'</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>314</td>\n",
       "      <td>64</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[241, 246): 'price'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>314</td>\n",
       "      <td>54</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[136, 139): 'was'</td>\n",
       "      <td>AUX</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>314</td>\n",
       "      <td>32</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[122, 129): 'morning'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>314</td>\n",
       "      <td>29</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[78, 82): 'sink'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>314</td>\n",
       "      <td>19</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                raw_span postag  in_gold  counts  \\\n",
       "0       [226, 228): 'is'    AUX     True      22   \n",
       "1      [201, 204): 'the'    DET     True      22   \n",
       "2       [133, 135): 'in'    ADP     True      22   \n",
       "3      [124, 127): 'the'    DET     True      22   \n",
       "4     [77, 83): 'tissue'   NOUN     True      22   \n",
       "5     [278, 282): 'Seth'  PROPN     True      22   \n",
       "6    [241, 246): 'price'   NOUN     True      22   \n",
       "7      [136, 139): 'was'    AUX     True      22   \n",
       "8  [122, 129): 'morning'   NOUN     True      22   \n",
       "9       [78, 82): 'sink'   NOUN     True      22   \n",
       "\n",
       "                                               model  fold  doc_num  token_id  \\\n",
       "0  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      315        41   \n",
       "1  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      315        34   \n",
       "2  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      315        22   \n",
       "3  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      315        20   \n",
       "4  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      315        14   \n",
       "5  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      314        64   \n",
       "6  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      314        54   \n",
       "7  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      314        32   \n",
       "8  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      314        29   \n",
       "9  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      314        19   \n",
       "\n",
       "  gold_pos  \n",
       "0      AUX  \n",
       "1      DET  \n",
       "2      ADP  \n",
       "3      DET  \n",
       "4     NOUN  \n",
       "5    PROPN  \n",
       "6     NOUN  \n",
       "7      AUX  \n",
       "8     NOUN  \n",
       "9     NOUN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a count column so that only model-predicted results are tallied\n",
    "result_feats_df['counts'] = 1\n",
    "result_feats_df.loc[result_feats_df['in_gold'],'counts']=0\n",
    "\n",
    "# create groupby aggregation dict \n",
    "aggby_firsts = ['fold','doc_num','token_id','gold_pos']\n",
    "aggby= {'in_gold':'any','counts':'sum','model': lambda x: list(x)}\n",
    "aggby.update({field: 'first' for field in aggby_firsts})\n",
    "             \n",
    "#now finally our groupby\n",
    "grouped_feats = result_feats_df.groupby(['raw_span','postag'])\\\n",
    "                    .agg(aggby).sort_values(['counts','fold','doc_num','token_id'],ascending=False)\\\n",
    "                    .reset_index()\n",
    "grouped_feats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c7b0ac5-40a9-48fe-86b9-c9ab022bc387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_span</th>\n",
       "      <th>postag</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>counts</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[88, 96): 'trimmers'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>303</td>\n",
       "      <td>27</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[45, 49): 'rear'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>303</td>\n",
       "      <td>17</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>[261, 262): '.'</td>\n",
       "      <td>X</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>292</td>\n",
       "      <td>50</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>[244, 252): 'computer'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>[195, 200): 'front'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>283</td>\n",
       "      <td>44</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>[203, 208): 'check'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>280</td>\n",
       "      <td>41</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>[213, 220): 'tmobile'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>279</td>\n",
       "      <td>49</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[168, 175): 'tmobile'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>[71, 78): 'tmobile'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>279</td>\n",
       "      <td>17</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>[6, 13): 'tmobile'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   raw_span postag  in_gold  counts  \\\n",
       "91     [88, 96): 'trimmers'   NOUN    False      22   \n",
       "93         [45, 49): 'rear'   NOUN    False      22   \n",
       "155         [261, 262): '.'      X    False      22   \n",
       "172  [244, 252): 'computer'   NOUN    False      22   \n",
       "231     [195, 200): 'front'   NOUN    False      22   \n",
       "249     [203, 208): 'check'   NOUN    False      22   \n",
       "257   [213, 220): 'tmobile'   NOUN    False      22   \n",
       "261   [168, 175): 'tmobile'   NOUN    False      22   \n",
       "263     [71, 78): 'tmobile'   NOUN    False      22   \n",
       "267      [6, 13): 'tmobile'   NOUN    False      22   \n",
       "\n",
       "                                                 model  fold  doc_num  \\\n",
       "91   [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      303   \n",
       "93   [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      303   \n",
       "155  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      292   \n",
       "172  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      290   \n",
       "231  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      283   \n",
       "249  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      280   \n",
       "257  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      279   \n",
       "261  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      279   \n",
       "263  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      279   \n",
       "267  [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      279   \n",
       "\n",
       "     token_id gold_pos  \n",
       "91         27    PROPN  \n",
       "93         17      ADJ  \n",
       "155        50    PUNCT  \n",
       "172        50      ADJ  \n",
       "231        44      ADJ  \n",
       "249        41     VERB  \n",
       "257        49    PROPN  \n",
       "261        39    PROPN  \n",
       "263        17    PROPN  \n",
       "267         2    PROPN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the not_in_gold data subset, showing features that\n",
    "# several models agree upon but disagree with the corpus label\n",
    "not_in_gold = grouped_feats[~ grouped_feats['in_gold']]\n",
    "not_in_gold.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa5f4a32-df7b-44a0-9a80-7e90e863e041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"spanArray\">\n",
       "    <div id=\"spans\" \n",
       "     style=\"color: var(--jp-layout-color2); border: 1px solid var(--jp-border-color0); float:left; padding:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>covered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>208</td>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div id=\"text\"\n",
       "     style=\"float:right; border: 1px solid var(--jp-border-color0); width: 60%;\">\n",
       "\n",
       "                <div style=\"float:center; padding:10px\">\n",
       "                    <p style=\"font-family:var(--jp-code-font-family); font-size:var(--jp-code-font-size)\">\n",
       "                        Walgreens on University<br>My pharmacy order is always correct and promptly delivered but the pharmacy staff are always very short with me and do n&#39;t seem to like answering questions.<br>Clean store, friendly <span style=\"background-color:rgba(255, 215, 0, 0.5)\">check</span>- out staff up front.<br>Good selection.\n",
       "                    </p>\n",
       "                </div>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<SpanArray>\n",
       "[[203, 208): 'check']\n",
       "Length: 1, dtype: SpanDtype"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display an example of a not-in-gold flagged token\n",
    "# here, all 22 models agree that 'wikipedia.org' is a proper noun\n",
    "# in this context, wheras the corpus lists it as 'X' type \n",
    "def display_span(span:tp.array.span):\n",
    "    # use the inbuilt display features in SpanArray to display the token\n",
    "    display(tp.SpanArray(span.target_text, [span.begin],[span.end]))\n",
    "display_span(not_in_gold.reset_index().iloc[5]['raw_span'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac527ff6-c345-4054-a02a-5a4414ae4d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_span</th>\n",
       "      <th>postag</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>counts</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83622</th>\n",
       "      <td>[0, 4): 'What'</td>\n",
       "      <td>PRON</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83093</th>\n",
       "      <td>[109, 119): 'connecting'</td>\n",
       "      <td>VERB</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>102</td>\n",
       "      <td>25</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83092</th>\n",
       "      <td>[387, 390): ':-)'</td>\n",
       "      <td>SYM</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>102</td>\n",
       "      <td>88</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83091</th>\n",
       "      <td>[76, 80): 'with'</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>103</td>\n",
       "      <td>19</td>\n",
       "      <td>SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83090</th>\n",
       "      <td>[394, 402): 'whatever'</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>103</td>\n",
       "      <td>83</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83089</th>\n",
       "      <td>[75, 80): 'where'</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83088</th>\n",
       "      <td>[208, 212): 'down'</td>\n",
       "      <td>ADV</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>39</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83087</th>\n",
       "      <td>[221, 232): 'considering'</td>\n",
       "      <td>VERB</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83086</th>\n",
       "      <td>[243, 249): 'search'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>48</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83085</th>\n",
       "      <td>[416, 422): 'Google'</td>\n",
       "      <td>VERB</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>134</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        raw_span postag  in_gold  counts   model  fold  \\\n",
       "83622             [0, 4): 'What'   PRON     True       0  [GOLD]  test   \n",
       "83093   [109, 119): 'connecting'   VERB     True       0  [GOLD]  test   \n",
       "83092          [387, 390): ':-)'    SYM     True       0  [GOLD]  test   \n",
       "83091           [76, 80): 'with'  SCONJ     True       0  [GOLD]  test   \n",
       "83090     [394, 402): 'whatever'    DET     True       0  [GOLD]  test   \n",
       "83089          [75, 80): 'where'    ADV     True       0  [GOLD]  test   \n",
       "83088         [208, 212): 'down'    ADV     True       0  [GOLD]  test   \n",
       "83087  [221, 232): 'considering'   VERB     True       0  [GOLD]  test   \n",
       "83086       [243, 249): 'search'   NOUN     True       0  [GOLD]  test   \n",
       "83085       [416, 422): 'Google'   VERB     True       0  [GOLD]  test   \n",
       "\n",
       "       doc_num  token_id gold_pos  \n",
       "83622        0         1     PRON  \n",
       "83093      102        25     VERB  \n",
       "83092      102        88      SYM  \n",
       "83091      103        19    SCONJ  \n",
       "83090      103        83      DET  \n",
       "83089      104        15      ADV  \n",
       "83088      104        39      ADV  \n",
       "83087      104        44     VERB  \n",
       "83086      104        48     NOUN  \n",
       "83085      104       134     VERB  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now generate in_gold, the set of tokens that are in the corpus\n",
    "# but have low agreement between the models and the corpus\n",
    "in_gold = grouped_feats[grouped_feats['in_gold']].sort_values('counts')# ascending\n",
    "in_gold.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a719e9f-e2bb-4557-911e-8271b3bca269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"spanArray\">\n",
       "    <div id=\"spans\" \n",
       "     style=\"color: var(--jp-layout-color2); border: 1px solid var(--jp-border-color0); float:left; padding:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>covered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>249</td>\n",
       "      <td>search</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div id=\"text\"\n",
       "     style=\"float:right; border: 1px solid var(--jp-border-color0); width: 60%;\">\n",
       "\n",
       "                <div style=\"float:center; padding:10px\">\n",
       "                    <p style=\"font-family:var(--jp-code-font-family); font-size:var(--jp-code-font-size)\">\n",
       "                        What would you call the device that hold up your photography backdrop?<br>and where can I find them?<br>Background support systems.<br>Or background stands<br>buy them in any good photography supplies shop.<br>frame<br>thumbs down ???<br>odd considering this is a <span style=\"background-color:rgba(255, 215, 0, 0.5)\">search</span> on the net:<br>http://www.google.co.uk/search?q=backdrop+frame&amp;ie=utf-8&amp;oe=utf-8&amp;aq=t&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a&amp;safe=active&amp;sout=1<br>Backdrop stand.<br>Google the term or find photography supplies websites and put it in the search box (or look for studio equipment supplies).\n",
       "                    </p>\n",
       "                </div>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<SpanArray>\n",
       "[[243, 249): 'search']\n",
       "Length: 1, dtype: SpanDtype"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_span</th>\n",
       "      <th>postag</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>counts</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>doc_num</th>\n",
       "      <th>token_id</th>\n",
       "      <th>gold_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>[243, 249): 'search'</td>\n",
       "      <td>X</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>[512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>48</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64248</th>\n",
       "      <td>[243, 249): 'search'</td>\n",
       "      <td>PRON</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>[32_2]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>48</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83086</th>\n",
       "      <td>[243, 249): 'search'</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[GOLD]</td>\n",
       "      <td>test</td>\n",
       "      <td>104</td>\n",
       "      <td>48</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   raw_span postag  in_gold  counts  \\\n",
       "4603   [243, 249): 'search'      X    False      21   \n",
       "64248  [243, 249): 'search'   PRON    False       1   \n",
       "83086  [243, 249): 'search'   NOUN     True       0   \n",
       "\n",
       "                                                   model  fold  doc_num  \\\n",
       "4603   [512_3, 512_2, 512_1, 384_3, 384_2, 384_1, 256...  test      104   \n",
       "64248                                             [32_2]  test      104   \n",
       "83086                                             [GOLD]  test      104   \n",
       "\n",
       "       token_id gold_pos  \n",
       "4603         48     NOUN  \n",
       "64248        48     NOUN  \n",
       "83086        48     NOUN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display an example of an in-gold flagged token\n",
    "# here the corpus states that the word 'must' is of the AUX\n",
    "# part of speech, with 0 models in agreement with it. \n",
    "# here we also display the other predictions made by models to provide \n",
    "# context\n",
    "targ_sp = in_gold.reset_index().iloc[8]['raw_span']\n",
    "display_span(targ_sp)\n",
    "grouped_feats \n",
    "grouped_feats[grouped_feats['raw_span']==targ_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "de5428a8-72e5-443e-9240-6d9bd987b252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numModels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "numModels       \n",
       "22           118\n",
       "21           108\n",
       "20           100\n",
       "19           114\n",
       "18           137\n",
       "17           139\n",
       "16           121\n",
       "15           153\n",
       "14           199\n",
       "13           259"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_ng = (\n",
    "    not_in_gold.rename(columns={\"counts\": \"numModels\"})\n",
    "    .groupby(\"numModels\")\n",
    "    .agg({\"fold\": \"count\"})\n",
    "    .rename(columns={\"fold\": \"count\"})\n",
    "    .sort_values(\"numModels\", ascending=False)\n",
    ")\n",
    "counts_ng.plot()\n",
    "counts_ng.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2645fb06-6971-4975-bc80-23be567be802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. elts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_models</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            no. elts\n",
       "num_models          \n",
       "0                801\n",
       "1                387\n",
       "2                332\n",
       "3                299\n",
       "4                303\n",
       "5                326\n",
       "6                330\n",
       "7                370\n",
       "8                418\n",
       "9                449"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_ig = (\n",
    "    in_gold.rename(columns={\"counts\": \"num_models\"})\n",
    "    .groupby(\"num_models\")\n",
    "    .agg({\"fold\": \"count\"})\n",
    "    .rename(columns={\"fold\": \"no. elts\"})\n",
    ")\n",
    "counts_ig.plot()\n",
    "counts_ig.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83bbb1e4-17f9-47b7-9e6e-12f7e88e0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of our data to a file \n",
    "grouped_feats.to_csv(cached_models_dir +'v3_outputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ff8b2-3027-423a-8f4b-d1d88494b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
