{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating ESSP rules to Gremlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_text as pt\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Initialize the spaCy deep parser\n",
    "parser = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjectives\n",
    "Original rules:\n",
    "```yaml\n",
    "-\n",
    "  condition: { /node/pos: ADJ }\n",
    "  actions:\n",
    "    -\n",
    "     output:  { form: normal, start: /node, head: /node, span: /node/span_of }\n",
    "     subcases:\n",
    "       -\n",
    "         condition: { /node/left/form: more }\n",
    "         outputs: [{ form: comparative, start: /node/left, head: /node, span: /node/span_of }]\n",
    "       -\n",
    "         condition: { /node/left/form: most }\n",
    "         outputs: [{ form: superlative, start: /node/left, head: /node, span: /node/span_of }]\n",
    "       - \n",
    "         condition: { /node/feats/Degree: Cmp }\n",
    "         outputs: [{ form: comparative, start: /node, head: /node, span: /node/span_of }]\n",
    "       -\n",
    "         condition: { /node/feats/Degree: Sup }\n",
    "         outputs: [{ form: superlative, start: /node, head: /node, span: /node/span_of }]\n",
    "  outputs: [{ view: Adjective, id: /node/id, form: /form, start: /start, head: /node, span: /node/span_of, headNF: /node/lemma, noun: /node/parent }]\n",
    "```\n",
    "English translation:\n",
    "1. Start with all nodes with the part of speech tag \"ADJ\". Use this node to fill the \"head\" and \"span\" fields of the result.\n",
    "1. Populate the output fields \"form\", \"start\", and \"span\" as follows:\n",
    "   * **Case 1: The token to the left of the head is \"more\".** Set the \"form\" output to \"comparative\", set \"start\" to the token to the left of the head.\n",
    "   * **Case 2: The token to the left of hte head is \"most\".** \"form\" ==> \"superlative\", \"start\" ==> token to left of head\n",
    "   * **Case 3: The head's degree is \"Cmp\" (\"JJR\" tag in SpaCy output).** \"form\" ==> \"comparative\", \"start\" ==> head\n",
    "   * **Case 4: The head's degree is \"Sup\" (\"JJS\" tag in SpaCy output).** \"form\" ==> \"superlative\", \"start\" ==> head\n",
    "   * **Case 5: None of the previous conditions hold.** \"form\" ==> \"normal\", \"start\" => head\n",
    "1. Also return the lemmatized form of the head as \"headNF\" and the parent of the head as \"noun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_num</th>\n",
       "      <th>char_span</th>\n",
       "      <th>token_span</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>head</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>sentence</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1): '\n",
       "'</td>\n",
       "      <td>[0, 1): '\n",
       "'</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 5): 'This'</td>\n",
       "      <td>[1, 2): 'This'</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>2</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[6, 8): 'is'</td>\n",
       "      <td>[2, 3): 'is'</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>2</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[9, 10): 'a'</td>\n",
       "      <td>[3, 4): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>6</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[11, 14): 'big'</td>\n",
       "      <td>[4, 5): 'big'</td>\n",
       "      <td>big</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>6</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[15, 18): 'red'</td>\n",
       "      <td>[5, 6): 'red'</td>\n",
       "      <td>red</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>6</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[19, 26): 'balloon'</td>\n",
       "      <td>[6, 7): 'balloon'</td>\n",
       "      <td>balloon</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>2</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[26, 27): '.'</td>\n",
       "      <td>[7, 8): '.'</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[28, 29): '\n",
       "'</td>\n",
       "      <td>[8, 9): '\n",
       "'</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 9): '\n",
       "This is a big red balloon. \n",
       "'</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[29, 33): 'That'</td>\n",
       "      <td>[9, 10): 'That'</td>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>10</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[34, 36): 'is'</td>\n",
       "      <td>[10, 11): 'is'</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>10</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[37, 38): 'a'</td>\n",
       "      <td>[11, 12): 'a'</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>13</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[39, 45): 'bigger'</td>\n",
       "      <td>[12, 13): 'bigger'</td>\n",
       "      <td>big</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJR</td>\n",
       "      <td>amod</td>\n",
       "      <td>13</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[46, 49): 'one'</td>\n",
       "      <td>[13, 14): 'one'</td>\n",
       "      <td>one</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>attr</td>\n",
       "      <td>10</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[49, 50): '.'</td>\n",
       "      <td>[14, 15): '.'</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[50, 51): '\n",
       "'</td>\n",
       "      <td>[15, 16): '\n",
       "'</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[9, 16): 'That is a bigger one.\n",
       "'</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_num            char_span          token_span    lemma    pos  tag  \\\n",
       "0           0          [0, 1): '\n",
       "'         [0, 1): '\n",
       "'       \\n  SPACE  _SP   \n",
       "1           1       [1, 5): 'This'      [1, 2): 'This'     this    DET   DT   \n",
       "2           2         [6, 8): 'is'        [2, 3): 'is'       be    AUX  VBZ   \n",
       "3           3         [9, 10): 'a'         [3, 4): 'a'        a    DET   DT   \n",
       "4           4      [11, 14): 'big'       [4, 5): 'big'      big    ADJ   JJ   \n",
       "5           5      [15, 18): 'red'       [5, 6): 'red'      red    ADJ   JJ   \n",
       "6           6  [19, 26): 'balloon'   [6, 7): 'balloon'  balloon   NOUN   NN   \n",
       "7           7        [26, 27): '.'         [7, 8): '.'        .  PUNCT    .   \n",
       "8           8        [28, 29): '\n",
       "'         [8, 9): '\n",
       "'       \\n  SPACE  _SP   \n",
       "9           9     [29, 33): 'That'     [9, 10): 'That'     that    DET   DT   \n",
       "10         10       [34, 36): 'is'      [10, 11): 'is'       be    AUX  VBZ   \n",
       "11         11        [37, 38): 'a'       [11, 12): 'a'        a    DET   DT   \n",
       "12         12   [39, 45): 'bigger'  [12, 13): 'bigger'      big    ADJ  JJR   \n",
       "13         13      [46, 49): 'one'     [13, 14): 'one'      one   NOUN   NN   \n",
       "14         14        [49, 50): '.'       [14, 15): '.'        .  PUNCT    .   \n",
       "15         15        [50, 51): '\n",
       "'       [15, 16): '\n",
       "'       \\n  SPACE  _SP   \n",
       "\n",
       "      dep  head shape  is_alpha  is_stop  \\\n",
       "0             1    \\n     False    False   \n",
       "1   nsubj     2  Xxxx      True     True   \n",
       "2    ROOT     2    xx      True     True   \n",
       "3     det     6     x      True     True   \n",
       "4    amod     6   xxx      True    False   \n",
       "5    amod     6   xxx      True    False   \n",
       "6    attr     2  xxxx      True    False   \n",
       "7   punct     2     .     False    False   \n",
       "8             7    \\n     False    False   \n",
       "9   nsubj    10  Xxxx      True     True   \n",
       "10   ROOT    10    xx      True     True   \n",
       "11    det    13     x      True     True   \n",
       "12   amod    13  xxxx      True    False   \n",
       "13   attr    10   xxx      True     True   \n",
       "14  punct    10     .     False    False   \n",
       "15           14    \\n     False    False   \n",
       "\n",
       "                                   sentence  left  right  \n",
       "0   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'  <NA>      1  \n",
       "1   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     0      2  \n",
       "2   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     1      3  \n",
       "3   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     2      4  \n",
       "4   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     3      5  \n",
       "5   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     4      6  \n",
       "6   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     5      7  \n",
       "7   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     6      8  \n",
       "8   [0, 9): '\n",
       "This is a big red balloon. \n",
       "'     7      9  \n",
       "9         [9, 16): 'That is a bigger one.\n",
       "'     8     10  \n",
       "10        [9, 16): 'That is a bigger one.\n",
       "'     9     11  \n",
       "11        [9, 16): 'That is a bigger one.\n",
       "'    10     12  \n",
       "12        [9, 16): 'That is a bigger one.\n",
       "'    11     13  \n",
       "13        [9, 16): 'That is a bigger one.\n",
       "'    12     14  \n",
       "14        [9, 16): 'That is a bigger one.\n",
       "'    13     15  \n",
       "15        [9, 16): 'That is a bigger one.\n",
       "'    14     16  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text = \"\"\"\n",
    "This is a big red balloon. \n",
    "That is a bigger one.\n",
    "This is the biggest sentence.\n",
    "This is a more big sentence.\n",
    "It is the most beautiful.\n",
    "This big house is bright.\"\"\"\n",
    "\n",
    "# Parse the text with SpaCy\n",
    "token_features = pt.make_tokens_and_features(target_text, parser, add_left_and_right=True)\n",
    "token_features.loc[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>headNF</th>\n",
       "      <th>span</th>\n",
       "      <th>form</th>\n",
       "      <th>noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[27, 28): 'big'</td>\n",
       "      <td>big</td>\n",
       "      <td>[27, 28): 'big'</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[28, 29): 'sentence'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[35, 36): 'beautiful'</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>[35, 36): 'beautiful'</td>\n",
       "      <td>superlative</td>\n",
       "      <td>[32, 33): 'is'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12, 13): 'bigger'</td>\n",
       "      <td>big</td>\n",
       "      <td>[12, 13): 'bigger'</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[13, 14): 'one'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19, 20): 'biggest'</td>\n",
       "      <td>big</td>\n",
       "      <td>[19, 20): 'biggest'</td>\n",
       "      <td>superlative</td>\n",
       "      <td>[20, 21): 'sentence'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, 5): 'big'</td>\n",
       "      <td>big</td>\n",
       "      <td>[4, 5): 'big'</td>\n",
       "      <td>normal</td>\n",
       "      <td>[6, 7): 'balloon'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[5, 6): 'red'</td>\n",
       "      <td>red</td>\n",
       "      <td>[5, 6): 'red'</td>\n",
       "      <td>normal</td>\n",
       "      <td>[6, 7): 'balloon'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[39, 40): 'big'</td>\n",
       "      <td>big</td>\n",
       "      <td>[39, 40): 'big'</td>\n",
       "      <td>normal</td>\n",
       "      <td>[40, 41): 'house'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[42, 43): 'bright'</td>\n",
       "      <td>bright</td>\n",
       "      <td>[42, 43): 'bright'</td>\n",
       "      <td>normal</td>\n",
       "      <td>[41, 42): 'is'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    head     headNF                   span         form  \\\n",
       "0        [27, 28): 'big'        big        [27, 28): 'big'  comparative   \n",
       "1  [35, 36): 'beautiful'  beautiful  [35, 36): 'beautiful'  superlative   \n",
       "2     [12, 13): 'bigger'        big     [12, 13): 'bigger'  comparative   \n",
       "3    [19, 20): 'biggest'        big    [19, 20): 'biggest'  superlative   \n",
       "4          [4, 5): 'big'        big          [4, 5): 'big'       normal   \n",
       "5          [5, 6): 'red'        red          [5, 6): 'red'       normal   \n",
       "6        [39, 40): 'big'        big        [39, 40): 'big'       normal   \n",
       "7     [42, 43): 'bright'     bright     [42, 43): 'bright'       normal   \n",
       "\n",
       "                   noun  \n",
       "0  [28, 29): 'sentence'  \n",
       "1        [32, 33): 'is'  \n",
       "2       [13, 14): 'one'  \n",
       "3  [20, 21): 'sentence'  \n",
       "4     [6, 7): 'balloon'  \n",
       "5     [6, 7): 'balloon'  \n",
       "6     [40, 41): 'house'  \n",
       "7        [41, 42): 'is'  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = pt.token_features_to_traversal(token_features)\n",
    "adj_traversal = (\n",
    "    g.V()\n",
    "    # Start with all nodes with the part of speech tag \"ADJ\". \n",
    "    # Use this node to fill the \"head\", \"headNF\" and \"span\" fields of the result.\n",
    "    .has(\"pos\", pt.Within(\"ADJ\")).as_(\"head\", \"headNF\", \"span\")\n",
    "    # Populate \"form\" field\n",
    "    .coalesce( # Cases 1-5 described above\n",
    "        pt.__.out(\"left\").has(\"lemma\", \"more\").constant(\"comparative\"),\n",
    "        pt.__.out(\"left\").has(\"lemma\", \"most\").constant(\"superlative\"),\n",
    "        pt.__.has(\"tag\", \"JJR\").constant(\"comparative\"),\n",
    "        pt.__.has(\"tag\", \"JJS\").constant(\"superlative\"),\n",
    "        pt.__.constant(\"normal\")\n",
    "    ).as_(\"form\")\n",
    "    # Populate \"start\" field\n",
    "    .select(\"head\")\n",
    "    .coalesce(\n",
    "        pt.__.out(\"left\").has(\"lemma\", \"more\"),  # Case 1 above\n",
    "        pt.__.out(\"left\").has(\"lemma\", \"most\"),  # Case 2\n",
    "        pt.__.select(\"head\")                     # Cases 3-5\n",
    "    )\n",
    "    # Populate \"noun\" field (outer join)\n",
    "    .select(\"head\")\n",
    "    .coalesce(\n",
    "        pt.__.out(\"head\").values(\"token_span\"),\n",
    "        pt.__.constant(None)\n",
    "    )\n",
    "    .as_(\"noun\")\n",
    "    .select(\"head\", \"headNF\", \"span\", \"form\", \"noun\")\n",
    "        .by(\"token_span\").by(\"lemma\").by(\"token_span\").by().by()\n",
    ").compute()\n",
    "adj_traversal.toDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals\n",
    "Original rules:\n",
    "```yaml\n",
    "-\n",
    "  condition : { /node/lower : [ if ] }\n",
    "  actions:\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent, b: /node }\n",
    "      output : { antecedent: /c }\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent/parent, b: /node/parent }\n",
    "      output : { consequent: /c }\n",
    "  outputs : [{ view: Conditional, id: /node/id, type: /node/lemma, antecedent : /antecedent, consequent: /consequent, span: /node/span_of }]\n",
    "  \n",
    "-\n",
    "  condition : { /node/lower : [ when, whenever ] }\n",
    "  actions:\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent, b: /node }\n",
    "      output : { consequent: /c }\n",
    "  outputs : [{ view: Conditional, id: /node/id, type: /node/lemma, antecedent : /node/children/pos=VERB/span_of, consequent: /consequent, span: /node/span_of }]\n",
    "-\n",
    "  condition : { /node/lower : [ unless, then, in case ] }\n",
    "  actions:\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent, b: /node }\n",
    "      output : { antecedent: /c }\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent/parent, b: /node/parent }\n",
    "      output : { consequent: /c }\n",
    "  outputs : [{ view: Conditional, id: /node/id, type: /node/lemma, antecedent : /antecedent, consequent: /consequent, span: /node/span_of }]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = \"\"\"\n",
    "I will do it if you ask me.\n",
    "This happens whenever we hear the noise.\n",
    "This is true as long as we stick to the point.\n",
    "It will continue to move forward unless stopped by an external force.\n",
    "Keep monitoring the gauge in case it exceeds threshold.\n",
    "If you ask, I will answer.\n",
    "If computer has any damage, it will need to be repaired.\n",
    "If computer has any damage, that issue will need to be resolved.\n",
    "If your 13-inch MacBook Pro has any damage which impairs the replacement of the battery, that issue will need to be resolved prior to the battery replacement.\n",
    "Note: If your 13-inch MacBook Pro has any damage which impairs the replacement of the battery, that issue will need to be resolved prior to the battery replacement.\n",
    "If I were the man that owned that car, I would have been angry.\"\"\"\n",
    "\n",
    "# Parse the text with SpaCy\n",
    "token_features = pt.make_tokens_and_features(target_text, parser)\n",
    "\n",
    "# Add a field \"lower\" with the lowercase form of each token\n",
    "token_features[\"lower\"] = np.char.lower(token_features[\"token_span\"].values.covered_text)\n",
    "\n",
    "# Build a dataframe of sentences\n",
    "sentences = pd.DataFrame({\"sentence\": token_features[\"sentence\"].unique()})\n",
    "\n",
    "# Show the first sentence's data\n",
    "token_features[token_features[\"sentence\"] == sentences[\"sentence\"].loc[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule 1:\n",
    "```yaml\n",
    "-\n",
    "  condition : { /node/lower : [ if ] }\n",
    "  actions:\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent, b: /node }\n",
    "      output : { antecedent: /c }\n",
    "    - function: subtract\n",
    "      input : { a: /node/parent/parent, b: /node/parent }\n",
    "      output : { consequent: /c }\n",
    "  outputs : [{ view: Conditional, id: /node/id, type: /node/lemma, antecedent : /antecedent, consequent: /consequent, span: /node/span_of }]\n",
    "```\n",
    "Source code of the `subtract()` built-in function:\n",
    "```java\n",
    "\n",
    "English translation:\n",
    "1. Start with all tokens whose lowercase form is \"if\"\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first example sentence \n",
    "first_sentence = token_features[token_features[\"sentence\"] == sentences[\"sentence\"].loc[0]]\n",
    "\n",
    "g = pt.token_features_to_traversal(first_sentence)\n",
    "\n",
    "first_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.V().toList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original rule is:\n",
    "```yaml\n",
    "-\n",
    "  condition: { /node/pos: NOUN }\n",
    "  actions:\n",
    "    - function: strip_phrase\n",
    " #     input : { node: /node}\n",
    "      params: { excludePos: '[ \"DET\", \"ADJ\" ]' }\n",
    "      output : { strippedPhrase: /strippedSpan, strippedPhraseNF: /normalForm }\n",
    "  outputs: [{ view: NounPhrase, id: /node/id, span: /node/span_of, \n",
    "          head: /node, headPOS: /node/pos, headNF: /node/lemma,\n",
    "          determiner: /node/children/pos=DET,\n",
    "          strippedPhrase: /strippedPhrase, strippedPhraseNF: /strippedPhraseNF }]     \n",
    "```\n",
    "Here's the source code for the `strip_phrase` UDF that this rule depends on:\n",
    "```java\n",
    "\tprivate DataObj stripPhrase(Data inputObj, Map<String, List<String>> paramSet, Trace trace) {\n",
    "\t\tif (_trace) trace.push(\"getStringExcludePos\");\n",
    "\t\tNode node = (Node) inputObj.get(\"node\", trace);\n",
    "\t\t\n",
    "\t\t// If node already has required output, return it\n",
    "\t\tDataObj output = (DataObj) node.stringRecursive;\n",
    "\t\tif (output != null) {\n",
    "\t\t\tif (_trace) trace.pop();\n",
    "\t\t\treturn output;\n",
    "\t\t}\n",
    "\n",
    "\t\t// Preprocess \n",
    "\t\tList<String> excludePosList = paramSet.get(\"excludePos\");\n",
    "\t\tSet<String> excludePos = new HashSet<>(excludePosList);\n",
    "\t\t\n",
    "\t\tDataObj result = stripPhrase(node, excludePos, trace);\n",
    "\n",
    "\t\tif (_trace) trace.pop();\n",
    "\t\treturn result;\n",
    "\t}\n",
    "\n",
    "\tprivate DataObj stripPhrase(Node node, Set<String> excludePos, Trace trace) {\n",
    "\t\tif (_trace) trace.push(\"stringRecursive for \" + node.id);\n",
    "\t\tList<Span> spans = new ArrayList<>();\n",
    "\t\tList<String> lemmas = new ArrayList<>();\n",
    "\t\t\n",
    "\t\t// From left\n",
    "\t\tfor (Node child: node.children) {\n",
    "\t\t\tif (child.id < node.id ) {\n",
    "\t\t\t\tDataObj results = stripPhrase(child, excludePos, trace);\n",
    "\t\t\t\tspans.add((Span) results.get(\"strippedSpan\"));\n",
    "\t\t\t\tlemmas.add(results.getBareString(\"normalForm\"));\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t// From self\n",
    "\t\tif (! excludePos.contains(node.pos)) {\n",
    "\t\t\tspans.add(node.getNodeSpan(trace));\n",
    "\t\t\tlemmas.add(node.lemma);\n",
    "\t\t}\n",
    "\n",
    "\t\t// Combine to form results\n",
    "\t\tSpan span = Span.combine(spans, trace);\n",
    "\t\tString normalForm = StringUtils.join(lemmas, \" \").trim();\n",
    "\t\tDataObj results = new DataObj();\n",
    "\t\tresults.put(\"strippedSpan\", span);\n",
    "\t\tresults.put(\"normalForm\", normalForm);\n",
    "\t\tnode.stringRecursive = results;\n",
    "\n",
    "\t\tif (_trace) trace.pop();\n",
    "\t\treturn results;\n",
    "\t}\n",
    "\n",
    "```\n",
    "\n",
    "English language translation of the above:\n",
    "1. Start with every token tagged `NOUN`\n",
    "1. Find every child of each `NOUN` token that is to the left of the `NOUN` and is not tagged with `DET` or `ADJ`\n",
    "1. Recursively repeat the previous step until a fixed point is reached.\n",
    "1. Also return the set of children of the head noun tagged with DET as the \"determiner\".  Leave the \"determiner\" field blank of no such children are present.\n",
    "1. For each set of children, find the smallest span that covers all children. Return that span as the \"stripped\" span.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a sentence\n",
    "target_text = \"The luxury auto maker bot last year sold 1,214 cars in the U.S.\"\n",
    "token_features = pt.make_tokens_and_features(target_text, parser)\n",
    "\n",
    "# Wrap a Gremlin GraphTraversal around our token features DataFrame \n",
    "g = pt.token_features_to_traversal(token_features)\n",
    "\n",
    "# The parts of the rule that naturally translate to Gremlin we do in Gremlin.\n",
    "noun_phrase_traversal = (\n",
    "    g.V()\n",
    "    # 1. Start with every token tagged `NOUN`\n",
    "    .has(\"pos\", \"NOUN\").as_(\"head\", \"headPOS\", \"headNF\")\n",
    "    # 2. Find every child of each NOUN token that is to the left of the NOUN and is not \n",
    "    #    tagged with DET or ADJ\n",
    "    # 3. Recursively repeat the previous step until a fixed point is reached\n",
    "    .repeat(pt.__.in_()\n",
    "            .where(pt.lt(\"head\")).by(\"token_span\")\n",
    "            .has(\"pos\", pt.without(\"DET\", \"ADJ\"))).emit().as_(\"child\")\n",
    "    # 4. Also return the set of children of the head noun tagged with DET as the \n",
    "    #   \"determiner\" field.  Leave the field blank if no such children are present.\n",
    "    .coalesce(\n",
    "        pt.__.select(\"head\").in_().has(\"pos\", \"DET\").values(\"token_span\"),\n",
    "        pt.__.constant(None)).as_(\"determiner\")\n",
    "    .select(\"head\", \"headPOS\", \"headNF\", \"child\", \"determiner\")\n",
    "        .by(\"token_span\").by(\"pos\").by(\"lemma\").by(\"token_span\").by()\n",
    "    .compute()\n",
    ")\n",
    "# The aggregation and formatting parts of the rule are in Pandas.\n",
    "# 5. For each set of children, find the smallest span that covers all children. \n",
    "#    Return that span as the \"stripped\" span.\n",
    "noun_phrase_df = (noun_phrase_traversal\n",
    "                  .toDataFrame()\n",
    "                  .groupby([\"head\"]).aggregate({\"headPOS\": \"first\", \"headNF\": \"first\", \n",
    "                                                \"determiner\": \"first\",\n",
    "                                                \"child\": pt.combine_agg})\n",
    "                  .reset_index())\n",
    "noun_phrase_df[\"strippedSpan\"] = pt.combine_spans(noun_phrase_df[\"child\"], noun_phrase_df[\"head\"])\n",
    "noun_phrase_df[\"normalForm\"] = pt.lemmatize(noun_phrase_df[\"strippedSpan\"], token_features)\n",
    "noun_phrase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase_traversal = (\n",
    "    g.V()\n",
    "     # 1. Start with every token tagged `NOUN`\n",
    "     .has(\"pos\", \"NOUN\").as_(\"head\", \"headPOS\", \"headNF\")\n",
    "     # 2. Find every child of each NOUN token that is to the left of the NOUN and is not \n",
    "     #    tagged with DET or ADJ\n",
    "     # 3. Recursively repeat the previous step until a fixed point is reached\n",
    "     .repeat(pt.__.in_()\n",
    "             .where(pt.lt(\"head\")).by(\"token_span\")\n",
    "             .has(\"pos\", pt.without(\"DET\", \"ADJ\"))).emit().as_(\"child\")\n",
    "#     # 4. Also return the set of children of the head noun tagged with DET as the \n",
    "#     #   \"determiner\" field.  Leave the field blank if no such children are present.\n",
    "#     .coalesce(\n",
    "#         pt.__.select(\"head\").in_().has(\"pos\", \"DET\").values(\"token_span\"),\n",
    "#         pt.__.constant(None)).as_(\"determiner\")\n",
    "#     .select(\"head\", \"headPOS\", \"headNF\", \"child\", \"determiner\")\n",
    "#         .by(\"token_span\").by(\"pos\").by(\"lemma\").by(\"token_span\").by()\n",
    "     .compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase_traversal.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase_traversal.aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Scratch space for Tinkerpop-compliant Gremlin code:\n",
    "\n",
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\").\n",
    "where(__.in().has(\"pos\", without(\"DET\", \"ADJ\"))).\n",
    "select(\"head\", \"headPOS\", \"headNF\").by(\"token_span\").by(\"pos\").by(\"lemma\").toList()\n",
    "\n",
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\").\n",
    "repeat(__.in().has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\").\n",
    "select(\"head\", \"child\").by(\"token_span\").toList()\n",
    "\n",
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().where(lt(\"head\")).by(\"token_span.begin_token\").\n",
    "       has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "select(\"head\", \"head.begin\", \"child\", \"child.begin\").\n",
    "by(\"token_span\").by(\"token_span.begin_token\").toList()\n",
    "\n",
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().where(lt(\"head\")).by(\"token_span.begin_token\").\n",
    "       has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "select(\"head\").in().has(\"pos\", \"DET\").as(\"determiner\").\n",
    "select(\"head\", \"child\", \"determiner\").\n",
    "    by(\"token_span\").\n",
    "toList()\n",
    "\n",
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().where(lt(\"head\")).by(\"token_span.begin_token\").\n",
    "       has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "coalesce(__.select(\"head\").in().has(\"pos\", \"DET\").values(\"token_span\"), constant(\"None\")).as(\"determiner\").\n",
    "select(\"head\", \"child\", \"determiner\").\n",
    "    by(\"token_span\").\n",
    "toList()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt.token_features_to_gremlin(token_features, include_begin_and_end=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
