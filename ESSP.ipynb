{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_text as pt\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Initialize the spaCy deep parser\n",
    "parser = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Parse a sentence\n",
    "target_text = \"The luxury auto maker bot last year sold 1,214 cars in the U.S.\"\n",
    "token_features = pt.make_tokens_and_features(target_text, parser)\n",
    "token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dependency parse of the sentence\n",
    "# Note that this is a bit different from the gold-standard parse tree.\n",
    "pt.render_parse_tree(token_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original rule is:\n",
    "```yaml\n",
    "-\n",
    "  condition: { /node/pos: NOUN }\n",
    "  actions:\n",
    "    - function: strip_phrase\n",
    " #     input : { node: /node}\n",
    "      params: { excludePos: '[ \"DET\", \"ADJ\" ]' }\n",
    "      output : { strippedPhrase: /strippedSpan, strippedPhraseNF: /normalForm }\n",
    "  outputs: [{ view: NounPhrase, id: /node/id, span: /node/span_of, \n",
    "          head: /node, headPOS: /node/pos, headNF: /node/lemma,\n",
    "          determiner: /node/children/pos=DET,\n",
    "          strippedPhrase: /strippedPhrase, strippedPhraseNF: /strippedPhraseNF }]     \n",
    "```\n",
    "Here's the source code for the `strip_phrase` UDF that this rule depends on:\n",
    "```java\n",
    "\tprivate DataObj stripPhrase(Data inputObj, Map<String, List<String>> paramSet, Trace trace) {\n",
    "\t\tif (_trace) trace.push(\"getStringExcludePos\");\n",
    "\t\tNode node = (Node) inputObj.get(\"node\", trace);\n",
    "\t\t\n",
    "\t\t// If node already has required output, return it\n",
    "\t\tDataObj output = (DataObj) node.stringRecursive;\n",
    "\t\tif (output != null) {\n",
    "\t\t\tif (_trace) trace.pop();\n",
    "\t\t\treturn output;\n",
    "\t\t}\n",
    "\n",
    "\t\t// Preprocess \n",
    "\t\tList<String> excludePosList = paramSet.get(\"excludePos\");\n",
    "\t\tSet<String> excludePos = new HashSet<>(excludePosList);\n",
    "\t\t\n",
    "\t\tDataObj result = stripPhrase(node, excludePos, trace);\n",
    "\n",
    "\t\tif (_trace) trace.pop();\n",
    "\t\treturn result;\n",
    "\t}\n",
    "\n",
    "\tprivate DataObj stripPhrase(Node node, Set<String> excludePos, Trace trace) {\n",
    "\t\tif (_trace) trace.push(\"stringRecursive for \" + node.id);\n",
    "\t\tList<Span> spans = new ArrayList<>();\n",
    "\t\tList<String> lemmas = new ArrayList<>();\n",
    "\t\t\n",
    "\t\t// From left\n",
    "\t\tfor (Node child: node.children) {\n",
    "\t\t\tif (child.id < node.id ) {\n",
    "\t\t\t\tDataObj results = stripPhrase(child, excludePos, trace);\n",
    "\t\t\t\tspans.add((Span) results.get(\"strippedSpan\"));\n",
    "\t\t\t\tlemmas.add(results.getBareString(\"normalForm\"));\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\t// From self\n",
    "\t\tif (! excludePos.contains(node.pos)) {\n",
    "\t\t\tspans.add(node.getNodeSpan(trace));\n",
    "\t\t\tlemmas.add(node.lemma);\n",
    "\t\t}\n",
    "\n",
    "\t\t// Combine to form results\n",
    "\t\tSpan span = Span.combine(spans, trace);\n",
    "\t\tString normalForm = StringUtils.join(lemmas, \" \").trim();\n",
    "\t\tDataObj results = new DataObj();\n",
    "\t\tresults.put(\"strippedSpan\", span);\n",
    "\t\tresults.put(\"normalForm\", normalForm);\n",
    "\t\tnode.stringRecursive = results;\n",
    "\n",
    "\t\tif (_trace) trace.pop();\n",
    "\t\treturn results;\n",
    "\t}\n",
    "\n",
    "```\n",
    "\n",
    "English language translation of the above:\n",
    "1. Start with every token tagged `NOUN`\n",
    "1. Find every child of each `NOUN` token that is to the left of the `NOUN` and is not tagged with `DET` or `ADJ`\n",
    "1. Recursively repeat the previous step until a fixed point is reached.\n",
    "1. For each set of children, find the smallest span that covers all children. Return that span as the \"stripped\" span. Also return the set of children of the head noun tagged with DET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap a Gremlin GraphTraversal around our token features DataFrame \n",
    "g = pt.token_features_to_traversal(token_features)\n",
    "\n",
    "# The parts of the rule that naturally translate to Gremlin we do in Gremlin.\n",
    "noun_phrase_traversal = (\n",
    "    g.V()\n",
    "    # 1. Start with every token tagged `NOUN`\n",
    "    .has(\"pos\", \"NOUN\").as_(\"head\", \"headPOS\", \"headNF\")\n",
    "    # 2. Find every child of each NOUN token that is to the left of the NOUN and is not tagged with DET or ADJ\n",
    "    # 3. Recursively repeat the previous step until a fixed point is reached\n",
    "    .repeat(pt.__.in_()\n",
    "            .where(pt.lt(\"head\")).by(\"token_span\")\n",
    "            .has(\"pos\", pt.without(\"DET\", \"ADJ\"))).emit().as_(\"child\")\n",
    "    \n",
    "    .select(\"head\", \"headPOS\", \"headNF\", \"child\").by(\"token_span\").by(\"pos\").by(\"lemma\").by(\"token_span\")\n",
    "    .compute()\n",
    ")\n",
    "noun_phrase_df = noun_phrase_traversal.toDataFrame()\n",
    "noun_phrase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noun_phrase_df.groupby([\"head\", \"headPOS\", \"headNF\"]).aggregate.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = noun_phrase_df[\"head\"].iloc[1]\n",
    "\"begin\" in dir(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(cell, \"begin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase_traversal.edges"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\").\n",
    "where(__.in().has(\"pos\", without(\"DET\", \"ADJ\"))).\n",
    "select(\"head\", \"headPOS\", \"headNF\").by(\"token_span\").by(\"pos\").by(\"lemma\").toList()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\").\n",
    "repeat(__.in().has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\").\n",
    "select(\"head\", \"child\").by(\"token_span\").toList()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "where(\"child\", lt(\"head\")).by(\"token_span.begin_token\").\n",
    "select(\"head\", \"head.begin\", \"child\", \"child.begin\").\n",
    "by(\"token_span\").by(\"token_span.begin_token\").toList()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().as(\"c\").where(\"c\", lt(\"head\")).by(\"token_span.begin_token\").has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "select(\"head\", \"head.begin\", \"child\", \"child.begin\").\n",
    "by(\"token_span\").by(\"token_span.begin_token\").toList()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g.V().has(\"pos\", \"NOUN\").as(\"head\", \"headPOS\", \"headNF\", \"head.begin\").\n",
    "repeat(__.in().where(lt(\"head\")).by(\"token_span.begin_token\").\n",
    "       has(\"pos\", without(\"DET\", \"ADJ\"))).emit().as(\"child\", \"child.begin\").\n",
    "select(\"head\", \"head.begin\", \"child\", \"child.begin\").\n",
    "by(\"token_span\").by(\"token_span.begin_token\").toList()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt.token_features_to_gremlin(token_features, include_begin_and_end=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
